{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"MCP Gateway","text":"<p>A flexible FastAPI-based gateway and router for Model Context Protocol (MCP) with support for virtual servers. It acts as a unified interface for tools, resources, prompts, virtual servers, and federated gateways - all accessible via rich multi-transport APIs and an interactive web-based Admin UI.</p> <p></p>"},{"location":"#what-it-does","title":"What it Does","text":"<ul> <li>\ud83d\udeaa Acts as a gateway layer in front of MCP servers or APIs</li> <li>\ud83d\udd17 Connects and federates multiple MCP backends (auto-discovery, fail-over, merging)</li> <li>\ud83d\udd04 Virtualizes REST APIs and external MCP servers as compliant tools and servers</li> <li>\ud83d\udee0\ufe0f Centralizes registration and management of tools, prompts, and resources</li> <li>\ud83d\udce1 Exposes all endpoints over HTTP/JSON-RPC, WebSocket, Server-Sent Events (SSE), and stdio</li> <li>\ud83d\udce6 Provides a stdio wrapper (<code>mcpgateway-wrapper</code>) for terminal-based or headless MCP clients</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Multi-Transport: HTTP, WebSocket, SSE, Streamable HTTP and stdio with auto-negotiation</li> <li>Federation &amp; Health Checks: Auto-discovery (mDNS or static), syncing, monitoring</li> <li>Admin UI: Real-time management (HTMX + Tailwind)</li> <li>Tool Wrapping: REST / CLI / local functions with JSON-Schema validation</li> <li>Security: JWT + Basic Auth, custom headers, rate limits, SSL control</li> <li>Caching &amp; Observability: Redis/in-memory/database caching, metrics, structured logs</li> <li>Virtual Servers: Group tools/resources/prompts into MCP-compliant servers</li> <li>Wrapper Mode: <code>mcpgateway-wrapper</code> turns any remote gateway into a local stdio MCP server</li> </ul> <p>For upcoming capabilities, see the Roadmap.</p> <pre><code>graph TD\n    subgraph UI_and_Auth\n        UI[\ud83d\udda5\ufe0f Admin UI]\n        Auth[\ud83d\udd10 Auth - JWT and Basic]\n        UI --&gt; Core\n        Auth --&gt; Core\n    end\n\n    subgraph Gateway_Core\n        Core[\ud83d\udeaa MCP Gateway Core]\n        Protocol[\ud83d\udce1 Protocol - Init Ping Completion]\n        Federation[\ud83c\udf10 Federation Manager]\n        Transports[\ud83d\udd00 Transports - HTTP WS SSE Stdio]\n        Core --&gt; Protocol\n        Core --&gt; Federation\n        Core --&gt; Transports\n    end\n\n    subgraph Services\n        Tools[\ud83e\uddf0 Tool Service]\n        Resources[\ud83d\udcc1 Resource Service]\n        Prompts[\ud83d\udcdd Prompt Service]\n        Servers[\ud83e\udde9 Server Service]\n        Core --&gt; Tools\n        Core --&gt; Resources\n        Core --&gt; Prompts\n        Core --&gt; Servers\n    end\n\n    subgraph Persistence\n        DB[\ud83d\udcbe Database - SQLAlchemy]\n        Tools --&gt; DB\n        Resources --&gt; DB\n        Prompts --&gt; DB\n        Servers --&gt; DB\n    end\n\n    subgraph Caching\n        Cache[\u26a1 Cache - Redis or Memory]\n        Core --&gt; Cache\n    end</code></pre>"},{"location":"#audience","title":"Audience","text":"<p>MCP Gateway serves:</p> <ul> <li>AI Platform Teams building unified gateways for LLM tools &amp; services</li> <li>DevOps Engineers deploying secure, observable, federated control planes</li> <li>Open-source contributors extending MCP tooling or adapters</li> <li>Cloud Architects running on Kubernetes, IBM Code Engine, AWS, Azure, or bare Docker</li> </ul>"},{"location":"#installation-deployment","title":"Installation &amp; Deployment","text":"Scenario One-liner / CLI Snippet Docs Local (PyPI) <code>pip install mcp-contextforge-gateway &amp;&amp; mcpgateway --host 0.0.0.0 --port 4444</code> Quick Start Docker / Podman <code>docker run -p 4444:4444 ghcr.io/ibm/mcp-context-forge:&lt;tag&gt;</code> Containers Docker-Compose (dev) <code>docker compose up</code> Compose Helm / Vanilla Kubernetes <code>helm repo add mcpgw https://IBM.github.io/mcp-context-forge &amp;&amp; helm install mcpgw mcpgw/mcpgateway</code> Helm Chart Minikube (local k8s) <code>make minikube</code> Minikube Guide OpenShift / OKD <code>oc apply -k openshift/</code> OpenShift Argo CD / GitOps <code>kubectl apply -f argo.yaml</code> Argo CD IBM Cloud - Code Engine <code>ibmcloud ce app create --name mcpgw --image ghcr.io/ibm/mcp-context-forge:&lt;tag&gt;</code> IBM Code Engine AWS - ECS (Fargate) <code>aws ecs create-service --cli-input-json file://ecs.json</code> AWS Guide AWS - EKS (Helm) <code>helm install mcpgw mcpgw/mcpgateway</code> AWS Guide Google Cloud Run <code>gcloud run deploy mcpgw --image ghcr.io/ibm/mcp-context-forge:&lt;tag&gt;</code> GCP Cloud Run Google GKE (Helm) <code>helm install mcpgw mcpgw/mcpgateway</code> GCP Guide Azure - Container Apps <code>az containerapp up --name mcpgw --image ghcr.io/ibm/mcp-context-forge:&lt;tag&gt;</code> Azure Guide Azure - AKS (Helm) <code>helm install mcpgw mcpgw/mcpgateway</code> Azure Guide <p>PyPI Package: <code>mcp-contextforge-gateway</code></p> <p>OCI Image: <code>ghcr.io/ibm/mcp-context-forge:0.3.0</code></p>"},{"location":"#get-started","title":"Get Started","text":"<p>Jump straight to:</p> <ul> <li>Quick Start Guide</li> <li>Features Overview</li> <li>Admin UI Walk-through</li> <li>Using the <code>mcpgateway-wrapper</code></li> <li>Deployment Options</li> </ul> <p>Note</p> <p>Source \u2192 IBM/mcp-context-forge</p> <p>Docs \u2192 https://ibm.github.io/mcp-context-forge/</p>"},{"location":"#authors-and-contributors","title":"Authors and Contributors","text":"<ul> <li>Mihai Criveti - IBM Distinguished Engineer, Agentic AI</li> </ul>"},{"location":"architecture/","title":"Architecture Overview","text":"<p>The MCP Gateway acts as a unified entry point for tools, resources, prompts, and servers, federating local and remote nodes into a coherent MCP-compliant interface.</p> <p>This gateway:</p> <ul> <li>Wraps REST/MCP tools and resources under JSON-RPC and streaming protocols</li> <li>Offers a pluggable backend (cache, auth, storage)</li> <li>Exposes multiple transports (HTTP, WS, SSE, StreamableHttp, stdio)</li> <li>Automatically discovers and merges federated peers</li> </ul>"},{"location":"architecture/#system-architecture","title":"System Architecture","text":"<pre><code>graph TD\n    subgraph Clients\n        ui[\"Admin UI (Browser)\"]\n        cli[\"CLI Tools\"]\n        sdk[\"SDK / Scripts\"]\n    end\n\n    subgraph Gateway\n        app[\"FastAPI App\"]\n        auth[\"Auth Middleware&lt;br/&gt;(JWT + Basic)\"]\n        router[\"Transport Router&lt;br/&gt;(HTTP / WS / SSE / STDIO)\"]\n        services[\"Service Layer&lt;br/&gt;(Tool / Resource / Prompt / Server)\"]\n        db[\"Async DB&lt;br/&gt;(SQLAlchemy + Alembic)\"]\n        cache[\"Cache Backend&lt;br/&gt;(memory / redis / db)\"]\n        metrics[\"Metrics Exporter&lt;br/&gt;(/metrics Prometheus)\"]\n    end\n\n    subgraph Federation\n        discovery[\"Discovery Service&lt;br/&gt;(DNS-SD + Static Peers)\"]\n        peers[\"Remote Gateways\"]\n    end\n\n    ui --&gt; app\n    cli --&gt; router\n    sdk --&gt; router\n    app --&gt; auth --&gt; router\n    router --&gt; services\n    services --&gt; db\n    services --&gt; cache\n    services --&gt; metrics\n    services --&gt; discovery\n    discovery --&gt; peers\n</code></pre> <p>Each service (ToolService, ResourceService, etc.) operates independently with unified auth/session/context layers.</p>"},{"location":"architecture/#adrs-and-design-decisions","title":"ADRs and Design Decisions","text":"<p>We maintain a formal set of Architecture Decision Records documenting all major design tradeoffs and rationale.</p> <p>\ud83d\udcdc See the full ADR Index \u2192</p>"},{"location":"architecture/roadmap/","title":"MCP Gateway Roadmap","text":"<p>Release Overview</p> <p>This roadmap outlines the planned development milestones for MCP Gateway, organized by release version with completion status and due dates.</p>"},{"location":"architecture/roadmap/#release-status-summary","title":"Release Status Summary","text":"Release Due Date Completion Status Description 1.6.0 06 Jan 2026 0 % Open TBD 1.5.0 23 Dec 2025 0 % Open TBD 1.4.0 09 Dec 2025 0 % Open TBD 1.3.0 25 Nov 2025 0 % Open Catalog Improvements, A2A Improvements, MCP Standard Review and Sync, Technical Debt 1.2.0 11 Nov 2025 0 % Open Catalog Enhancements, Ratings, experience and UI 1.1.0 28 Oct 2025 0 % Open Post-GA Testing, Bugfixing, Documentation, Performance and Scale 1.0.0 14 Oct 2025 0 % Open General Availability &amp; Release Candidate Hardening - stable &amp; audited 0.9.0 30 Sep 2025 8 % Open Interoperability, marketplaces &amp; advanced connectivity 0.8.0 16 Sep 2025 0 % Open Enterprise Security &amp; Policy Guardrails 0.7.0 02 Sep 2025 0 % Open Multitenancy and RBAC (Private/Team/Global catalogs), Extended Connectivity, Core Observability &amp; Starter Agents (OpenAI and A2A) 0.6.0 19 Aug 2025 0 % Open Security, Scale &amp; Smart Automation 0.5.0 05 Aug 2025 0 % Open Enterprise Operability, Auth, Configuration &amp; Observability 0.4.0 22 Jul 2025 19 % Open Bugfixes, Resilience (retry with exponential backoff), code quality and technical debt 0.3.0 08 Jul 2025 100 % Closed Annotations and multi-server tool federations 0.2.0 24 Jun 2025 100 % Closed Streamable HTTP, Infra-as-Code, Dark Mode 0.1.0 05 Jun 2025 100 % Closed Initial release"},{"location":"architecture/roadmap/#release-010-initial-release","title":"Release 0.1.0 - Initial Release","text":"<p>Release 0.1.0 - Completed (100%)</p> <p>Due: June 5, 2025 | Status: Closed Initial release with core functionality and basic deployment support.</p> \u2728 Features (3) <ul> <li>#27 - Add /ready endpoint for readiness probe</li> <li>#24 - Publish Helm chart for Kubernetes deployment</li> <li>#23 - Add VS Code Devcontainer support for instant onboarding</li> </ul> \ud83d\udc1b Bugs (3) <ul> <li>#49 - Make venv install serve fails with \"python: command not found\"</li> <li>#37 - Issues with the gateway Container Image</li> <li>#35 - Error when running in Docker Desktop for Windows</li> </ul> \ud83d\udcda Documentation (2) <ul> <li>#50 - Virtual env location is incorrect</li> <li>#30 - Deploying to Google Cloud Run</li> </ul>"},{"location":"architecture/roadmap/#release-020-streamable-http-infra-as-code-dark-mode","title":"Release 0.2.0 - Streamable HTTP, Infra-as-Code, Dark Mode","text":"<p>Release 0.2.0 - Completed (100%)</p> <p>Due: June 24, 2025 | Status: Closed Enhanced transport capabilities and improved user experience.</p> \u2728 Features (3) <ul> <li>#125 - Add Streamable HTTP MCP servers to Gateway</li> <li>#109 - Implement Streamable HTTP Transport for Client Connections to MCP Gateway</li> <li>#25 - Add \"Version and Environment Info\" tab to Admin UI</li> </ul> \ud83d\udc1b Bugs (2) <ul> <li>#85 - Internal server error comes if there is any error while adding an entry or any crud operation is happening</li> <li>#51 - Internal server running when running gunicorn after install</li> </ul> \ud83d\udcda Documentation (3) <ul> <li>#98 - Add additional information for using the mcpgateway with Claude desktop</li> <li>#71 - Documentation Over Whelming Cannot figure out the basic task of adding an MCP server</li> <li>#21 - Deploying to Fly.io</li> </ul>"},{"location":"architecture/roadmap/#release-030-annotations-and-multi-server-tool-federations","title":"Release 0.3.0 - Annotations and Multi-Server Tool Federations","text":"<p>Release 0.3.0 - Completed (100%)</p> <p>Due: July 8, 2025 | Status: Closed Focus on tool federation and server management improvements.</p> \u2728 Features (7) <ul> <li>#265 - Sample MCP Server - Go (fast-time-server)</li> <li>#159 - Add auto activation of mcp-server, when it goes up back again</li> <li>#154 - Export connection strings to various clients from UI and via API</li> <li>#135 - Dynamic UI Picker for Tool, Resource, and Prompt Associations</li> <li>#116 - Namespace Composite Key &amp; UUIDs for Tool Identity</li> <li>#100 - Add path parameter or replace value in input payload for a REST API</li> <li>#26 - Add dark mode toggle to Admin UI</li> </ul> \ud83d\udc1b Bugs (7) <ul> <li>#316 - Correctly create filelock_path: str = \"tmp/gateway_service_leader.lock\" in /tmp not current directory</li> <li>#303 - Update manager.py and admin.js removed <code>is_active</code> field - replace with separate <code>enabled</code> and <code>reachable</code> fields from migration</li> <li>#302 - Alembic configuration not packaged with pip wheel, <code>pip install . &amp;&amp; mcpgateway</code> fails on db migration</li> <li>#197 - Pytest run exposes warnings from outdated Pydantic patterns, deprecated stdlib functions</li> <li>#189 - Close button for parameter input scheme does not work</li> <li>#179 - Configurable Connection Retries for DB and Redis</li> <li>#152 - Not able to add Github Remote Server</li> <li>#132 - SBOM Generation Failure</li> <li>#131 - Documentation Generation fails due to error in Makefile's image target</li> <li>#28 - Reactivating a gateway logs warning due to 'dict' object used as Pydantic model</li> </ul> \ud83d\udcda Documentation (1) <ul> <li>#18 - Add Developer Workstation Setup Guide for Mac (Intel/ARM), Linux, and Windows</li> </ul>"},{"location":"architecture/roadmap/#release-040-bugfixes-resilience-code-quality","title":"Release 0.4.0 - Bugfixes, Resilience &amp; Code Quality","text":"<p>Release 0.4.0 - Open (19%)</p> <p>Due: July 22, 2025 | Status: Open Focus on bugfixes, resilience (retry with exponential backoff), code quality and technical debt (test coverage, linting, security scans, GitHub Actions, Makefile, Helm improvements).</p> \ud83d\udc1b Open Bugs (2) <ul> <li>#232 - Leaving Auth to None fails</li> <li>#213 - Can't use <code>STREAMABLEHTTP</code></li> </ul> \ud83d\udc1b Completed Bugs (2) <ul> <li>#340 - Add input validation for main API endpoints (depends on #339 /admin API validation)</li> <li>#339 - Add input validation for /admin endpoints</li> </ul> \u2728 Open Features (4) <ul> <li>#323 - [Docs]: Add Developer Guide for using fast-time-server via JSON-RPC commands using curl or stdio</li> <li>#320 - [Feature Request]: Update Streamable HTTP to fully support Virtual Servers</li> <li>#258 - Universal Client Retry Mechanisms with Exponential Backoff &amp; Random Jitter</li> <li>#234 - \ud83e\udde0 Protocol Feature - Elicitation Support (MCP 2025-06-18)</li> <li>#233 - Contextual Hover-Help Tooltips in UI</li> <li>#217 - Graceful-Shutdown Hooks for API &amp; Worker Containers (SIGTERM-safe rollouts, DB-pool cleanup, zero-drop traffic)</li> <li>#172 - Enable Auto Refresh and Reconnection for MCP Servers in Gateways</li> </ul> \u2728 Completed Features (2) <ul> <li>#181 - Test MCP Server Connectivity Debugging Tool</li> <li>#177 - Persistent Admin UI Filter State</li> </ul> \ud83d\udd27 Open Chores (23) <ul> <li>#351 - Checklist for complete End-to-End Validation Testing for All API Endpoints, UI and Data Validation</li> <li>#344 - Implement additional security headers and CORS configuration</li> <li>#342 - Implement database-level security constraints and SQL injection prevention</li> <li>#341 - Enhance UI security with DOMPurify and content sanitization</li> <li>#317 - [CHORE]: Script to add relative file path header to each file and verify top level docstring</li> <li>#315 - [CHORE] Check SPDX headers Makefile and GitHub Actions target - ensure all files have File, Author(s) and SPDX headers</li> <li>#312 - [CHORE]: End-to-End MCP Gateway Stack Testing Harness (mcpgateway, translate, wrapper, mcp-servers)</li> <li>#307 - [CHORE]: GitHub Actions to build docs, with diagrams and test report, and deploy to GitHub Pages using MkDocs on every push to main</li> <li>#305 - [CHORE]: Add vulture (dead code detect) and unimport (unused import detect) to Makefile and GitHub Actions</li> <li>#292 - [CHORE]: Enable AI Alliance Analytics Stack Integration</li> <li>#281 - [CHORE]: Set up contract testing with Pact (pact-python) including Makefile and GitHub Actions targets</li> <li>#280 - [CHORE]: Add mutation testing with mutmut for test quality validation</li> <li>#279 - [CHORE]: Implement security audit and vulnerability scanning with grype in Makefile and GitHub Actions</li> <li>#261 - [CHORE]: Implement 90% Test Coverage Quality Gate and automatic badge and coverage html / markdown report publication</li> <li>#260 - [CHORE]: Manual security testing plan and template for release validation and production deployments</li> <li>#259 - [CHORE]: SAST (Semgrep) and DAST (OWASP ZAP) automated security testing Makefile targets and GitHub Actions</li> <li>#256 - [CHORE]: Implement comprehensive fuzz testing automation and Makefile targets (hypothesis, atheris, schemathesis , RESTler)</li> <li>#255 - [CHORE]: Implement comprehensive Playwright test automation for the entire MCP Gateway Admin UI with Makefile targets and GitHub Actions</li> <li>#254 - [CHORE]: Async Code Testing and Performance Profiling Makefile targets (flake8-async, cprofile, snakeviz, aiomonitor)</li> <li>#253 - [CHORE]: Implement chaos engineering tests for fault tolerance validation (network partitions, service failures)</li> <li>#252 - [CHORE]: Establish database migration testing pipeline with rollback validation across SQLite, Postgres, and Redis</li> <li>#251 - [CHORE]: Automatic performance testing and tracking for every build (hey) including SQLite and Postgres / Redis configurations</li> <li>#250 - [CHORE]: Implement automatic API documentation generation using mkdocstrings and update Makefile</li> <li>#249 - [CHORE]: Achieve 100% doctest coverage and add Makefile and CI/CD targets for doctest and coverage</li> <li>#223 - [CHORE]: Helm Chart Test Harness &amp; Red Hat chart-verifier</li> <li>#222 - [CHORE]: Helm chart build Makefile with lint and values.schema.json validation + CODEOWNERS, CHANGELOG.md, .helmignore and CONTRIBUTING.md</li> <li>#216 - [CHORE]: Add spec-validation targets and make the OpenAPI build go green</li> <li>#212 - [CHORE]: Achieve zero flagged Bandit / SonarQube issues</li> <li>#211 - [CHORE]: Achieve Zero Static-Type Errors Across All Checkers (mypy, ty, pyright, pyrefly)</li> <li>#210 - [CHORE]: Raise pylint from 9.16/10 -&gt; 10/10</li> </ul> \ud83d\udd27 Completed Chores (2) <ul> <li>#338 - Eliminate all lint issues in web stack</li> <li>#336 - Implement output escaping for user data in UI</li> </ul> \ud83d\udcda Open Documentation (2) <ul> <li>#94 - [Feature Request]: Transport-Translation Bridge (<code>mcpgateway.translate</code>) any to any protocol conversion cli tool</li> <li>#46 - [Docs]: Add documentation for using mcp-cli with MCP Gateway</li> <li>#19 - [Docs]: Add Developer Guide for using MCP via the CLI (curl commands, JSON-RPC)</li> </ul>"},{"location":"architecture/roadmap/#release-050-enterprise-operability-auth-configuration-observability","title":"Release 0.5.0 - Enterprise Operability, Auth, Configuration &amp; Observability","text":"<p>Release 0.5.0 - Open (0%)</p> <p>Due: August 5, 2025 | Status: Open Enterprise-grade authentication, configuration management, and comprehensive observability.</p> \u2728 Open Features (13) <ul> <li>#284 - [Feature Request]: LDAP / Active-Directory Integration</li> <li>#278 - [Feature Request]: Authentication &amp; Authorization - Google SSO Integration Tutorial (Depends on #220)</li> <li>#277 - [Feature Request]: Authentication &amp; Authorization - GitHub SSO Integration Tutorial (Depends on #220)</li> <li>#272 - [Feature Request]: Observability - Pre-built Grafana Dashboards &amp; Loki Log Export</li> <li>#220 - [Feature Request]: Authentication &amp; Authorization - SSO + Identity-Provider Integration</li> <li>#218 - [Feature Request]: Prometheus Metrics Instrumentation using prometheus-fastapi-instrumentator</li> <li>#186 - [Feature Request]: Granular Configuration Export &amp; Import (via UI &amp; API)</li> <li>#185 - [Feature Request]: Portable Configuration Export &amp; Import CLI (registry, virtual servers and prompts)</li> <li>#138 - [Feature Request]: View &amp; Export Logs from Admin UI</li> <li>#137 - [Feature Request]: Track Creator &amp; Timestamp Metadata for Servers, Tools, and Resources</li> <li>#136 - [Feature Request]: Downloadable JSON Client Config Generator from Admin UI</li> <li>#87 - [Feature Request]: Epic: JWT Token Catalog with Per-User Expiry and Revocation</li> <li>#80 - [Feature Request]: Publish a multi-architecture container (including ARM64) support</li> </ul>"},{"location":"architecture/roadmap/#release-060-security-scale-smart-automation","title":"Release 0.6.0 - Security, Scale &amp; Smart Automation","text":"<p>Release 0.6.0 - Open (0%)</p> <p>Due: August 19, 2025 | Status: Open Advanced security features, scalability improvements, and intelligent automation capabilities.</p> \u2728 Open Features (10) <ul> <li>#301 - [Feature Request]: Full Circuit Breakers for Unstable MCP Server Backends support (extend existing healthchecks with half-open state)</li> <li>#289 - [Feature Request]: Multi-Layer Caching System (Memory + Redis)</li> <li>#287 - [Feature Request]: API Path Versioning /v1 and /experimental prefix</li> <li>#286 - [Feature Request]: Dynamic Configuration UI &amp; Admin API (store config in database after db init)</li> <li>#282 - [Feature Request]: Per-Virtual-Server API Keys with Scoped Access</li> <li>#276 - [Feature Request]: Terraform Module - \"mcp-gateway-ibm-cloud\" supporting IKS, ROKS, Code Engine targets</li> <li>#275 - [Feature Request]: Terraform Module - \"mcp-gateway-gcp\" supporting GKE and Cloud Run</li> <li>#274 - [Feature Request]: Terraform Module - \"mcp-gateway-azure\" supporting AKS and ACA</li> <li>#273 - [Feature Request]: Terraform Module - \"mcp-gateway-aws\" supporting both EKS and ECS Fargate targets</li> <li>#208 - [Feature Request]: HTTP Header Passthrough</li> </ul> \ud83d\udd27 Open Chores (1) <ul> <li>#313 - [DESIGN]: Architecture Decisions and Discussions for AI Middleware and Plugin Framework (Enables #319)</li> </ul>"},{"location":"architecture/roadmap/#release-070-multitenancy-and-rbac","title":"Release 0.7.0 - Multitenancy and RBAC","text":"<p>Release 0.7.0 - Open (0%)</p> <p>Due: September 2, 2025 | Status: Open Multitenancy and RBAC (Private/Team/Global catalogs), Extended Connectivity, Core Observability &amp; Starter Agents (OpenAI and A2A).</p> \u2728 Open Features (7) <ul> <li>#300 - [Feature Request]: Structured JSON Logging with Correlation IDs</li> <li>#283 - [Feature Request]: Role-Based Access Control (RBAC) - User/Team/Global Scopes for full multi-tenancy support</li> <li>#270 - [Feature Request]: MCP Server - Go Implementation (\"libreoffice-server\")</li> <li>#269 - [Feature Request]: MCP Server - Go Implementation (LaTeX Service)</li> <li>#263 - [Feature Request]: Sample Agent - CrewAI Integration (OpenAI &amp; A2A Endpoints)</li> <li>#262 - [Feature Request]: Sample Agent - LangChain Integration (OpenAI &amp; A2A Endpoints)</li> <li>#175 - [Feature Request]: Add OpenLLMetry Integration for Observability</li> </ul>"},{"location":"architecture/roadmap/#release-080-enterprise-security-policy-guardrails","title":"Release 0.8.0 - Enterprise Security &amp; Policy Guardrails","text":"<p>Release 0.8.0 - Open (0%)</p> <p>Due: September 16, 2025 | Status: Open Comprehensive enterprise security features and policy enforcement mechanisms.</p> \u2728 Open Features (8) <ul> <li>#319 - [Feature Request]: AI Middleware Integration / Plugin Framework for extensible gateway capabilities</li> <li>#285 - [Feature Request]: Configuration Validation &amp; Schema Enforcement using Pydantic V2 models, config validator cli flag</li> <li>#271 - [Feature Request]: Policy-as-Code Engine - Rego Prototype</li> <li>#257 - [Feature Request]: Gateway-Level Rate Limiting, DDoS Protection &amp; Abuse Detection</li> <li>#230 - [Feature Request]: Cryptographic Request &amp; Response Signing</li> <li>#229 - [Feature Request]: Guardrails - Input/Output Sanitization &amp; PII Masking</li> <li>#221 - [Feature Request]: Gateway-Level Input Validation &amp; Output Sanitization (prevent traversal)</li> <li>#182 - [Feature Request]: Semantic tool auto-filtering</li> </ul> \ud83d\udd27 Open Chores (1) <ul> <li>#291 - [CHORE]: Comprehensive Scalability &amp; Soak-Test Harness (Long-term Stability &amp; Load) - locust, pytest-benchmark, smocker mocked MCP servers</li> </ul>"},{"location":"architecture/roadmap/#release-090-interoperability-marketplaces-advanced-connectivity","title":"Release 0.9.0 - Interoperability, Marketplaces &amp; Advanced Connectivity","text":"<p>Release 0.9.0 - Open (8%)</p> <p>Due: September 30, 2025 | Status: Open Enhanced interoperability, marketplace features, and advanced connectivity options.</p> \u2728 Open Features (11) <ul> <li>#298 - [Feature Request]: A2A Initial Support - Add A2A Servers as Tools</li> <li>#295 - [Feature Request]: MCP Server Marketplace</li> <li>#294 - [Feature Request]: Automated MCP Server Testing and Certification</li> <li>#288 - [Feature Request]: MariaDB Support Testing, Documentation, CI/CD (alongside PostgreSQL &amp; SQLite)</li> <li>#268 - [Feature Request]: Sample MCP Server - Haskell Implementation (\"pandoc-server\") (html, docx, pptx, latex conversion)</li> <li>#267 - [Feature Request]: Sample MCP Server - Java Implementation (\"plantuml-server\")</li> <li>#266 - [Feature Request]: Sample MCP Server - Rust Implementation (\"filesystem-server\")</li> <li>#209 - [Feature Request]: Anthropic Desktop Extensions DTX directory/marketplace</li> <li>#130 - [Feature Request]: Dynamic LLM-Powered Tool Generation via Prompt</li> <li>#123 - [Feature Request]: Dynamic Server Catalog via Rule, Regexp, Tags - or LLM-Based Selection</li> <li>#114 - [Feature Request]: Connect to Dockerized MCP Servers via STDIO</li> </ul> \ud83d\udd27 Open Chores (1) <ul> <li>#290 - [CHORE]: Enhance Gateway Tuning Guide with PostgreSQL Deep-Dive</li> </ul> \u2728 Completed Features (1) <ul> <li>#243 - [Feature Request]: a2a compatibility?</li> </ul>"},{"location":"architecture/roadmap/#release-100-general-availability-release-candidate-hardening","title":"Release 1.0.0 - General Availability &amp; Release Candidate Hardening","text":"<p>Release 1.0.0 - Open (0%)</p> <p>Due: October 14, 2025 | Status: Open Stable and audited release for general availability.</p> \ud83d\udcda Open Documentation (1) <ul> <li>#264 - [DOCS]: GA Documentation Review &amp; End-to-End Validation Audit</li> </ul>"},{"location":"architecture/roadmap/#release-110-post-ga-testing-bugfixing-documentation-performance-and-scale","title":"Release 1.1.0 - Post-GA Testing, Bugfixing, Documentation, Performance and Scale","text":"<p>Release 1.1.0 - Open (0%)</p> <p>Due: October 28, 2025 | Status: Open Post-launch improvements and performance optimizations.</p> \u2728 Open Features (1) <ul> <li>#293 - [Feature Request]: Intelligent Load Balancing for Redundant MCP Servers</li> </ul>"},{"location":"architecture/roadmap/#release-120-catalog-enhancements-ratings-experience-and-ui","title":"Release 1.2.0 - Catalog Enhancements, Ratings, Experience and UI","text":"<p>Release 1.2.0 - Open (0%)</p> <p>Due: November 11, 2025 | Status: Open Enhanced catalog features and improved user experience.</p> \u2728 Open Features (1) <ul> <li>#296 - [Feature Request]: MCP Server Rating and Review System</li> </ul>"},{"location":"architecture/roadmap/#release-130-catalog-improvements-a2a-improvements-mcp-standard-review-and-sync-technical-debt","title":"Release 1.3.0 - Catalog Improvements, A2A Improvements, MCP Standard Review and Sync, Technical Debt","text":"<p>Release 1.3.0 - Open (0%)</p> <p>Due: November 25, 2025 | Status: Open Catalog improvements, A2A enhancements, and technical debt resolution.</p> \u2728 Open Features (1) <ul> <li>#299 - [Feature Request]: A2A Ecosystem Integration &amp; Marketplace (Extends A2A support)</li> </ul>"},{"location":"architecture/roadmap/#release-140","title":"Release 1.4.0","text":"<p>Release 1.4.0 - Open (0%)</p> <p>Due: December 9, 2025 | Status: Open TBD</p> <p>No issues currently assigned to this release.</p>"},{"location":"architecture/roadmap/#release-150","title":"Release 1.5.0","text":"<p>Release 1.5.0 - Open (0%)</p> <p>Due: December 23, 2025 | Status: Open TBD</p> <p>No issues currently assigned to this release.</p>"},{"location":"architecture/roadmap/#release-160","title":"Release 1.6.0","text":"<p>Release 1.6.0 - Open (0%)</p> <p>Due: January 6, 2026 | Status: Open TBD</p> <p>No issues currently assigned to this release.</p>"},{"location":"architecture/roadmap/#unassigned-issues","title":"Unassigned Issues","text":"<p>Issues Without Release Assignment</p> <p>The following issues are currently open but not assigned to any specific release:</p> \ud83d\udc1b Open Bugs (1) <ul> <li>#352 - Resources - All data going into content</li> </ul> \ud83d\udd27 Open Chores (1) <ul> <li>#318 - [CHORE]: Publish Agents and Tools that leverage codebase and templates (draft)</li> </ul> \ud83d\udcda Open Documentation (1) <ul> <li>#22 - [Docs]: Add BeeAI Framework client integration (Python &amp; TypeScript)</li> </ul>"},{"location":"architecture/roadmap/#recently-closed-issues","title":"Recently Closed Issues","text":"<p>Recently Completed</p> <p>The following issues have been recently closed:</p> \u2728 Completed Features (1) <ul> <li>#306 - [Bug]: Quick Start (manual install) gunicorn fails</li> </ul>"},{"location":"architecture/roadmap/#legend","title":"Legend","text":"<ul> <li>\u2728 Feature Request - New functionality or enhancement</li> <li>\ud83d\udc1b Bug - Issues that need to be fixed</li> <li>\ud83d\udd27 Chore - Maintenance, tooling, or infrastructure work</li> <li>\ud83d\udcda Documentation - Documentation improvements or additions</li> </ul> <p>Contributing</p> <p>Want to contribute to any of these features? Check out the individual GitHub issues for more details and discussion!</p>"},{"location":"architecture/roadmap/#pending-issue-creation","title":"Pending Issue Creation","text":""},{"location":"architecture/roadmap/#lifecycle-management","title":"\u2699\ufe0f Lifecycle &amp; Management","text":"<ol> <li> <p>Virtual Server Protocol Version Selection - Allow choosing which MCP protocol version each virtual server uses dynamically (mentioned as possible through ENV variables but should be dynamic)</p> </li> <li> <p>CLI Enhancements for Admin Operations - CLI subcommands for registering tools, flushing caches, exporting configs for CI/CD integration</p> </li> <li> <p>Cache Management API - Endpoints to view cache stats and clear entries for data freshness management</p> </li> </ol>"},{"location":"architecture/roadmap/#developer-experience","title":"\ud83d\udee0\ufe0f Developer Experience","text":"<ol> <li> <p>Prompt Template Tester &amp; Validator - Preview and validate Jinja2 templates with sample data to avoid runtime errors</p> </li> <li> <p>System Diagnostics &amp; Self-Check Report - Self-contained system report (config, health, metrics) for troubleshooting</p> </li> <li> <p>Auto-Tuning of Timeout &amp; Retry Policies - Automatically adjust timeouts and retry intervals based on observed latencies</p> </li> <li> <p>Chrome MCP Plugin Integration - Browser extension for managing MCP configurations, servers, and connections</p> </li> </ol>"},{"location":"architecture/roadmap/#secrets-sensitive-data","title":"\ud83d\udd10 Secrets &amp; Sensitive Data","text":"<ol> <li>Secure Secrets Management &amp; Masking - External secrets store integration (Vault)</li> </ol>"},{"location":"architecture/adr/","title":"Architecture Decision Records","text":"<p>This page tracks all significant design decisions made for the MCP Gateway project, using the ADR format.</p> ID Title Status Section Date 0001 Adopt FastAPI + Pydantic Accepted Framework 2025-02-01 0002 Use Async SQLAlchemy ORM Accepted Persistence 2025-02-01 0003 Expose Multi-Transport Endpoints Accepted Transport 2025-02-01 0004 Combine JWT &amp; Basic Auth Accepted Security 2025-02-01 0005 Structured JSON Logging Accepted Observability 2025-02-21 0006 Gateway &amp; Tool-Level Rate Limiting Accepted Performance 2025-02-21 0007 Pluggable Cache Backend (memory / Redis / DB) Accepted Caching 2025-02-21 0008 Federation &amp; Auto-Discovery via DNS-SD Accepted Federation 2025-02-21 0009 Built-in Health Checks &amp; Self-Monitoring Accepted Operations 2025-02-21 0010 Observability via Prometheus, Structured Logs Accepted Observability 2025-02-21 <p>\u2733\ufe0f Add new decisions chronologically and link to them from this table.</p>"},{"location":"architecture/adr/001-adopt-fastapi-pydantic/","title":"ADR-0001: Adopt FastAPI + Pydantic","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-01</li> <li>Deciders: Mihai Criveti</li> </ul>"},{"location":"architecture/adr/001-adopt-fastapi-pydantic/#context","title":"Context","text":"<p>The MCP Gateway must serve both human and machine clients with low-latency HTTP and WebSocket endpoints. Payloads require runtime validation and schema documentation, while internal data types must align with environment-driven settings and JSON models.</p> <p>We explored Python-native frameworks that support async-first operation, data validation, OpenAPI generation, and modular service layout.</p>"},{"location":"architecture/adr/001-adopt-fastapi-pydantic/#decision","title":"Decision","text":"<p>We will adopt:</p> <ul> <li>FastAPI as the core web framework for routing HTTP, WebSocket, and streaming endpoints.</li> <li>Pydantic v2 for all settings, schemas, and typed data models (e.g., <code>Tool</code>, <code>Resource</code>, <code>GatewayMetadata</code>, etc.).</li> </ul> <p>These will form the foundation for the application layer and public API.</p>"},{"location":"architecture/adr/001-adopt-fastapi-pydantic/#consequences","title":"Consequences","text":"<ul> <li>\u2728 Strong typing, runtime validation, and auto-generated OpenAPI specs.</li> <li>\ud83e\udde9 Unified model structure across internal logic, external APIs, and config parsing.</li> <li>\ud83d\ude80 Excellent async performance with Uvicorn and Starlette compatibility.</li> <li>\ud83d\udd12 Tight coupling to Pydantic means future transitions (e.g., to dataclasses or attrs) would be non-trivial.</li> </ul>"},{"location":"architecture/adr/001-adopt-fastapi-pydantic/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not Flask + Marshmallow Sync-first architecture, weak async support, manual OpenAPI generation. Django REST Framework Heavyweight, monolithic, tightly bound to Django ORM, not async-native. Tornado or Starlette alone More boilerplate to assemble middlewares, validators, and routing. Node.js + Fastify Excellent performance but requires a split language/runtime and loss of shared model code. Pure <code>httpx</code> + <code>uvicorn</code> + <code>pydantic-core</code> Too low-level; duplicating FastAPI features manually."},{"location":"architecture/adr/001-adopt-fastapi-pydantic/#status","title":"Status","text":"<p>This decision has been implemented in the current architecture.</p>"},{"location":"architecture/adr/002-use-async-sqlalchemy-orm/","title":"ADR-0002: Use Async SQLAlchemy ORM","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-01</li> <li>Deciders: Mihai Criveti</li> </ul>"},{"location":"architecture/adr/002-use-async-sqlalchemy-orm/#context","title":"Context","text":"<p>The gateway must persist:</p> <ul> <li>Tool metadata</li> <li>Resource configurations</li> <li>Usage metrics</li> <li>Peer discovery and federation state</li> </ul> <p>We require a relational database with schema evolution, strong typing, and async support. The current codebase already uses SQLAlchemy ORM models with an async engine and declarative mapping style.</p>"},{"location":"architecture/adr/002-use-async-sqlalchemy-orm/#decision","title":"Decision","text":"<p>We will use:</p> <ul> <li>SQLAlchemy 2.x (async) for all data persistence.</li> <li>AsyncSession and <code>async with</code> scoped transactions.</li> <li>Alembic for migrations, with autogeneration and CLI support.</li> <li>SQLite for development; PostgreSQL or MySQL for production via <code>DATABASE_URL</code>.</li> </ul> <p>This provides consistent, well-understood relational behavior and integrates cleanly with FastAPI.</p>"},{"location":"architecture/adr/002-use-async-sqlalchemy-orm/#consequences","title":"Consequences","text":"<ul> <li>\ud83e\uddf1 Mature and reliable ORM with a wide developer base.</li> <li>\ud83d\udd04 Fully async I/O stack without thread-pools or blocking.</li> <li>\ud83d\udd27 Migrations handled declaratively using Alembic.</li> <li>\ud83d\udcc4 Pydantic models can be derived from or synchronized with SQLAlchemy models if needed.</li> </ul>"},{"location":"architecture/adr/002-use-async-sqlalchemy-orm/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not Raw asyncpg / aiosqlite Manual query strings, error-prone joins, no built-in migrations. Tortoise ORM / GINO Less widely used, more magic, lower confidence in long-term maintainability. Django ORM Not async-native, tightly coupled to Django ecosystem, too heavyweight. NoSQL (e.g., MongoDB) No relational guarantees, weaker query language, major refactor from current SQL-based model."},{"location":"architecture/adr/002-use-async-sqlalchemy-orm/#status","title":"Status","text":"<p>This decision is in place and all gateway persistence uses SQLAlchemy 2.x with async support.</p>"},{"location":"architecture/adr/003-expose-multi-transport-endpoints/","title":"ADR-0003: Expose Multi-Transport Endpoints (HTTP / WebSocket / SSE / STDIO)","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-01</li> <li>Deciders: Mihai Criveti</li> </ul>"},{"location":"architecture/adr/003-expose-multi-transport-endpoints/#context","title":"Context","text":"<p>The MCP Gateway must serve diverse clients: web browsers, CLIs, language-specific SDKs, and headless daemons. Different use cases require support for both request/response and streaming interactions.</p> <p>Requirements:</p> <ul> <li>Human-readable RPC over HTTP for developers</li> <li>Low-latency streaming for long-running tools</li> <li>IPC-style invocations for local CLI integration</li> <li>Unified business logic regardless of transport</li> </ul>"},{"location":"architecture/adr/003-expose-multi-transport-endpoints/#decision","title":"Decision","text":"<p>The gateway will support the following built-in transports:</p> <ul> <li>HTTP JSON-RPC (primary RPC interface)</li> <li>WebSocket (bidirectional messaging)</li> <li>SSE (Server-Sent Events) (for push-only event streaming)</li> <li>Streamable HTTP  (bidirectional, resumable streams, efficient MCP transport over HTTP)</li> <li>STDIO (optional local CLI / subprocess transport)</li> </ul> <p>Transport selection is dynamic, based on environment (<code>TRANSPORT_TYPE</code>) and route grouping. All transports share the same service layer and authentication mechanisms.</p>"},{"location":"architecture/adr/003-expose-multi-transport-endpoints/#consequences","title":"Consequences","text":"<ul> <li>\u2705 Maximum client flexibility, supporting modern browsers and legacy CLI tools.</li> <li>\ud83d\udd04 Business logic remains decoupled from transport implementation.</li> <li>\ud83d\udcf6 Streaming transports (WS, SSE) require timeout, reconnection, and back-pressure handling. Easy expansion with new MCP standards</li> </ul>"},{"location":"architecture/adr/003-expose-multi-transport-endpoints/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not HTTP-only JSON API Poor fit for long-lived streaming tasks; requires polling. gRPC (HTTP/2) Not browser-friendly; requires generated stubs; less discoverable. Separate microservices per transport Code duplication, diverging implementations, and operational complexity. Single transport abstraction Reduces explicitness; transport-specific needs get buried in generic interfaces."},{"location":"architecture/adr/003-expose-multi-transport-endpoints/#status","title":"Status","text":"<p>All four transports are implemented in the current FastAPI application and are toggleable via configuration.</p>"},{"location":"architecture/adr/004-combine-jwt-and-basic-auth/","title":"ADR-0004: Combine JWT &amp; Basic Auth","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-01</li> <li>Deciders: Core Engineering Team</li> </ul>"},{"location":"architecture/adr/004-combine-jwt-and-basic-auth/#context","title":"Context","text":"<p>The gateway needs to support two types of clients:</p> <ul> <li>Browser-based users using the Admin UI</li> <li>Headless clients such as scripts, services, and tools</li> </ul> <p>These use cases require different authentication workflows:</p> <ul> <li>Browsers prefer form-based login and session cookies.</li> <li>Automation prefers stateless, token-based access.</li> </ul> <p>The current config exposes both:</p> <ul> <li><code>BASIC_AUTH_USER</code> and <code>BASIC_AUTH_PASSWORD</code></li> <li><code>JWT_SECRET_KEY</code>, <code>JWT_EXPIRY_SECONDS</code>, and cookie settings</li> </ul>"},{"location":"architecture/adr/004-combine-jwt-and-basic-auth/#decision","title":"Decision","text":"<p>We will combine both authentication modes as follows:</p> <ul> <li>Basic Auth secures access to <code>/admin</code>. Upon success, a short-lived JWT cookie is issued.</li> <li>JWT Bearer token (via header or cookie) is required for all API, WebSocket, and SSE requests.</li> <li>Tokens are signed using the shared <code>JWT_SECRET_KEY</code> and include standard claims (sub, exp, scopes).</li> <li>When <code>AUTH_REQUIRED=false</code>, the gateway allows unauthenticated access (dev only).</li> </ul>"},{"location":"architecture/adr/004-combine-jwt-and-basic-auth/#consequences","title":"Consequences","text":"<ul> <li>\u2705 Developers can log in once via browser and obtain an authenticated session.</li> <li>\u2705 Scripts can use a generated JWT directly, with no credential storage.</li> <li>\u274c Tokens must be signed, rotated, and verified securely (TLS required).</li> <li>\ud83d\udd04 JWTs expire and must be refreshed periodically by clients.</li> </ul>"},{"location":"architecture/adr/004-combine-jwt-and-basic-auth/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not JWT only CLI tools need a pre-acquired token; not friendly for interactive login. Basic only Password sent on every request; cannot easily revoke or expire credentials. OAuth2 / OpenID Connect Too complex for self-hosted setups; requires external identity provider. mTLS client auth Secure but heavy; not usable in browsers or simple HTTP clients."},{"location":"architecture/adr/004-combine-jwt-and-basic-auth/#status","title":"Status","text":"<p>This combined authentication mechanism is implemented and enabled by default in the gateway.</p>"},{"location":"architecture/adr/005-structured-json-logging/","title":"ADR-0005: Structured JSON Logging","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-21</li> <li>Deciders: Core Engineering Team</li> </ul>"},{"location":"architecture/adr/005-structured-json-logging/#context","title":"Context","text":"<p>The gateway must emit logs that:</p> <ul> <li>Are machine-readable and parseable by tools like ELK, Loki, or Datadog</li> <li>Include rich context (e.g., request ID, auth user, duration)</li> <li>Can be viewed in plaintext locally and JSON in production</li> </ul> <p>Our configuration supports:</p> <ul> <li><code>LOG_FORMAT</code>: <code>json</code> or <code>plain</code></li> <li><code>LOG_LEVEL</code>: standard Python levels</li> <li><code>LOG_FILE</code>: optional log file destination</li> </ul> <p>Logs are initialized at startup via <code>LoggingService</code>.</p>"},{"location":"architecture/adr/005-structured-json-logging/#decision","title":"Decision","text":"<p>Use the Python standard <code>logging</code> module with:</p> <ul> <li>A custom JSON formatter for structured logs (e.g. <code>{\"level\": \"INFO\", \"msg\": ..., \"request_id\": ...}</code>)</li> <li>Plain text output when <code>LOG_FORMAT=plain</code></li> <li>Per-request context via filters or middleware</li> <li>Global setup at app startup to avoid late binding issues</li> </ul>"},{"location":"architecture/adr/005-structured-json-logging/#consequences","title":"Consequences","text":"<ul> <li>\ud83d\udccb Easily parsed logs suitable for production observability pipelines</li> <li>\u2699\ufe0f Compatible with <code>stdout</code>, file, or syslog targets</li> <li>\ud83e\uddea Local development uses plain logs for readability</li> <li>\ud83e\uddf1 Minimal dependency footprint (no third-party logging libraries)</li> </ul>"},{"location":"architecture/adr/005-structured-json-logging/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not loguru Elegant syntax, but non-standard; poor compatibility with Python ecosystem. structlog Adds context pipeline complexity; not needed for current log volume. External sidecar (e.g. Fluent Bit) Useful downstream but doesn't solve app-side structure. Raw print() statements Unstructured, difficult to manage at scale."},{"location":"architecture/adr/005-structured-json-logging/#status","title":"Status","text":"<p>Structured logging is implemented in <code>LoggingService</code>, configurable via environment variables.</p>"},{"location":"architecture/adr/005-vscode-devcontainer-support/","title":"ADR-005: VS Code Dev Container Support","text":""},{"location":"architecture/adr/005-vscode-devcontainer-support/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture/adr/005-vscode-devcontainer-support/#context","title":"Context","text":"<p>New contributors to the MCP Context Forge project face significant setup friction when trying to get a development environment running. The manual setup process requires:</p> <ul> <li>Installing Python 3.11</li> <li>Installing Docker/Podman</li> <li>Setting up virtual environments</li> <li>Installing development dependencies</li> <li>Configuring environment variables</li> <li>Running tests to verify setup</li> </ul> <p>This setup complexity can discourage contributions and slow down the onboarding process for new developers. Many contributors use VS Code or GitHub Codespaces, which support Dev Containers for standardized development environments.</p>"},{"location":"architecture/adr/005-vscode-devcontainer-support/#decision","title":"Decision","text":"<p>We will add VS Code Dev Container support to the project by implementing:</p> <ol> <li><code>.devcontainer/devcontainer.json</code> - Configuration specifying:</li> <li>Container build instructions</li> <li>VS Code extensions (Python, Docker)</li> <li>Post-creation commands</li> <li> <p>Environment variables for development mode</p> </li> <li> <p><code>.devcontainer/Dockerfile</code> - Container definition with:</p> </li> <li>Python 3.11 slim base image</li> <li>Docker CLI for container management</li> <li>System dependencies (curl, git, build-essential)</li> <li>Python tooling (pip, setuptools, pdm, uv)</li> <li> <p>Development environment setup</p> </li> <li> <p><code>.devcontainer/postCreateCommand.sh</code> - Setup script that:</p> </li> <li>Copies <code>.env.example</code> to <code>.env</code> if needed</li> <li>Runs <code>make install-dev</code> to install development dependencies</li> <li> <p>Runs <code>make test</code> to verify the environment</p> </li> <li> <p>Documentation updates - README.md section explaining:</p> </li> <li>How to use the devcontainer in VS Code</li> <li>How to use with GitHub Codespaces</li> <li>Benefits and included tools</li> </ol>"},{"location":"architecture/adr/005-vscode-devcontainer-support/#consequences","title":"Consequences","text":""},{"location":"architecture/adr/005-vscode-devcontainer-support/#positive","title":"Positive","text":"<ul> <li>Instant onboarding: New contributors can start developing immediately with one click</li> <li>Consistent environments: All developers use the same Python version, tools, and dependencies</li> <li>Reduced setup friction: No need to manually install Python, Docker, or configure environments</li> <li>GitHub Codespaces support: Cloud-based development without local setup requirements</li> <li>Automated verification: Tests run automatically to ensure the environment is working</li> <li>Standardized tooling: Everyone gets the same VS Code extensions and configuration</li> </ul>"},{"location":"architecture/adr/005-vscode-devcontainer-support/#negative","title":"Negative","text":"<ul> <li>Additional maintenance: Need to keep devcontainer configuration in sync with project requirements</li> <li>Container build time: Initial setup takes a few minutes for first-time users</li> <li>Docker dependency: Requires Docker/Podman to be installed and running</li> <li>Limited to VS Code: Only benefits developers using VS Code or Codespaces</li> </ul>"},{"location":"architecture/adr/005-vscode-devcontainer-support/#neutral","title":"Neutral","text":"<ul> <li>File size increase: Adds minimal files to the repository</li> <li>Learning curve: Developers unfamiliar with Dev Containers may need to learn the workflow</li> </ul>"},{"location":"architecture/adr/005-vscode-devcontainer-support/#alternatives-considered","title":"Alternatives Considered","text":"<ol> <li>Manual setup instructions only (current state)</li> <li>Pros: No additional complexity</li> <li> <p>Cons: High setup friction, inconsistent environments</p> </li> <li> <p>Gitpod integration</p> </li> <li>Pros: Cloud-based development</li> <li> <p>Cons: Less VS Code-native, additional external dependency</p> </li> <li> <p>Docker Compose for development</p> </li> <li>Pros: Tool-agnostic</li> <li> <p>Cons: More complex setup, less integrated with VS Code</p> </li> <li> <p>Vagrant-based development environment</p> </li> <li>Pros: Full VM isolation</li> <li>Cons: Resource-heavy, slower, less modern workflow</li> </ol>"},{"location":"architecture/adr/005-vscode-devcontainer-support/#implementation-details","title":"Implementation Details","text":"<p>The devcontainer uses: - Python 3.11: As specified in the project requirements - PDM and UV: For package management (matching the project's tooling) - Make targets: Leverages existing <code>make install-dev</code> and <code>make test</code> workflows - Environment variables: Sets <code>MCPGATEWAY_DEV_MODE=true</code> for development - VS Code extensions: Includes Python and Docker extensions for optimal development experience</p>"},{"location":"architecture/adr/005-vscode-devcontainer-support/#verification","title":"Verification","text":"<p>The implementation was tested by: 1. Building the devcontainer in VS Code 2. Verifying that development dependencies install correctly 3. Confirming that the test suite passes 4. Checking that all Make targets work properly inside the container</p>"},{"location":"architecture/adr/005-vscode-devcontainer-support/#references","title":"References","text":"<ul> <li>VS Code Dev Containers documentation</li> <li>GitHub Codespaces documentation</li> <li>Dev Container specification</li> <li>Project issue/PR requesting devcontainer support</li> </ul>"},{"location":"architecture/adr/006-gateway-tool-rate-limiting/","title":"ADR-0006: Gateway &amp; Tool-Level Rate Limiting","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-21</li> <li>Deciders: Core Engineering Team</li> </ul>"},{"location":"architecture/adr/006-gateway-tool-rate-limiting/#context","title":"Context","text":"<p>The MCP Gateway may serve hundreds of concurrent clients accessing multiple tools. Without protection, a single client or misbehaving tool could monopolize resources or overwhelm upstream services.</p> <p>The configuration includes:</p> <ul> <li><code>TOOL_RATE_LIMIT</code>: default limit in requests/min per tool/client</li> <li>Planned support for Redis-based or database-backed counters</li> </ul> <p>Current implementation is an in-memory token bucket.</p>"},{"location":"architecture/adr/006-gateway-tool-rate-limiting/#decision","title":"Decision","text":"<p>Implement a rate limiter at the tool invocation level, keyed by:</p> <ul> <li>Tool name</li> <li>Authenticated user / client identity (JWT or Basic)</li> <li>Time window (per-minute by default)</li> </ul> <p>Backend options:</p> <ul> <li>Memory (default for dev / single instance)</li> <li>Redis (planned for clustering / shared limits)</li> <li>Database (eventually consistent fallback)</li> </ul>"},{"location":"architecture/adr/006-gateway-tool-rate-limiting/#consequences","title":"Consequences","text":"<ul> <li>\u2705 Prevents abuse, controls cost, and provides predictable fairness</li> <li>\ud83d\udcc9 Failed requests return <code>429 Too Many Requests</code> with retry headers</li> <li>\u274c Memory backend does not scale across instances; Redis required for HA</li> <li>\ud83d\udd04 Optional override of limits via config/env for testing</li> </ul>"},{"location":"architecture/adr/006-gateway-tool-rate-limiting/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not No rate limiting Leaves gateway and tools vulnerable to overload or accidental DoS. Global rate limit only Heavy tools can starve lightweight tools; no fine-grained control. Proxy-level throttling (e.g. NGINX, Envoy) Can't distinguish tools or users inside payload; lacks granularity."},{"location":"architecture/adr/006-gateway-tool-rate-limiting/#status","title":"Status","text":"<p>Rate limiting is implemented for tool routes, with <code>TOOL_RATE_LIMIT</code> as the default policy.</p>"},{"location":"architecture/adr/007-pluggable-cache-backend/","title":"ADR-0007: Pluggable Cache Backend (memory / Redis / database)","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-21</li> <li>Deciders: Core Engineering Team</li> </ul>"},{"location":"architecture/adr/007-pluggable-cache-backend/#context","title":"Context","text":"<p>The MCP Gateway uses short-lived caching for:</p> <ul> <li>Tool responses and resource lookups</li> <li>Peer discovery metadata</li> <li>Temporary session state and rate-limiting</li> </ul> <p>Different deployments require different caching characteristics:</p> <ul> <li>Dev mode: no external services (in-memory only)</li> <li>Production: clustered and persistent (Redis)</li> <li>Air-gapped: embedded fallback (database table)</li> </ul> <p>The config exposes <code>CACHE_TYPE=memory|redis|database</code>.</p>"},{"location":"architecture/adr/007-pluggable-cache-backend/#decision","title":"Decision","text":"<p>Abstract the caching system via a <code>CacheBackend</code> interface and support the following pluggable backends:</p> <ul> <li><code>MemoryCacheBackend</code>: simple <code>dict</code> with TTL, for dev and unit tests</li> <li><code>RedisCacheBackend</code>: shared, centralized cache for multi-node clusters</li> <li><code>DatabaseCacheBackend</code>: uses SQLAlchemy ORM to persist TTL-based records</li> </ul> <p>Selection is driven by the <code>CACHE_TYPE</code> environment variable. Code paths use a consistent interface regardless of backend.</p>"},{"location":"architecture/adr/007-pluggable-cache-backend/#consequences","title":"Consequences","text":"<ul> <li>\ud83d\udd04 Easy to switch cache backend per environment or load profile</li> <li>\ud83d\ude80 Redis allows horizontal scaling and persistent shared state</li> <li>\u274c Memory cache does not survive restarts or share state</li> <li>\ud83d\udc22 Database cache is slower, but useful in restricted networks</li> </ul>"},{"location":"architecture/adr/007-pluggable-cache-backend/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not Hardcoded Redis Adds operational overhead and single point of failure for dev. Memory-only cache Incompatible with horizontal scale or restart resilience. External CDN or HTTP cache Doesn't address in-process sessions, discovery, or tool state. Disk-based cache (e.g., shelve, pickle) Complex invalidation and concurrency issues; not cloud-ready."},{"location":"architecture/adr/007-pluggable-cache-backend/#status","title":"Status","text":"<p>All three cache backends are implemented and the gateway selects one dynamically based on configuration.</p>"},{"location":"architecture/adr/008-federation-discovery/","title":"ADR-0008: Federation &amp; Auto-Discovery via DNS-SD","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-21</li> <li>Deciders: Core Engineering Team</li> </ul>"},{"location":"architecture/adr/008-federation-discovery/#context","title":"Context","text":"<p>The MCP Gateway must support federated operation, where multiple gateway instances:</p> <ul> <li>Automatically discover each other on a shared network</li> <li>Exchange metadata and tool/service availability</li> <li>Merge registries and route calls to remote nodes</li> </ul> <p>Manual configuration (e.g. hardcoded peer IPs) is error-prone and brittle in dynamic environments like laptops or Kubernetes.</p> <p>The codebase includes a <code>DiscoveryService</code> and federation settings such as:</p> <ul> <li><code>FEDERATION_ENABLED</code></li> <li><code>FEDERATION_DISCOVERY</code></li> <li><code>DISCOVERY_INTERVAL_SECONDS</code></li> </ul>"},{"location":"architecture/adr/008-federation-discovery/#decision","title":"Decision","text":"<p>We enable auto-discovery via DNS-SD (mDNS/zeroconf) by default. Each gateway:</p> <ul> <li>Publishes itself using <code>_mcp._tcp.local.</code> with TXT records</li> <li>Periodically probes for peers using <code>zeroconf</code> or a fallback registry</li> <li>Merges discovered gateways into its internal routing map</li> <li>Sends periodic liveness pings to verify peer health</li> </ul> <p>Static peer configuration is still supported for restricted networks.</p>"},{"location":"architecture/adr/008-federation-discovery/#consequences","title":"Consequences","text":"<ul> <li>\ud83d\udd0c Gateways connect seamlessly on the same local network or overlay mesh</li> <li>\ud83d\udd75\ufe0f\u2642\ufe0f DNS-SD adds moderate background network traffic, tunable via TTL</li> <li>\u26a0\ufe0f Firewalls or environments without multicast must use static peer config</li> <li>\u267b\ufe0f Federated topologies are self-healing and require no orchestration</li> </ul>"},{"location":"architecture/adr/008-federation-discovery/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not Static peer list only Manual entry, error-prone, not zero-config. Central registry (e.g. etcd, Consul) Adds external infrastructure and tight coordination. Cloud DNS-based discovery Requires cloud provider integration and persistent internet access. gRPC service registry Less transparent, requires protobuf tooling and internal coordination layer."},{"location":"architecture/adr/008-federation-discovery/#status","title":"Status","text":"<p>Auto-discovery is implemented using <code>zeroconf</code>, and federation is active when <code>FEDERATION_ENABLED=true</code>.</p> <p>Current feature is early pre-alpha and may not work correctly.</p>"},{"location":"architecture/adr/009-built-in-health-checks/","title":"ADR-0009: Built-in Health Checks &amp; Self-Monitoring","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-21</li> <li>Deciders: Core Engineering Team</li> </ul>"},{"location":"architecture/adr/009-built-in-health-checks/#context","title":"Context","text":"<p>MCP Gateways must participate in mesh/federated deployments. Faulty nodes must be detected and removed automatically. Additionally, cloud-native infrastructure (like Kubernetes, Docker Swarm, or systemd watchdogs) needs a way to check local health.</p> <p>The gateway config supports health-related settings:</p> <ul> <li><code>HEALTH_CHECK_INTERVAL</code>: frequency of peer checks</li> <li><code>HEALTH_CHECK_TIMEOUT</code>: request timeout per probe</li> <li><code>UNHEALTHY_THRESHOLD</code>: number of failures before a peer is marked unhealthy</li> </ul> <p>The README and architecture describe <code>/health</code> and <code>/metrics</code> endpoints as built-in features</p>"},{"location":"architecture/adr/009-built-in-health-checks/#decision","title":"Decision","text":"<p>Implement two health-check levels:</p> <ol> <li>Local health endpoint at <code>/health</code>:</li> <li>Verifies database connectivity and response time</li> <li> <p>Optionally checks cache (e.g. Redis ping or in-memory status)</p> </li> <li> <p>Federated peer liveness:</p> </li> <li>Every <code>HEALTH_CHECK_INTERVAL</code>, we ping all registered peers via HTTP</li> <li>If a peer fails <code>UNHEALTHY_THRESHOLD</code> times consecutively, it's tagged as 'Offline' i.e. The gateway is unreachable. Once its back online, it's automatically tagged as 'Active'</li> <li>A separate background task handles this (see <code>GatewayService</code>)</li> </ol> <p>Health info is also published to <code>/metrics</code> in Prometheus format.</p>"},{"location":"architecture/adr/009-built-in-health-checks/#consequences","title":"Consequences","text":"<ul> <li>\u2705 Federated topologies can eject bad nodes quickly and re-accept them later</li> <li>\u2705 Local health can be used by Kubernetes probes, HAProxy, etc.</li> <li>\ud83d\udd04 Gateways that go offline briefly won't be removed immediately (tunable)</li> <li>\ud83d\udd0d Metrics include last check time, RTT, and result status</li> </ul>"},{"location":"architecture/adr/009-built-in-health-checks/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not No health checks Delayed or no reaction to failures; requires manual debugging Rely on Kubernetes probes Only detects local process health, not remote peers External APM agent (Datadog) Complex setup, costly for small/self-hosted use cases Central heartbeat server Single point of failure, requires extra infra"},{"location":"architecture/adr/009-built-in-health-checks/#status","title":"Status","text":"<p>This is implemented as part of the <code>GatewayService</code> and exposed via <code>/health</code> and <code>/metrics</code> endpoints.</p>"},{"location":"architecture/adr/010-observability-prometheus/","title":"ADR-0010: Observability via Prometheus, Structured Logs, and Metrics","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-21</li> <li>Deciders: Core Engineering Team</li> </ul>"},{"location":"architecture/adr/010-observability-prometheus/#context","title":"Context","text":"<p>The MCP Gateway is a long-running service that executes tools, processes requests, and federates with remote peers. Operators and developers must be able to observe:</p> <ul> <li>Overall system health</li> <li>Request throughput and latency</li> <li>Tool and resource usage</li> <li>Error rates and failure patterns</li> <li>Federation behavior and peer availability</li> </ul> <p>The gateway needs to surface this without requiring external instrumentation or agents.</p>"},{"location":"architecture/adr/010-observability-prometheus/#decision","title":"Decision","text":"<p>We will implement native observability features using:</p> <ol> <li>Structured JSON logs with optional plaintext fallback:</li> <li>Controlled by <code>LOG_FORMAT=json|text</code> and <code>LOG_LEVEL</code></li> <li> <p>Includes fields: timestamp, level, logger name, request ID, route, auth user, latency</p> </li> <li> <p>Prometheus-compatible <code>/metrics</code> endpoint:</p> </li> <li>Exposes key counters and histograms: tool invocations, failures, resource loads, peer syncs, etc.</li> <li> <p>Uses plain <code>text/plain; version=0.0.4</code> exposition format</p> </li> <li> <p>Latency decorators and in-code timing for critical paths:</p> </li> <li>Completion requests</li> <li>Resource resolution</li> <li> <p>Federation sync/health probes</p> </li> <li> <p>Per-request IDs and correlation:</p> </li> <li>Middleware attaches <code>X-Request-ID</code> if present or generates a new one</li> <li>Request ID propagates through logs and errors</li> </ol>"},{"location":"architecture/adr/010-observability-prometheus/#consequences","title":"Consequences","text":"<ul> <li>\ud83d\udcca Metrics can be scraped by Prometheus and visualized in Grafana</li> <li>\ud83d\udd0d Developers can trace logs by request or user</li> <li>\ud83d\udee0\ufe0f No external sidecars required for basic visibility</li> <li>\ud83d\udce6 Docker image contains <code>/metrics</code> by default and logs to <code>stdout</code> (JSON)</li> </ul>"},{"location":"architecture/adr/010-observability-prometheus/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not No structured logging Difficult to parse or filter logs; weak correlation per request Third-party APM (e.g., Datadog) Adds vendor lock-in, overhead, and cost Syslog or Fluentd only Requires extra deployment layers; still needs JSON emitters StatsD / Telegraf metrics Less common today than Prometheus; harder to self-host"},{"location":"architecture/adr/010-observability-prometheus/#status","title":"Status","text":"<p>Implemented in <code>LoggingService</code> and <code>metrics_router</code>. Observability is active by default for all transports and routes.</p>"},{"location":"architecture/adr/011-tool-federation/","title":"ADR-0011: Allow gateways to add tools with the same server side name to the MCP Gateway without conflict","text":"<ul> <li>Status: Implemented</li> <li>Date: 2025-06-22</li> <li>Deciders: Core Engineering Team</li> <li>Implemented by: IBM/mcp-context-forge#116</li> </ul>"},{"location":"architecture/adr/011-tool-federation/#context","title":"Context","text":"<p>The current functionality only supports unique names for tools, making it hard for addition of tools from different gateways with similar common names.</p> <p>This needs to be updated so that tool names are allowed with a combination of gateway name (slugified namespace) and tool name. This would allow servers to add their own versions of the tools.</p> <p>The tool names would be stored along with their original name in the database so that the correct server side name is passed while invoking it.</p>"},{"location":"architecture/adr/011-tool-federation/#decision","title":"Decision","text":"<p>We implemented this by making the following changes:</p> <ol> <li>Update IDs from integers to UUIDs:</li> <li>Modify the data type of <code>id</code> in <code>Gateway</code>, <code>Tool</code> and <code>Server</code> SQLAlchemy ORM classes from int to str</li> <li>Use a default value of <code>uuid.uuid4().hex</code> for the IDs</li> <li> <p>Modify <code>server_id</code> and <code>tool_id</code> to String in <code>server_tool_association</code> table</p> </li> <li> <p>Separate server side and gateway side names for tools:</p> </li> <li>Add a new field called <code>original_name</code> in Tool ORM class to store the MCP server side name used for invocation</li> <li>Define a hybrid operator <code>name</code> to capture how the gateway exposes the tool. Set it as <code>f\"{slugify(self.gateway.name)}{settings.gateway_tool_name_separator}{self.original_name}\"</code></li> <li>Slugified <code>self.gateway.name</code> is used to remove spaces in new tool names</li> <li>Hybrid operator is used so it can be used in Python and SQL code for filtering and querying</li> <li> <p>Add a new field called <code>gateway_slug</code> which is defined as the <code>slug</code> of the Gateway linked via <code>self.gateway_id</code>. This field is later used to extract the original name from name passed from APIs</p> </li> <li> <p>Addition of configurable environmental variable <code>GATEWAY_TOOL_NAME_SEPARATOR</code> to set how the tool name looks like:</p> </li> <li> <p>By default, this is set to <code>-</code> in config.py</p> </li> <li> <p>Updates Python object schemas, function data types to match database ORM changes**</p> </li> <li>Change data type of <code>gateway_id</code>, <code>tool_id</code> and <code>server_id</code> from int to str in API functions</li> <li>When storing and updating tools, use <code>original_name</code> in <code>DbTool</code> objects to store the original name coming from <code>_initiate_gateway</code>.</li> <li>Remove check for only storing tools without matching original names</li> <li>Check if <code>gateway.url</code> exists instead of <code>gateway.name</code> exists before thowing <code>GatewayNameConflictError</code>.</li> <li>Check for existing tools on <code>original_name</code> and <code>gateway_id</code> instead of just <code>name</code> (as earlier) in update_gateway and toggle_gateway_status code.</li> <li>Set <code>name</code> and <code>gateway_slug</code> just before passing to <code>ToolRead</code> seprately since these don't come from the database as these are properties and not columns.</li> <li> <p>To obtain tool from database for invocation, handle the case that <code>name</code> from the API is not stored as a column in the database, but is a property by making an appropriate comparison as <code>DbTool.gateway_slug + settings.gateway_tool_name_separator + DbTool.original_name == name</code></p> </li> <li> <p>Handle tool changes from the gateway by adding and removing tools based on latest deactivate/activate or edit:</p> </li> <li>Step 1: Add all tools not present in database based on <code>original_name</code> to <code>gateway.tools</code></li> <li> <p>Step 2: Remove any tools not sent in the latest call to <code>_initialize_gateway</code> from <code>gateway.tools</code>.</p> </li> <li> <p>Show row index in UI:</p> </li> <li>Display the index of the row with <code>loop.index</code> in a new column called <code>S. No.</code> in Gateways, Tools and Servers screens.</li> </ol>"},{"location":"architecture/adr/011-tool-federation/#consequences","title":"Consequences","text":"<ul> <li>Two gateways can have the tools with the same native name on the gateway. e.g. <code>gateway-1-get_system_time</code> and <code>gateway-2-get_system_time</code>.</li> <li>If the tools on a gateway change, they will reflect after Deactivate/Activate cycle or after Edit Gateway action.</li> </ul>"},{"location":"architecture/adr/011-tool-federation/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not Use qualified_name as display name and name as native MCP server name Requires changes at more places since most clients display and call with the field <code>name</code>"},{"location":"architecture/adr/011-tool-federation/#status","title":"Status","text":"<p>PR created: </p>"},{"location":"architecture/adr/012-dropdown-ui-tool-selection/","title":"ADR-0012: Display available tools in a dropdown and allow selection from there for creating a server","text":"<ul> <li>Status: Draft</li> <li>Date: 2025-06-22</li> <li>Deciders: Core Engineering Team</li> </ul>"},{"location":"architecture/adr/012-dropdown-ui-tool-selection/#context","title":"Context","text":"<p>The current solution provides a text box for users where they can enter tool ids to link to a server</p> <p>With the change of IDs from integers to UUIDs, this process is more cumbursome.</p> <p>This is modified so that users can select from tool names from a drop down.</p>"},{"location":"architecture/adr/012-dropdown-ui-tool-selection/#decision","title":"Decision","text":"<p>We implemented this by making the following changes:</p> <ol> <li>Replace text box with a dropdown element keeping the styling consistent with the to the tailwind styling used</li> <li>Users select names, but the selected tool <code>id</code>s are sent to the API for databse storage</li> <li> <p>Make this change in server creation and editing screens</p> </li> <li> <p>Add a span to display selected tools</p> </li> <li>Display the selected tools below the dropdown</li> <li>Show a warning if more than 6 tools are selected in a server. This is to encourage small servers more suited for use with agents.</li> </ol>"},{"location":"architecture/adr/012-dropdown-ui-tool-selection/#screenshots","title":"Screenshots","text":"<p> Tool selection screen</p> <p> Tool count warning</p>"},{"location":"architecture/adr/012-dropdown-ui-tool-selection/#status","title":"Status","text":"<p>PR created: </p>"},{"location":"architecture/adr/013-APIs-for-server-connection-strings/","title":"ADR-0012: Display available tools in a dropdown and allow selection from there for creating a server","text":"<ul> <li>Status: Draft</li> <li>Date: 2025-06-22</li> <li>Deciders: Core Engineering Team</li> </ul>"},{"location":"architecture/adr/013-APIs-for-server-connection-strings/#context","title":"Context","text":"<p>The current solution provides a text box for users where they can enter tool ids to link to a server</p> <p>With the change of IDs from integers to UUIDs, this process is more cumbursome.</p> <p>This is modified so that users can select from tool names from a drop down.</p>"},{"location":"architecture/adr/013-APIs-for-server-connection-strings/#decision","title":"Decision","text":"<p>We implemented this by making the following changes:</p> <ol> <li>Replace text box with a dropdown element keeping the styling consistent with the to the tailwind styling used</li> <li>Users select names, but the selected tool <code>id</code>s are sent to the API for databse storage</li> <li> <p>Make this change in server creation and editing screens</p> </li> <li> <p>Add a span to display selected tools</p> </li> <li>Display the selected tools below the dropdown</li> <li>Show a warning if more than 6 tools are selected in a server. This is to encourage small servers more suited for use with agents.</li> </ol>"},{"location":"architecture/adr/013-APIs-for-server-connection-strings/#screenshots","title":"Screenshots","text":"<p> Tool selection screen</p> <p> Tool count warning</p>"},{"location":"architecture/adr/013-APIs-for-server-connection-strings/#status","title":"Status","text":"<p>PR created: </p>"},{"location":"blog/","title":"Blog","text":""},{"location":"deployment/","title":"Deployment Overview","text":"<p>This section explains how to deploy MCP Gateway in various environments - from local development to cloud-native platforms like Kubernetes, IBM Code Engine, AWS, and Azure.</p>"},{"location":"deployment/#deployment-options","title":"\ud83d\uddfa Deployment Options","text":"<p>MCP Gateway supports multiple deployment strategies:</p> Method Description Local Run directly on your dev machine using <code>make</code>, <code>uvicorn</code>, or a virtual-env Container Package and run as a single container image using Podman or Docker Compose Stack Bring up Gateway + Postgres + Redis (and optional MPC servers) with Podman/Docker Compose Minikube Launch a local single-node Kubernetes cluster and deploy the Gateway stack Kubernetes Generic manifests or Helm chart for any K8s-compliant platform OpenShift OpenShift-specific deployment using Routes, SCCs, and Operator-managed back-ends IBM Code Engine Serverless container build &amp; run on IBM Cloud AWS Deploy on ECS Fargate, EKS, or EC2-hosted containers Azure Run on Azure Container Apps, App Service, or AKS"},{"location":"deployment/#runtime-configuration","title":"\ud83d\udee0 Runtime Configuration","text":"<p>MCP Gateway loads configuration from:</p> <ul> <li><code>.env</code> file (in project root or mounted at <code>/app/.env</code>)</li> <li>Environment variables (overrides <code>.env</code>)</li> <li>CLI flags (e.g., via <code>run.sh</code>)</li> </ul>"},{"location":"deployment/#health-checks","title":"\ud83e\uddea Health Checks","text":"<p>All deployments should expose:</p> <pre><code>GET /health\n</code></pre> <p>This returns basic system latency metrics and can be used with cloud provider readiness probes.</p>"},{"location":"deployment/#container-basics","title":"\ud83d\udce6 Container Basics","text":"<p>The default container image:</p> <ul> <li>Uses the Red Hat Universal Base image running as a non-root user</li> <li>Exposes port <code>4444</code></li> <li>Runs <code>gunicorn</code> with Uvicorn workers</li> <li>Uses <code>.env</code> for all settings</li> </ul> <p>For Kubernetes, you can mount a ConfigMap or Secret as <code>.env</code>.</p>"},{"location":"deployment/argocd/","title":"\ud83d\udea2 Deploying the MCP Gateway Stack with Argo CD","text":"<p>This guide shows how to operate the MCP Gateway Stack with a Git-Ops workflow powered by Argo CD. Once wired up, every commit to the repository becomes an automatic deployment (or rollback) to your Kubernetes cluster.</p> <p>\ud83c\udf33 Git source of truth: <code>https://github.com/IBM/mcp-context-forge</code></p> <ul> <li>App manifests: <code>k8s/</code> (Kustomize-ready)</li> <li>Helm chart (optional): <code>charts/mcp-stack</code></li> </ul>"},{"location":"deployment/argocd/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"Requirement Notes Kubernetes \u2265 1.23 Local (Minikube/kind) or managed (EKS, AKS, GKE, etc.) Argo CD \u2265 2.7 Server &amp; CLI (this guide installs server into the cluster) kubectl Configured to talk to the target cluster Git access The cluster must be able to pull the repo (public or deploy-key)"},{"location":"deployment/argocd/#step-1-install-argo-cd-once-per-cluster","title":"\ud83d\udee0 Step 1 - Install Argo CD (once per cluster)","text":"<pre><code># Namespace + core components\nkubectl create namespace argocd\nkubectl apply -n argocd \\\n  -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml\n\n# Wait for the server component\nkubectl -n argocd rollout status deploy/argocd-server\n</code></pre>"},{"location":"deployment/argocd/#install-the-cli","title":"Install the CLI","text":"<pre><code># macOS\nbrew install argocd\n\n# Linux (single-binary)\ncurl -sSL -o /tmp/argocd \\\n  https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-amd64\nsudo install -m 555 /tmp/argocd /usr/local/bin/argocd\n</code></pre> <p>Verify:</p> <pre><code>argocd version --client\n</code></pre>"},{"location":"deployment/argocd/#step-2-initial-login","title":"\ud83d\udd10 Step 2 - Initial Login","text":"<p>Forward the API/UI to your workstation (leave running):</p> <pre><code>kubectl -n argocd port-forward svc/argocd-server 8083:443\n</code></pre> <p>Fetch the one-time admin password and log in:</p> <pre><code>PASS=\"$(kubectl -n argocd get secret argocd-initial-admin-secret \\\n          -o jsonpath='{.data.password}' | base64 -d)\"\nargocd login localhost:8083 \\\n  --username admin --password \"$PASS\" --insecure\n</code></pre> <p>Open the web UI \u2192 http://localhost:8083 (credentials above).</p>"},{"location":"deployment/argocd/#step-3-bootstrap-the-application","title":"\ud83d\ude80 Step 3 - Bootstrap the Application","text":"<p>Create an Argo CD Application that tracks the <code>k8s/</code> folder from the main branch:</p> <pre><code>APP=mcp-gateway\nREPO=https://github.com/IBM/mcp-context-forge.git\n\nargocd app create \"$APP\" \\\n  --repo \"$REPO\" \\\n  --path k8s \\\n  --dest-server https://kubernetes.default.svc \\\n  --dest-namespace default \\\n  --sync-policy automated \\\n  --revision main\n</code></pre> <p>Trigger the first sync:</p> <pre><code>argocd app sync \"$APP\"\n</code></pre> <p>Argo CD will apply all manifests and keep them in the Synced \ud83c\udf3f / Healthy \ud83d\udc9a state.</p>"},{"location":"deployment/argocd/#step-4-verify-deployment","title":"\u2705 Step 4 - Verify Deployment","text":"<pre><code>kubectl get pods,svc,ingress\nargocd app list\nargocd app get mcp-gateway\n</code></pre> <p>If using the sample Ingress:</p> <pre><code>curl http://gateway.local/health\n</code></pre> <p>Otherwise, port-forward:</p> <pre><code>kubectl port-forward svc/mcp-context-forge 8080:80 &amp;\ncurl http://localhost:8080/health\n</code></pre>"},{"location":"deployment/argocd/#day-2-operations","title":"\ud83d\udd04 Day-2 Operations","text":""},{"location":"deployment/argocd/#sync-after-a-new-commit","title":"Sync after a new commit","text":"<pre><code>argocd app sync mcp-gateway\n</code></pre>"},{"location":"deployment/argocd/#view-diff-before-syncing","title":"View diff before syncing","text":"<pre><code>argocd app diff mcp-gateway\n</code></pre>"},{"location":"deployment/argocd/#roll-back-to-a-previous-revision","title":"Roll back to a previous revision","text":"<pre><code>argocd app history mcp-gateway\nargocd app rollback mcp-gateway &lt;REVISION&gt;\n</code></pre>"},{"location":"deployment/argocd/#disable-enable-auto-sync","title":"Disable / enable auto-sync","text":"<pre><code># Pause auto-sync\na rgocd app set mcp-gateway --sync-policy none\n# Re-enable\nargocd app set mcp-gateway --sync-policy automated\n</code></pre>"},{"location":"deployment/argocd/#uninstall","title":"\ud83e\uddf9 Uninstall","text":"<pre><code># Delete the application (leaves cluster objects intact)\nargocd app delete mcp-gateway --yes\n\n# Remove Argo CD completely\\ nkubectl delete ns argocd\n</code></pre>"},{"location":"deployment/argocd/#makefile-shortcuts","title":"\ud83e\uddf0 Makefile Shortcuts","text":"<p>The repository ships with ready-made targets:</p> Target Action <code>make argocd-install</code> Installs Argo CD server into the current cluster <code>make argocd-forward</code> Port-forwards UI/API on http://localhost:8083 <code>make argocd-app-bootstrap</code> Creates &amp; auto-syncs the mcp-gateway application <code>make argocd-app-sync</code> Forces a manual sync <p>Run <code>make help</code> to list them all.</p>"},{"location":"deployment/argocd/#troubleshooting","title":"\ud83e\uddef Troubleshooting","text":"Symptom Fix <code>ImagePullBackOff</code> Check image name / pull secret &amp; that the repo is public or credentials are configured in Argo CD <code>SyncFailed</code> <code>argocd app logs mcp-gateway</code> for details; often due to immutable fields Web UI 404 Ensure <code>argocd-forward</code> is still running, or expose via Ingress/LoadBalancer RBAC denied Argo CD needs ClusterRoleBinding for non-default namespaces - see docs"},{"location":"deployment/argocd/#further-reading","title":"\ud83d\udcda Further Reading","text":"<ul> <li>Argo CD Docs - https://argo-cd.readthedocs.io</li> <li>GitOps Pattern - https://www.weave.works/technologies/gitops/</li> <li>Kustomize - https://kubectl.docs.kubernetes.io/references/kustomize/</li> <li>Helm + Argo CD - https://argo-cd.readthedocs.io/en/stable/user-guide/helm/</li> </ul>"},{"location":"deployment/aws/","title":"\ud83d\udfe7 AWS","text":"<p>MCP Gateway can be deployed to AWS using multiple container-based services:</p> <ul> <li>ECS (Fargate or EC2-backed)</li> <li>EKS (Elastic Kubernetes Service)</li> <li>EC2 (direct VM hosting with Docker)</li> </ul>"},{"location":"deployment/aws/#option-1-ecs-fargate","title":"\ud83d\ude80 Option 1: ECS (Fargate)","text":"<p>ECS is a fully managed container orchestration service. Use it to deploy MCP Gateway without managing servers.</p>"},{"location":"deployment/aws/#steps","title":"Steps","text":"<ol> <li>Build and push your image:</li> </ol> <pre><code>docker build -t YOUR_ECR_URI/mcpgateway .\naws ecr get-login-password | docker login --username AWS --password-stdin YOUR_ECR_URI\ndocker push YOUR_ECR_URI/mcpgateway\n</code></pre> <ol> <li> <p>Create an ECS Task Definition:</p> </li> <li> <p>Use port <code>4444</code></p> </li> <li> <p>Mount a secret or config for your <code>.env</code> (or set environment variables manually)</p> </li> <li> <p>Create a Service:</p> </li> <li> <p>Use a Load Balancer (Application LB)</p> </li> <li>Map <code>/</code> or <code>/admin</code> to port <code>4444</code></li> </ol>"},{"location":"deployment/aws/#option-2-eks","title":"\ud83d\ude80 Option 2: EKS","text":"<p>Use the same Kubernetes deployment guide and run on Amazon EKS.</p> <p>You can:</p> <ul> <li>Use <code>kubectl</code> + <code>eksctl</code></li> <li>Store <code>.env</code> as a Secret or ConfigMap</li> <li>Use AWS Load Balancer Controller or NGINX Ingress</li> </ul>"},{"location":"deployment/aws/#option-3-ec2-docker","title":"\ud83d\ude80 Option 3: EC2 (Docker)","text":"<ol> <li>Launch a VM (e.g., Ubuntu)</li> <li>Install Docker</li> <li>Copy your <code>.env</code> file and build the container:</li> </ol> <pre><code>scp .env ec2-user@host:/home/ec2-user\nssh ec2-user@host\ndocker build -t mcpgateway .\ndocker run -p 80:4444 --env-file .env mcpgateway\n</code></pre>"},{"location":"deployment/aws/#security-tips","title":"\ud83d\udee1\ufe0f Security Tips","text":"<ul> <li>Set <code>AUTH_REQUIRED=true</code> in production</li> <li>Use <code>JWT_SECRET_KEY</code> and <code>AUTH_ENCRYPTION_SECRET</code></li> <li>Terminate TLS at the ELB level, or use Caddy/Nginx in-container if needed</li> </ul>"},{"location":"deployment/aws/#dns-access","title":"\ud83d\udce1 DNS &amp; Access","text":"<p>You can point Route53 or your DNS provider to the Load Balancer hostname.</p> <p>Example:</p> <pre><code>gateway.example.com -&gt; my-elb-1234.us-west-2.elb.amazonaws.com\n</code></pre>"},{"location":"deployment/azure/","title":"\ud83d\udd37 Azure","text":"<p>MCP Gateway can be deployed on Azure in multiple ways:</p> <ul> <li>Azure Container Apps (serverless)</li> <li>Azure App Service (PaaS for containers)</li> <li>Azure Kubernetes Service (AKS) (fully managed K8s)</li> </ul>"},{"location":"deployment/azure/#option-1-azure-container-apps-recommended","title":"\ud83d\ude80 Option 1: Azure Container Apps (Recommended)","text":"<p>Azure Container Apps is ideal for lightweight container-based workloads.</p>"},{"location":"deployment/azure/#steps","title":"Steps","text":"<ol> <li>Build and push your image to Azure Container Registry (ACR):</li> </ol> <pre><code>az acr login --name yourregistry\ndocker tag mcpgateway yourregistry.azurecr.io/mcpgateway\ndocker push yourregistry.azurecr.io/mcpgateway\n</code></pre> <ol> <li>Create the container app:</li> </ol> <pre><code>az containerapp create \\\n  --name mcpgateway \\\n  --resource-group my-rg \\\n  --image yourregistry.azurecr.io/mcpgateway \\\n  --target-port 4444 \\\n  --environment my-container-env \\\n  --registry-server yourregistry.azurecr.io \\\n  --env-vars-from-secrets .env\n</code></pre> <p>You can mount <code>.env</code> via Key Vault or inject environment variables directly.</p>"},{"location":"deployment/azure/#option-2-azure-app-service","title":"\ud83d\ude80 Option 2: Azure App Service","text":"<ol> <li>Push your image to ACR</li> <li>Create an App Service plan and container-based Web App</li> <li>Set <code>PORT=4444</code> and other env vars in Configuration \u2192 Application settings</li> <li>Map your custom domain (optional)</li> </ol>"},{"location":"deployment/azure/#option-3-azure-kubernetes-service-aks","title":"\ud83d\ude80 Option 3: Azure Kubernetes Service (AKS)","text":"<p>Use your existing Kubernetes deployment instructions, but deploy to AKS.</p> <ul> <li>Deploy with Helm or <code>kubectl</code></li> <li>Use Azure Load Balancer or Application Gateway</li> <li>Store secrets in Azure Key Vault (optional)</li> </ul>"},{"location":"deployment/azure/#secrets-config","title":"\ud83d\udd10 Secrets &amp; Config","text":"<p>Use Azure CLI to upload your <code>.env</code> values to App Config or Key Vault:</p> <pre><code>az keyvault secret set --vault-name my-kv --name JWT-SECRET --value \"super-secret\"\n</code></pre> <p>Then reference in App Service / Container App using environment variables.</p>"},{"location":"deployment/azure/#dns-tls","title":"\ud83d\udce1 DNS &amp; TLS","text":"<ul> <li>Use Azure Front Door or Application Gateway to handle TLS</li> <li>Point your domain to the public IP or hostname of the service</li> </ul> <p>Example:</p> <pre><code>gateway.example.com \u2192 mygateway.eastus.azurecontainerapps.io\n</code></pre>"},{"location":"deployment/compose/","title":"\ud83e\udde9 Docker Compose","text":"<p>Running MCP Gateway with Compose spins up a full stack (Gateway, Postgres, Redis, optional MPC servers) behind a single YAML file. The Makefile detects Podman or Docker automatically, and you can override it with <code>COMPOSE_CMD=</code>. Health-checks (<code>service_healthy</code>) gate the Gateway until the database is ready, preventing race conditions.</p>"},{"location":"deployment/compose/#configure-the-compose-command-to-use","title":"Configure the compose command to use","text":"<p>For example, install and use Docker Compose v2:</p> <pre><code>sudo apt install docker-buildx docker-compose-v2\nexport COMPOSE_CMD=\"docker compose\"\n</code></pre>"},{"location":"deployment/compose/#build-the-images","title":"\ud83d\udc33/\ud83e\uddad Build the images","text":"<pre><code>docker pull ghcr.io/ibm/mcp-context-forge:latest\n</code></pre>"},{"location":"deployment/compose/#build-the-images-when-doing-local-development","title":"\ud83d\udc33/\ud83e\uddad Build the images (when doing local development)","text":""},{"location":"deployment/compose/#using-make-preferred","title":"Using Make (preferred)","text":"Target Image Dockerfile Notes <code>make podman</code> <code>mcpgateway:latest</code> Containerfile Rootless Podman, dev-oriented <code>make podman-prod</code> <code>mcpgateway:latest</code> Containerfile.lite Ultra-slim UBI 9-micro build <code>make docker</code> <code>mcpgateway:latest</code> Containerfile Docker Desktop / CI runners <code>make docker-prod</code> <code>mcpgateway:latest</code> Containerfile.lite Same multi-stage \"lite\" build <p>Remember to tag the image or configure the correct image in <code>docker-compose.yml</code></p>"},{"location":"deployment/compose/#manual-equivalents","title":"Manual equivalents","text":"<pre><code># Podman (dev image)\npodman build -t mcpgateway-dev:latest -f Containerfile .\n\n# Podman (prod image, AMD64, squash layers)\npodman build --platform=linux/amd64 --squash \\\n  -t mcpgateway:latest -f Containerfile.lite .\n\n# Docker (dev image)\ndocker build -t mcpgateway-dev:latest -f Containerfile .\n\n# Docker (prod image)\ndocker build -t mcpgateway:latest -f Containerfile.lite .\n</code></pre> <p>Apple Silicon caveat <code>Containerfile.lite</code> derives from ubi9-micro. Running it via QEMU emulation on M-series Macs often fails with a <code>glibc x86-64-v2</code> error. Use the regular image or build a native <code>linux/arm64</code> variant on Mac.</p>"},{"location":"deployment/compose/#start-the-compose-stack","title":"\ud83c\udfc3 Start the Compose stack","text":""},{"location":"deployment/compose/#with-make","title":"With Make","text":"<pre><code>make compose-up                   # auto-detects engine\nCOMPOSE_ENGINE=docker make compose-up   # force Docker\nCOMPOSE_ENGINE=podman make compose-up   # force Podman\n</code></pre>"},{"location":"deployment/compose/#without-make","title":"Without Make","text":"Make target Docker CLI Podman built-in podman-compose <code>compose-up</code> <code>docker compose -f podman-compose.yml up -d</code> <code>podman compose -f podman-compose.yml up -d</code> <code>podman-compose -f podman-compose.yml up -d</code> <code>compose-restart</code> <code>docker compose up -d --pull=missing --build</code> idem idem <code>compose-logs</code> <code>docker compose logs -f</code> <code>podman compose logs -f</code> <code>podman-compose logs -f</code> <code>compose-ps</code> <code>docker compose ps</code> <code>podman compose ps</code> <code>podman-compose ps</code> <code>compose-stop</code> <code>docker compose stop</code> <code>podman compose stop</code> <code>podman-compose stop</code> <code>compose-down</code> <code>docker compose down</code> <code>podman compose down</code> <code>podman-compose down</code> <code>compose-clean</code> <code>docker compose down -v</code> (removes volumes) <code>podman compose down -v</code> <code>podman-compose down -v</code>"},{"location":"deployment/compose/#access-and-verify","title":"\ud83c\udf10 Access and verify","text":"<ul> <li>Gateway URL: http://localhost:4444   (Bound to <code>0.0.0.0</code> inside the container so port-forwarding works.)</li> </ul> <pre><code>curl http://localhost:4444/health    # {\"status\":\"ok\"}\n</code></pre> <ul> <li>Logs: <code>make compose-logs</code> or raw <code>docker compose logs -f gateway</code>.</li> </ul>"},{"location":"deployment/compose/#selecting-a-database","title":"\ud83d\uddc4 Selecting a database","text":"<p>Uncomment one service block in <code>podman-compose.yml</code> and align <code>DATABASE_URL</code>:</p> Service block Connection string <code>postgres:</code> (default) <code>postgresql://postgres:...@postgres:5432/mcp</code> <code>mariadb:</code> <code>mysql+pymysql://admin:...@mariadb:3306/mcp</code> <code>mysql:</code> <code>mysql+pymysql://mysql:...@mysql:3306/mcp</code> <code>mongodb:</code> <code>mongodb://admin:...@mongodb:27017/mcp</code> <p>Named volumes (<code>pgdata</code>, <code>mariadbdata</code>, <code>mysqldata</code>, <code>mongodata</code>) isolate persistent data.</p>"},{"location":"deployment/compose/#lifecycle-cheatsheet","title":"\ud83d\udd04 Lifecycle cheatsheet","text":"Task Make Manual (engine-agnostic) Start / create <code>make compose-up</code> <code>&lt;engine&gt; compose up -d</code> Re-create changed <code>make compose-restart</code> <code>&lt;engine&gt; compose up -d --pull=missing --build</code> Tail logs <code>make compose-logs</code> <code>&lt;engine&gt; compose logs -f</code> Shell into gateway <code>make compose-shell</code> <code>&lt;engine&gt; compose exec gateway /bin/sh</code> Stop <code>make compose-stop</code> <code>&lt;engine&gt; compose stop</code> Remove containers <code>make compose-down</code> <code>&lt;engine&gt; compose down</code> Nuke volumes <code>make compose-clean</code> <code>&lt;engine&gt; compose down -v</code> <p><code>&lt;engine&gt;</code> = <code>docker</code>, <code>podman</code>, or <code>podman-compose</code> as shown earlier.</p>"},{"location":"deployment/compose/#troubleshooting-port-publishing-on-wsl2-rootless-podman","title":"\ud83d\udd0d Troubleshooting port publishing on WSL2 (rootless Podman)","text":"<pre><code># Verify the port is listening (dual-stack)\nss -tlnp | grep 4444        # modern tool\nnetstat -anp | grep 4444    # legacy fallback\n</code></pre> <p>A line like <code>LISTEN rootlessport</code> is normal - the IPv6 wildcard socket (<code>::</code>) also accepts IPv4 when <code>net.ipv6.bindv6only=0</code> (the default on Linux).</p> <p>WSL2 quirk</p> <p>WSL's NAT maps only the IPv6 side, so <code>http://127.0.0.1:4444</code> fails from Windows. Tell Podman you are inside WSL and restart your containers:</p> <pre><code># inside the WSL distro\necho \"wsl\" | sudo tee /etc/containers/podman-machine\n</code></pre> <p><code>ss</code> should now show an explicit <code>0.0.0.0:4444</code> listener, making the service reachable from Windows and the LAN.</p>"},{"location":"deployment/compose/#references","title":"\ud83d\udcda References","text":"<ul> <li>Docker Compose CLI (<code>up</code>, <code>logs</code>, <code>down</code>) - official docs</li> <li>Podman's integrated compose wrapper - man page</li> <li><code>podman-compose</code> rootless implementation - GitHub project</li> <li>Health-check gating with <code>depends_on: condition: service_healthy</code></li> <li>UBI9 runtime on Apple Silicon limitations (<code>x86_64-v2</code> glibc)</li> <li>General Containerfile build guidance (Fedora/Red Hat)</li> </ul>"},{"location":"deployment/container/","title":"\ud83d\udce6 Container Deployment","text":"<p>You can run MCP Gateway as a fully self-contained container. This is the recommended method for production or platform-agnostic deployments. You can use any container engine (ex: Docker or Podman).</p>"},{"location":"deployment/container/#quick-start-pre-built-container-image","title":"Quick Start (Pre-built Container Image)","text":"<p>If you just want to run the gateway using the official OCI container image from GitHub Container Registry:</p> <pre><code>docker run -d --name mcpgateway \\\n  -p 4444:4444 \\\n  -e HOST=0.0.0.0 \\\n  -e JWT_SECRET_KEY=my-test-key \\\n  -e BASIC_AUTH_USER=admin \\\n  -e BASIC_AUTH_PASSWORD=changeme \\\n  -e AUTH_REQUIRED=true \\\n  -e DATABASE_URL=sqlite:///./mcp.db \\\n  --network=host \\\n  ghcr.io/ibm/mcp-context-forge:latest\n\ndocker logs mcpgateway\n</code></pre> <p>You can now access the UI at http://localhost:4444/admin</p>"},{"location":"deployment/container/#build-the-container","title":"\ud83d\udc33 Build the Container","text":""},{"location":"deployment/container/#using-podman-recommended","title":"Using Podman (recommended)","text":"<pre><code>make podman\n</code></pre>"},{"location":"deployment/container/#using-docker-manual-alternative","title":"Using Docker (manual alternative)","text":"<pre><code>docker build -t mcpgateway:latest -f Containerfile .\n</code></pre> <p>The base image uses <code>python:3.11-slim</code> with Gunicorn and Uvicorn workers.</p>"},{"location":"deployment/container/#run-the-container","title":"\ud83c\udfc3 Run the Container","text":""},{"location":"deployment/container/#with-http-no-tls","title":"With HTTP (no TLS)","text":"<pre><code>make podman-run\n</code></pre> <p>This starts the app at <code>http://localhost:4444</code>.</p>"},{"location":"deployment/container/#with-self-signed-tls-https","title":"With Self-Signed TLS (HTTPS)","text":"<pre><code>make podman-run-ssl\n</code></pre> <p>Runs the gateway using certs from <code>./certs/</code>, available at:</p> <pre><code>https://localhost:4444\n</code></pre>"},{"location":"deployment/container/#runtime-configuration","title":"\u2699 Runtime Configuration","text":"<p>All environment variables can be passed via:</p> <ul> <li><code>docker run -e KEY=value</code></li> <li>A mounted <code>.env</code> file (<code>--env-file .env</code>)</li> </ul>"},{"location":"deployment/container/#test-the-running-container","title":"\ud83e\uddea Test the Running Container","text":"<pre><code>curl http://localhost:4444/health\ncurl http://localhost:4444/tools\n</code></pre> <p>Use <code>curl -k</code> if running with self-signed TLS</p>"},{"location":"deployment/container/#stop-clean-up","title":"\ud83e\uddfc Stop &amp; Clean Up","text":"<pre><code>podman stop mcpgateway\npodman rm mcpgateway\n</code></pre> <p>Or with Docker:</p> <pre><code>docker stop mcpgateway\ndocker rm mcpgateway\n</code></pre>"},{"location":"deployment/fly-io/","title":"\u2699\ufe0f Fly.io Deployment Guide for MCP Gateway","text":"<p>This guide covers the complete deployment workflow for the MCP Gateway on Fly.io, including common troubleshooting steps.</p>"},{"location":"deployment/fly-io/#overview","title":"Overview","text":"<p>Fly.io is a global app platform for running containers close to your users, with built-in TLS, persistent volumes, and managed Postgres support. It offers a generous free tier and automatic HTTPS with fly.dev subdomains.</p>"},{"location":"deployment/fly-io/#1-prerequisites","title":"1 - Prerequisites","text":"Requirement Details Fly.io account Sign up Fly CLI Install via Homebrew: <code>brew install flyctl</code> or see Fly docs Docker or Podman For local image builds (optional) Containerfile The included Containerfile with psycopg2-binary support"},{"location":"deployment/fly-io/#2-quick-start-recommended","title":"2 - Quick Start (Recommended)","text":""},{"location":"deployment/fly-io/#21-initialize-fly-project","title":"2.1 Initialize Fly project","text":"<p><pre><code>fly launch --name your-app-name --no-deploy\n</code></pre> This creates a new Fly app without deploying immediately.</p>"},{"location":"deployment/fly-io/#22-create-and-attach-fly-postgres","title":"2.2 Create and attach Fly Postgres","text":"<pre><code># Create postgres (choose Development configuration for testing)\nfly postgres create --name your-app-db --region yyz\n\n# Note the connection details from the output, you'll need the password\n</code></pre>"},{"location":"deployment/fly-io/#23-set-secrets","title":"2.3 Set secrets","text":"<pre><code># Set authentication secrets\nfly secrets set JWT_SECRET_KEY=$(openssl rand -hex 32)\nfly secrets set BASIC_AUTH_USER=admin BASIC_AUTH_PASSWORD=your-secure-password\n\n# Set database URL (CRITICAL: use postgresql:// not postgres://)\nfly secrets set DATABASE_URL=\"postgresql://postgres:YOUR_PASSWORD@your-app-db.flycast:5432/postgres\"\n</code></pre> <p>\u26a0\ufe0f Important: Always use <code>postgresql://</code> scheme, not <code>postgres://</code>. The latter causes SQLAlchemy dialect loading errors.</p>"},{"location":"deployment/fly-io/#24-deploy-the-app","title":"2.4 Deploy the app","text":"<pre><code>fly deploy\n</code></pre>"},{"location":"deployment/fly-io/#3-containerfile-requirements","title":"3 - Containerfile Requirements","text":"<p>Ensure your Containerfile explicitly installs PostgreSQL dependencies:</p> <pre><code># Create virtual environment, upgrade pip and install dependencies\nRUN python3 -m venv /app/.venv &amp;&amp; \\\n/app/.venv/bin/python3 -m pip install --upgrade pip setuptools pdm uv &amp;&amp; \\\n/app/.venv/bin/python3 -m pip install psycopg2-binary &amp;&amp; \\\n/app/.venv/bin/python3 -m uv pip install \".[redis]\"\n</code></pre> <p>The explicit <code>psycopg2-binary</code> installation is required because uv may not properly install optional dependencies.</p>"},{"location":"deployment/fly-io/#4-flytoml-configuration","title":"4 - fly.toml Configuration","text":"<p>Your <code>fly.toml</code> should look like this:</p> <pre><code>app = \"your-app-name\"\nprimary_region = \"yyz\"\n\n[build]\ndockerfile = \"Containerfile\"\n\n[env]\nHOST = \"0.0.0.0\"\nPORT = \"4444\"\n\n[http_service]\ninternal_port = 4444\nforce_https = true\nauto_stop_machines = \"stop\"\nauto_start_machines = true\nmin_machines_running = 0\nprocesses = [\"app\"]\n\n[[vm]]\nmemory = \"1gb\"\ncpu_kind = \"shared\"\ncpus = 1\n</code></pre> <p>Note: Don't put secrets like <code>DATABASE_URL</code> in <code>fly.toml</code> - use <code>fly secrets set</code> instead.</p>"},{"location":"deployment/fly-io/#5-testing-your-deployment","title":"5 - Testing Your Deployment","text":""},{"location":"deployment/fly-io/#51-check-app-status","title":"5.1 Check app status","text":"<pre><code>fly status\nfly logs\n</code></pre>"},{"location":"deployment/fly-io/#52-test-endpoints","title":"5.2 Test endpoints","text":"<pre><code># Health check (no auth required)\ncurl https://your-app-name.fly.dev/health\n\n# Protected endpoints (require auth)\ncurl -u admin:your-password https://your-app-name.fly.dev/docs\ncurl -u admin:your-password https://your-app-name.fly.dev/tools\n</code></pre>"},{"location":"deployment/fly-io/#53-expected-responses","title":"5.3 Expected responses","text":"<ul> <li>Health: <code>{\"status\":\"healthy\"}</code></li> <li>Protected endpoints without auth: <code>{\"detail\":\"Not authenticated\"}</code></li> <li>Protected endpoints with auth: JSON response with data</li> </ul>"},{"location":"deployment/fly-io/#6-troubleshooting","title":"6 - Troubleshooting","text":""},{"location":"deployment/fly-io/#common-issue-1-sqlalchemy-postgres-dialect-error","title":"Common Issue 1: SQLAlchemy postgres dialect error","text":"<pre><code>sqlalchemy.exc.NoSuchModuleError: Can't load plugin: sqlalchemy.dialects:postgres\n</code></pre> <p>Solutions: 1. Ensure <code>psycopg2-binary</code> is explicitly installed in Containerfile 2. Use <code>postgresql://</code> not <code>postgres://</code> in DATABASE_URL 3. Rebuild with <code>fly deploy --no-cache</code></p>"},{"location":"deployment/fly-io/#common-issue-2-database-connection-refused","title":"Common Issue 2: Database connection refused","text":"<p>Solutions: 1. Verify DATABASE_URL format: <code>postgresql://postgres:PASSWORD@your-db.flycast:5432/postgres</code> 2. Check postgres app is running: <code>fly status -a your-app-db</code> 3. Verify password matches postgres creation output</p>"},{"location":"deployment/fly-io/#common-issue-3-machines-not-updating","title":"Common Issue 3: Machines not updating","text":"<p>Solutions: <pre><code># Force machine updates\nfly machine list\nfly machine update MACHINE_ID --image your-new-image\n\n# Or restart all machines\nfly scale count 0\nfly scale count 1\n</code></pre></p>"},{"location":"deployment/fly-io/#7-production-considerations","title":"7 - Production Considerations","text":""},{"location":"deployment/fly-io/#security","title":"Security","text":"<ul> <li>Change default <code>BASIC_AUTH_PASSWORD</code> to a strong password</li> <li>Consider using JWT tokens for API access</li> <li>Enable Fly's private networking for database connections</li> </ul>"},{"location":"deployment/fly-io/#scaling","title":"Scaling","text":"<pre><code># Scale to multiple machines for HA\nfly scale count 2\n\n# Scale machine resources\nfly scale memory 2gb\n</code></pre>"},{"location":"deployment/fly-io/#monitoring","title":"Monitoring","text":"<pre><code># View real-time logs\nfly logs -f\n\n# Check machine metrics\nfly machine status MACHINE_ID\n</code></pre>"},{"location":"deployment/fly-io/#8-clean-deployment-script","title":"8 - Clean Deployment Script","text":"<p>For a completely fresh deployment:</p> <pre><code>#!/bin/bash\nset -e\n\nAPP_NAME=\"your-app-name\"\nDB_NAME=\"${APP_NAME}-db\"\nREGION=\"yyz\"\nPASSWORD=$(openssl rand -base64 32)\n\necho \"\ud83d\ude80 Deploying MCP Gateway to Fly.io...\"\n\n# Create app\nfly launch --name $APP_NAME --no-deploy --region $REGION\n\n# Create postgres\nfly postgres create --name $DB_NAME --region $REGION\n\n# Set secrets\nfly secrets set JWT_SECRET_KEY=$(openssl rand -hex 32)\nfly secrets set BASIC_AUTH_USER=admin\nfly secrets set BASIC_AUTH_PASSWORD=$PASSWORD\n\n# Get postgres password and set DATABASE_URL\necho \"\u26a0\ufe0f  Set your DATABASE_URL manually with the postgres password:\"\necho \"fly secrets set DATABASE_URL=\\\"postgresql://postgres:YOUR_PG_PASSWORD@${DB_NAME}.flycast:5432/postgres\\\"\"\n\n# Deploy\necho \"\ud83c\udfd7\ufe0f  Ready to deploy. Run: fly deploy\"\n</code></pre>"},{"location":"deployment/fly-io/#9-additional-resources","title":"9 - Additional Resources","text":"<ul> <li>Fly.io Documentation</li> <li>Fly Postgres Guide</li> <li>Fly Secrets Management</li> </ul> <p>Success indicators: - \u2705 <code>fly status</code> shows machines as \"started\" - \u2705 <code>/health</code> endpoint returns <code>{\"status\":\"healthy\"}</code> - \u2705 Protected endpoints require authentication - \u2705 No SQLAlchemy errors in logs</p>"},{"location":"deployment/google-cloud-run/","title":"\u2601\ufe0f Deploying MCP Gateway on Google Cloud Run","text":"<p>MCP Gateway can be deployed to Google Cloud Run, a fully managed, autoscaling platform for containerized applications. This guide provides step-by-step instructions to provision PostgreSQL and Redis backends, deploy the container, configure environment variables, authenticate using JWT, and monitor logs-all optimized for cost-efficiency.</p>"},{"location":"deployment/google-cloud-run/#overview","title":"\u2705 Overview","text":"<p>Google Cloud Run is an ideal platform for MCP Gateway due to its:</p> <ul> <li>Serverless and cost-efficient model with scale-to-zero capability.</li> <li>Public HTTPS endpoints with automatic TLS configuration.</li> <li>Seamless integration with Cloud SQL (PostgreSQL) and Memorystore (Redis).</li> <li>Compatibility with public container registries like GitHub's <code>ghcr.io</code>.</li> </ul> <p>You can deploy the public image directly:</p> <pre><code>ghcr.io/ibm/mcp-context-forge:latest\n</code></pre>"},{"location":"deployment/google-cloud-run/#prerequisites","title":"\ud83d\udee0 Prerequisites","text":""},{"location":"deployment/google-cloud-run/#1-install-and-initialize-google-cloud-cli-gcloud","title":"1. Install and Initialize Google Cloud CLI (<code>gcloud</code>)","text":"<p>Install the Google Cloud SDK:</p> <ul> <li>macOS (Homebrew):</li> </ul> <pre><code>brew install --cask google-cloud-sdk\n</code></pre> <ul> <li>Debian/Ubuntu:</li> </ul> <p>These steps also apply to WSL2 running Ubuntu.</p> <pre><code># Update package lists and install necessary utilities\nsudo apt-get update\nsudo apt-get install -y apt-transport-https ca-certificates gnupg curl\n\n# Import the Google Cloud public key securely\n# This is for newer distributions (Debian 9+ or Ubuntu 18.04+).\ncurl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg\n\n# Add the Google Cloud SDK distribution URI as a package source\n# This is for newer distributions, ensuring packages are signed by the key we just added.\necho \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main\" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list\n\n# Update your package lists again to recognize the new repository\nsudo apt-get update\n\n# Install the Google Cloud CLI\nsudo apt-get install -y google-cloud-cli\n</code></pre> <ul> <li>Windows (PowerShell):</li> </ul> <pre><code>winget install --id Google.CloudSDK\n</code></pre> <p>After installation, initialize the CLI:</p> <pre><code>gcloud init\n</code></pre> <p>Authenticate with your Google Cloud account:</p> <pre><code>gcloud auth login\n</code></pre> <p>Set a project ID:</p> <pre><code>gcloud config set project PROJECT_ID\n</code></pre>"},{"location":"deployment/google-cloud-run/#2-enable-required-apis","title":"2. Enable Required APIs","text":"<p>Enable the necessary Google Cloud APIs:</p> <pre><code># This might take a minute..\ngcloud services enable \\\n  run.googleapis.com \\\n  sqladmin.googleapis.com \\\n  redis.googleapis.com\n</code></pre>"},{"location":"deployment/google-cloud-run/#3-install-docker","title":"3. Install Docker","text":"<p>Ensure Docker is installed for local testing and JWT token generation. Visit Docker's official website for installation instructions.</p>"},{"location":"deployment/google-cloud-run/#4-set-environment-variables","title":"4. Set Environment Variables","text":"<p>Prepare the following environment variables:</p> Variable Description <code>JWT_SECRET_KEY</code> Secret key for signing JWT tokens <code>BASIC_AUTH_USER</code> Username for HTTP Basic Authentication <code>BASIC_AUTH_PASSWORD</code> Password for HTTP Basic Authentication <code>AUTH_REQUIRED</code> Set to <code>true</code> to enforce authentication <code>DATABASE_URL</code> PostgreSQL connection string <code>REDIS_URL</code> Redis connection string <code>CACHE_TYPE</code> Set to <code>redis</code> for production environments <code>PORT</code> Port number the application listens on (e.g., <code>4444</code>) <p>Consider creating a <code>.env.gcr</code> file where you will record the various settings used during deployment.</p> <pre><code># \u2500\u2500\u2500 Google Cloud project \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nPROJECT_ID=\nREGION=us-central1\nSERVICE_NAME=mcpgateway\n\n# \u2500\u2500\u2500 Authentication \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nJWT_SECRET_KEY=\nBASIC_AUTH_USER=\nBASIC_AUTH_PASSWORD=\nAUTH_REQUIRED=true\n\n# \u2500\u2500\u2500 Cloud SQL (PostgreSQL) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nSQL_INSTANCE=mcpgw-db\nSQL_REGION=us-central1\nDATABASE_URL=postgresql://postgres:&lt;PASSWORD&gt;@&lt;SQL_IP&gt;:5432/mcpgw\n\n# \u2500\u2500\u2500 Memorystore (Redis) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nREDIS_INSTANCE=mcpgw-redis\nREDIS_REGION=us-central1\nREDIS_URL=redis://&lt;REDIS_IP&gt;:6379/0\nCACHE_TYPE=redis\n\n# \u2500\u2500\u2500 Application \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nPORT=4444\n</code></pre>"},{"location":"deployment/google-cloud-run/#setup-steps","title":"\u2699\ufe0f Setup Steps","text":""},{"location":"deployment/google-cloud-run/#1-provision-cloud-sql-postgresql","title":"1. Provision Cloud SQL (PostgreSQL)","text":"<p>Create a PostgreSQL instance using the <code>db-f1-micro</code> tier for cost efficiency:</p> <pre><code># POSTGRES_16 and POSTGRES_17 default to Enterprise Plus; adding --edition=ENTERPRISE lets you pick db-f1-micro\ngcloud sql instances create mcpgw-db \\\n  --database-version=POSTGRES_17 \\\n  --edition=ENTERPRISE \\\n  --tier=db-f1-micro \\\n  --region=us-central1\n</code></pre> <p>Set the password for the <code>postgres</code> user:</p> <pre><code>gcloud sql users set-password postgres \\\n  --instance=mcpgw-db \\\n  --password=mysecretpassword\n</code></pre> <p>Create the <code>mcpgw</code> database:</p> <pre><code>gcloud sql databases create mcpgw --instance=mcpgw-db\n</code></pre> <p>Retrieve the IP address of the instance:</p> <pre><code>gcloud sql instances describe mcpgw-db \\\n  --format=\"value(ipAddresses.ipAddress)\"\n</code></pre> <p>Note: The <code>db-f1-micro</code> tier is a shared-core instance designed for low-cost development and testing environments. It is not covered by the Cloud SQL SLA.</p>"},{"location":"deployment/google-cloud-run/#2-provision-memorystore-redis","title":"2. Provision Memorystore (Redis)","text":"<p>Create a Redis instance using the Basic Tier with 1 GiB capacity:</p> <pre><code>gcloud redis instances create mcpgw-redis \\\n  --region=us-central1 \\\n  --tier=BASIC \\\n  --size=1\n</code></pre> <p>Retrieve the host IP address:</p> <pre><code>gcloud redis instances describe mcpgw-redis \\\n  --region=us-central1 \\\n  --format=\"value(host)\"\n</code></pre> <p>Note: The Basic Tier provides a standalone Redis instance suitable for applications that can tolerate potential data loss during failures.</p>"},{"location":"deployment/google-cloud-run/#3-deploy-to-google-cloud-run","title":"3. Deploy to Google Cloud Run","text":"<p>Cloud Run only accepts container images that live in Artifact Registry or the older Container Registry endpoints; anything pulled from the public internet (for example ghcr.io) must first be proxied or copied into Artifact Registry.</p>"},{"location":"deployment/google-cloud-run/#set-your-project-id","title":"Set Your Project ID","text":"<p>Begin by setting your Google Cloud project ID as an environment variable:</p> <pre><code>export PROJECT_ID=\"your-project-id\"\n</code></pre> <p>Replace <code>\"your-project-id\"</code> with your actual Google Cloud project ID.</p>"},{"location":"deployment/google-cloud-run/#enable-required-apis","title":"Enable Required APIs","text":"<p>Ensure that the necessary Google Cloud APIs are enabled:</p> <pre><code>gcloud services enable artifactregistry.googleapis.com\n</code></pre>"},{"location":"deployment/google-cloud-run/#create-a-remote-repository","title":"Create a Remote Repository","text":"<p>Set up a remote repository in Artifact Registry that proxies GitHub Container Registry (GHCR):</p> <pre><code>gcloud artifacts repositories create ghcr-remote \\\n  --project=$PROJECT_ID \\\n  --repository-format=docker \\\n  --location=us-central1 \\\n  --description=\"Proxy for GitHub Container Registry\" \\\n  --mode=remote-repository \\\n  --remote-docker-repo=https://ghcr.io\n</code></pre>"},{"location":"deployment/google-cloud-run/#retrieve-cloud-sql-instance-connection-name","title":"Retrieve Cloud SQL Instance Connection Name","text":"<pre><code>gcloud sql instances describe mcpgw-db \\\n  --format=\"value(connectionName)\"\n</code></pre> <p>It will output something like this:</p> <pre><code>your-project-id:us-central1:mcpgw-db\n</code></pre>"},{"location":"deployment/google-cloud-run/#allow-ingress-to-your-database","title":"Allow ingress to your database.","text":"<p>Consider only allowing the Cloud Run IP range.</p> <pre><code>gcloud sql instances patch mcpgw-db \\\n  --authorized-networks=0.0.0.0/0\n</code></pre>"},{"location":"deployment/google-cloud-run/#deploy-the-mcp-gateway-container-with-minimal-resource-allocation","title":"Deploy the MCP Gateway container with minimal resource allocation:","text":"<pre><code>gcloud run deploy mcpgateway \\\n  --image=us-central1-docker.pkg.dev/$PROJECT_ID/ghcr-remote/ibm/mcp-context-forge:latest\n  --region=us-central1 \\\n  --platform=managed \\\n  --allow-unauthenticated \\\n  --port=4444 \\\n  --cpu=1 \\\n  --memory=512i \\\n  --max-instances=1 \\\n  --set-env-vars=\\\nJWT_SECRET_KEY=jwt-secret-key,\\\nBASIC_AUTH_USER=admin,\\\nBASIC_AUTH_PASSWORD=changeme,\\\nAUTH_REQUIRED=true,\\\nDATABASE_URL=postgresql://postgres:mysecretpassword@&lt;SQL_IP&gt;:5432/mcpgw,\\\nREDIS_URL=redis://&lt;REDIS_IP&gt;:6379/0,\\\nCACHE_TYPE=redis,\\\nHOST=0.0.0.0,\\\nGUNICORN_WORKERS=1\n</code></pre> <p>Replace <code>&lt;SQL_IP&gt;</code> and <code>&lt;REDIS_IP&gt;</code> with the actual IP addresses obtained from the previous steps. Do not leave out the HOST=0.0.0.0 to ensure the container listens on all ports, or the container engine won't be able to reach the container. Setting the number of GUNICORN_WORKERS lets you control how much memory the service consumes.</p>"},{"location":"deployment/google-cloud-run/#check-the-logs","title":"Check the logs","text":""},{"location":"deployment/google-cloud-run/#gcloud-run-services-logs-read-mcpgateway-regionus-central1","title":"<pre><code>gcloud run services logs read mcpgateway --region=us-central1\n</code></pre>","text":""},{"location":"deployment/google-cloud-run/#check-that-the-database-is-created","title":"Check that the database is created:","text":"<p>You can use any PostgreSQL client, such as <code>psql</code>. You should see the list of tables when using <code>dt;</code></p> <pre><code>psql postgresql://postgres:mysecretpassword@&lt;SQL_IP&gt;:5432/mcpgw\n\nmcpgw=&gt; \\dt;\n                    List of relations\n Schema |             Name             | Type  |  Owner\n--------+------------------------------+-------+----------\n public | gateways                     | table | postgres\n public | mcp_messages                 | table | postgres\n public | mcp_sessions                 | table | postgres\n public | prompt_gateway_association   | table | postgres\n public | prompt_metrics               | table | postgres\n public | prompts                      | table | postgres\n public | resource_gateway_association | table | postgres\n public | resource_metrics             | table | postgres\n public | resource_subscriptions       | table | postgres\n public | resources                    | table | postgres\n public | server_metrics               | table | postgres\n public | server_prompt_association    | table | postgres\n public | server_resource_association  | table | postgres\n public | server_tool_association      | table | postgres\n public | servers                      | table | postgres\n public | tool_gateway_association     | table | postgres\n public | tool_metrics                 | table | postgres\n public | tools                        | table | postgres\n(18 rows)\n</code></pre>"},{"location":"deployment/google-cloud-run/#authentication-and-access","title":"\ud83d\udd12 Authentication and Access","text":""},{"location":"deployment/google-cloud-run/#generate-a-jwt-bearer-token","title":"Generate a JWT Bearer Token","text":"<p>Use the MCP Gateway container to generate a JWT token:</p> <pre><code>docker run -it --rm ghcr.io/ibm/mcp-context-forge:latest \\\n  python3 -m mcpgateway.utils.create_jwt_token -u admin --secret jwt-secret-key\n</code></pre> <p>Export the token as an environment variable:</p> <pre><code>export MCPGATEWAY_BEARER_TOKEN=&lt;paste-token-here&gt;\n</code></pre>"},{"location":"deployment/google-cloud-run/#perform-smoke-tests","title":"Perform Smoke Tests","text":"<p>Test the <code>/health</code>, <code>/version</code>, and <code>/tools</code> endpoints:</p> <pre><code># Check that the service is healthy\ncurl -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     https://&lt;your-cloud-run-url&gt;/health\n\n# Check that version reports the version and show Postgres/Redis as connected\ncurl -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     https://&lt;your-cloud-run-url&gt;/health\n\n# Check that tools return an empty list []\ncurl -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     https://&lt;your-cloud-run-url&gt;/tools\n</code></pre> <p>Replace <code>&lt;your-cloud-run-url&gt;</code> with the URL provided after deploying the service.</p>"},{"location":"deployment/google-cloud-run/#logs-and-monitoring","title":"\ud83d\udcca Logs and Monitoring","text":""},{"location":"deployment/google-cloud-run/#view-logs-via-cli","title":"View Logs via CLI","text":"<p>Tailing real-time logs requires <code>google-cloud-cli-log-streaming</code>. Ex: <code>sudo apt-get install google-cloud-cli-log-streaming</code>:</p> <pre><code>gcloud beta run services logs tail mcpgateway --region=us-central1\n</code></pre>"},{"location":"deployment/google-cloud-run/#access-logs-via-console","title":"Access Logs via Console","text":"<p>Navigate to the Cloud Run Console and select your service to view logs and metrics.</p>"},{"location":"deployment/google-cloud-run/#github-actions-deployment-optional","title":"\ud83d\udce6 GitHub Actions Deployment (Optional)","text":"<p>Automate builds and deployments using GitHub Actions. Refer to the workflow file:</p> <pre><code>.github/workflows/google-cloud-run.yml\n</code></pre> <p>This workflow:</p> <ul> <li>Restores and updates a local BuildKit layer cache.</li> <li>Builds the Docker image from <code>Containerfile.lite</code>.</li> <li>Pushes the image to Google Artifact Registry.</li> <li>Deploys to Google Cloud Run with <code>--max-instances=1</code>.</li> </ul>"},{"location":"deployment/google-cloud-run/#setting-up-permissions-for-google-cloud-run-deployment","title":"Setting up permissions for Google Cloud Run deployment","text":"<p>Instead of project-wide permissions, grant permissions on specific resources:</p> <pre><code># Create service account\ngcloud iam service-accounts create github-mcpgateway \\\n  --display-name=\"GitHub MCP Gateway Deploy\"\n\n# Grant permission ONLY on the specific Cloud Run service\ngcloud run services add-iam-policy-binding mcpgateway \\\n  --region=us-central1 \\\n  --member=\"serviceAccount:github-mcpgateway@YOUR-PROJECT-ID.iam.gserviceaccount.com\" \\\n  --role=\"roles/run.developer\"\n\n# Grant permission ONLY on the specific Artifact Registry repository\ngcloud artifacts repositories add-iam-policy-binding mcpgateway \\\n  --location=us-central1 \\\n  --member=\"serviceAccount:github-mcpgateway@YOUR-PROJECT-ID.iam.gserviceaccount.com\" \\\n  --role=\"roles/artifactregistry.writer\"\n\n# Create the key\ngcloud iam service-accounts keys create restricted-key.json \\\n  --iam-account=github-mcpgateway@YOUR-PROJECT-ID.iam.gserviceaccount.com\n</code></pre>"},{"location":"deployment/google-cloud-run/#notes-and-tips","title":"\ud83d\udcd8 Notes and Tips","text":"<ul> <li> <p>HTTPS by Default: Cloud Run services are accessible over HTTPS without additional configuration.</p> </li> <li> <p>Custom Domains: You can map custom domains via the Cloud Run settings.</p> </li> <li> <p>Secret Management: Consider using Secret Manager for managing sensitive environment variables.</p> </li> <li> <p>Cold Starts: To reduce cold start latency, set a minimum number of instances:</p> </li> </ul> <pre><code>--min-instances=1\n</code></pre> <ul> <li>Monitoring: Utilize Cloud Monitoring for detailed metrics and alerts.</li> </ul>"},{"location":"deployment/google-cloud-run/#feature-summary","title":"\ud83e\udde9 Feature Summary","text":"Feature Supported HTTPS (built-in) \u2705 Custom domains \u2705 PostgreSQL (Cloud SQL) \u2705 Redis (Memorystore) \u2705 Auto-scaling \u2705 Scale-to-zero \u2705 Max instance limit \u2705"},{"location":"deployment/google-cloud-run/#additional-resources","title":"\ud83e\udde0 Additional Resources","text":"<ul> <li>Cloud Run Documentation</li> <li>Cloud SQL for PostgreSQL Documentation</li> <li>Memorystore for Redis Documentation</li> <li>Google Cloud SDK Installation Guide</li> <li>Cloud Run Pricing</li> <li>Cloud SQL Pricing</li> <li>Memorystore Pricing</li> </ul> <p>By following this guide, you can deploy MCP Gateway on Google Cloud Run using the most cost-effective configurations, ensuring efficient resource utilization and seamless scalability.</p>"},{"location":"deployment/helm/","title":"\ud83d\ude80 Deploying the MCP Gateway Stack with Helm","text":"<p>This guide walks you through installing, upgrading, and removing the full MCP Gateway Stack using Helm. The stack includes:</p> <ul> <li>\ud83e\udde0 MCP Context Forge (the gateway)</li> <li>\ud83d\uddc4 PostgreSQL database</li> <li>\u26a1 Redis cache</li> <li>\ud83e\uddd1\ud83d\udcbb PgAdmin UI (optional)</li> <li>\ud83e\uddf0 Redis Commander UI (optional)</li> </ul> <p>Everything is deployable via Helm on any Kubernetes cluster (Minikube, kind, EKS, AKS, GKE, OpenShift, etc.).</p> <p>\ud83d\udce6 Helm chart location: https://github.com/IBM/mcp-context-forge/tree/main/charts/mcp-stack</p>"},{"location":"deployment/helm/#architecture","title":"\ud83e\udded Architecture","text":"<pre><code>flowchart TD\n    subgraph Ingress Layer\n        ingress[NGINX Ingress Controller]\n    end\n\n    subgraph Application Layer\n        mcp[MCP Context Forge]\n        pgadmin[PgAdmin UI&lt;br/&gt;optional]\n        rediscommander[Redis Commander UI&lt;br/&gt;optional]\n    end\n\n    subgraph Data Layer\n        postgres[(PostgreSQL)]\n        redis[(Redis)]\n    end\n\n    ingress --&gt; mcp\n    ingress --&gt; pgadmin\n    ingress --&gt; rediscommander\n\n    mcp --&gt; postgres\n    mcp --&gt; redis\n\n    pgadmin --&gt; postgres\n    rediscommander --&gt; redis</code></pre>"},{"location":"deployment/helm/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"Requirement Notes Kubernetes \u2265 1.23 Local (Minikube/kind) or managed (EKS, AKS, GKE, etc.) Helm 3 Used for installing and managing releases kubectl Configured to talk to your target cluster Ingress Controller NGINX, Traefik, or cloud-native (or disable via values.yaml) StorageClass (RWX) Required for PostgreSQL PVC unless persistence is disabled \u2705 Pre-flight Checklist (Run Before Deploying) <p>Ensure these checks pass before installing the stack.</p> What cluster am I connected to?Do I have the right permissions?Is my Kubernetes version compatible?Is a StorageClass with RWX access available?Is an Ingress controller installed? <pre><code>kubectl config current-context\nkubectl cluster-info\n</code></pre> <p>Verify you're pointing to the intended cluster context.</p> <pre><code>kubectl auth can-i create namespace\nkubectl auth can-i create deployment -n default\nkubectl auth can-i create clusterrolebinding\n</code></pre> <p>Confirm you have adequate access (or switch to a namespace where you do).</p> <pre><code>kubectl version -o json | jq -r '.serverVersion.gitVersion'\n</code></pre> <p>Must be <code>v1.23</code> or higher. Some Helm charts and features depend on it.</p> <pre><code>kubectl get sc\n</code></pre> <p>Required for persistent volumes (e.g., PostgreSQL).</p> <pre><code>kubectl get pods -A | grep -E 'ingress|traefik|nginx' || echo \"No ingress controller found\"\n</code></pre> <p>If not, deploy one or disable ingress in <code>values.yaml</code>.</p> \ud83d\udee0 Install Helm &amp; kubectl <p>You'll need both Helm and kubectl installed to deploy the stack.</p> macOSLinuxWindows (PowerShell)Verify installation <pre><code>brew install helm kubernetes-cli\n</code></pre> <p>Uses Homebrew to install both tools in one step.</p> <pre><code># Helm\ncurl -fsSL https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\n\n# kubectl\ncurl -LO \"https://dl.k8s.io/release/$(curl -sSL https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\nchmod +x kubectl\nsudo mv kubectl /usr/local/bin\n</code></pre> <p>Installs latest stable versions directly from official sources.</p> <pre><code>choco install -y kubernetes-helm kubernetes-cli\n</code></pre> <p>Requires Chocolatey to be installed first.</p> <pre><code>helm version\nkubectl version\nkubectl config get-contexts\n</code></pre> <p>Confirm both tools are installed and kubectl is configured for your cluster.</p> \ud83d\udce6 Clone and inspect the chart <pre><code>git clone https://github.com/IBM/mcp-context-forge.git\ncd mcp-context-forge/charts/mcp-stack\nhelm lint .\n</code></pre> \u2705 RBAC test (if enabled) <p>Confirm the service account created by the chart can access resources as expected.</p> Test using impersonationIf denied, check RBAC status <pre><code>kubectl auth can-i list pods \\\n  --as=system:serviceaccount:mcp-private:mcp-stack-sa \\\n  -n mcp-private\n</code></pre> <pre><code>kubectl get role,rolebinding -n mcp-private\nkubectl describe role mcp-stack-role -n mcp-private\n</code></pre> \ud83d\udd10 Prepare the Namespace (Recommended) <p>It's best practice to isolate the stack in its own namespace, with labels and policies for security and clarity.</p> Create the namespaceAdd environment labels and annotationsOptional: Apply default-deny NetworkPolicyVerify the namespace is ready <pre><code>kubectl create namespace mcp-private --dry-run=client -o yaml | kubectl apply -f -\n</code></pre> <p>You can use a different name (e.g. <code>mcp</code>, <code>prod-gateway</code>) as long as you reference it consistently in your Helm commands.</p> <pre><code>kubectl label namespace mcp-private environment=prod --overwrite\nkubectl annotate namespace mcp-private \"config.kubernetes.io/owner=mcp\" --overwrite\n</code></pre> <p>Labels and annotations can help with GitOps sync, audit, and tracking tools.</p> <pre><code>cat &lt;&lt;'EOF' | kubectl apply -n mcp-private -f -\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: deny-by-default\nspec:\n  podSelector: {}\n  policyTypes: [Ingress, Egress]\nEOF\n</code></pre> <p>This restricts all traffic by default. You'll need to define allowed communication between components separately, or use service mesh policies.</p> <pre><code>kubectl get ns mcp-private\nkubectl get networkpolicy -n mcp-private\nkubectl get sa default -n mcp-private -o yaml\n</code></pre> <p>Confirm that the namespace exists and basic policies are in place.</p>"},{"location":"deployment/helm/#customize-values","title":"\ud83e\uddfe Customize values","text":"\ud83e\uddfe Customize values.yaml <p>Copy and edit the default values file to tailor the deployment to your environment.</p> Clone and copy the values fileEdit values for your environmentValidate the chart after customizing <pre><code>cp values.yaml my-values.yaml\n</code></pre> <p>This gives you a working copy of the Helm chart and lets you customize settings safely.</p> <pre><code>mcpContextForge:\n  image:\n    repository: ghcr.io/ibm/mcp-context-forge\n    tag: v1.0.0\n  ingress:\n    enabled: true\n    host: gateway.local        # Change this to your actual DNS\n    className: nginx\n\n  envFrom:\n    - secretRef:\n        name: mcp-gateway-secret\n    - configMapRef:\n        name: mcp-gateway-config\n\npostgres:\n  credentials:\n    user: admin\n    password: S3cuReP@ss       # Avoid hardcoding in production\n  persistence:\n    size: 10Gi\n\npgadmin:\n  enabled: false\n\nredisCommander:\n  enabled: false\n\nrbac:\n  create: true\n</code></pre> <p>This configures image version, ingress host, secrets, storage, and RBAC. In production, prefer secrets over inline passwords.</p> <pre><code>helm lint .\n</code></pre> <p>Ensures the chart is valid and ready to install.</p>"},{"location":"deployment/helm/#install-upgrade-the-stack","title":"\ud83d\ude80 Install / Upgrade the stack","text":"\ud83d\ude80 Install or Upgrade the Stack <p>Install the MCP Gateway Stack into your Kubernetes cluster using Helm. This will deploy all components defined in your <code>my-values.yaml</code>.</p> Install for the first timeWhat does this deploy?Need to re-run install? <pre><code>helm upgrade --install mcp-stack . \\\n  --namespace mcp-private \\\n  --create-namespace=false \\\n  -f my-values.yaml \\\n  --wait --timeout 30m --debug\n</code></pre> <p>This installs or upgrades the stack in the <code>mcp-private</code> namespace, using your custom values file. Set <code>--create-namespace=true</code> if the namespace hasn't been created yet.</p> <ul> <li>MCP Context Forge (API Gateway)</li> <li>PostgreSQL with optional persistence</li> <li>Redis cache</li> <li>(Optional) PgAdmin &amp; Redis Commander</li> <li>Ingress configuration (if enabled)</li> <li>NetworkPolicy and RBAC (if configured)</li> </ul> <p>Helm upgrades are idempotent. You can run the same command again safely after making changes to <code>my-values.yaml</code>.</p>"},{"location":"deployment/helm/#verify-deployment","title":"\u2705 Verify deployment","text":"\u2705 Verify Deployment <p>After installation completes, confirm that all resources are running and healthy.</p> Check all resources in the namespaceVerify Ingress (if enabled)If not using Ingress: port forwardCheck logs and pod status (optional) <pre><code>kubectl get all -n mcp-private\nhelm status mcp-stack -n mcp-private\n</code></pre> <p>This should show running pods, services, deployments, and Helm release status.</p> <pre><code>kubectl get ingress -n mcp-private\ncurl http://gateway.local/health\n</code></pre> <p>You should see a <code>200 OK</code> response or similar from the health endpoint.</p> <pre><code>kubectl port-forward svc/mcp-stack-app 8080:80 -n mcp-private\ncurl http://localhost:8080/health\n</code></pre> <p>Port-forwarding gives you local access to the service when Ingress is disabled or not ready.</p> <pre><code>kubectl logs -n mcp-private deploy/mcp-stack-app --tail=50\nkubectl describe pod -l app.kubernetes.io/instance=mcp-stack -n mcp-private\n</code></pre> <p>Useful for debugging if components are not responding or entering <code>CrashLoopBackOff</code>.</p>"},{"location":"deployment/helm/#upgrade-rollback","title":"\ud83d\udd04 Upgrade &amp; Rollback","text":"\ud83d\udd04 Upgrade &amp; Rollback <p>You can upgrade to a new image version, preview changes before applying, or roll back to a previous release.</p> Upgrade to a new image versionPreview changes before upgradingRoll back to a previous revision <pre><code>helm upgrade mcp-stack . -n mcp-private \\\n  --set mcpContextForge.image.tag=v1.2.3 \\\n  --wait\n</code></pre> <p>Updates only the image tag (or any specific value you override) while preserving existing resources.</p> <pre><code>helm plugin install https://github.com/databus23/helm-diff\nhelm diff upgrade mcp-stack . -n mcp-private -f my-values.yaml\n</code></pre> <p>Shows what will change without applying anything. Requires the helm-diff plugin.</p> <pre><code>helm rollback mcp-stack 1 -n mcp-private\n</code></pre> <p>Use <code>helm history mcp-stack -n mcp-private</code> to list available revisions before rolling back.</p>"},{"location":"deployment/helm/#uninstall","title":"\ud83e\uddf9 Uninstall","text":"\ud83e\uddf9 Uninstall the Stack <p>This removes all components deployed by the Helm chart.</p> Basic uninstallDelete the namespace (optional)Full reset workflow <pre><code>helm uninstall mcp-stack -n mcp-private\n</code></pre> <p>Removes deployments, services, and related resources created by the chart.</p> <pre><code>kubectl delete namespace mcp-private\n</code></pre> <p>Use this if you want to fully clean up everything, including secrets, configmaps, and PVCs.</p> <pre><code># Uninstall the Helm release\nhelm uninstall mcp-stack -n mcp-private\n\n# Delete PVCs if you're not keeping data\nkubectl delete pvc --all -n mcp-private\n\n# Delete the namespace\nkubectl delete namespace mcp-private\n\n# Reinstall from scratch (if desired)\nhelm upgrade --install mcp-stack . \\\n  --namespace mcp-private \\\n  -f my-values.yaml \\\n  --wait --timeout 15m --debug\n</code></pre> <p>Use this flow when you need to wipe the environment and redeploy fresh.</p>"},{"location":"deployment/helm/#cicd-packaging-oci-push","title":"\ud83e\uddea CI/CD: Packaging &amp; OCI Push","text":"\ud83e\uddea CI/CD: Packaging &amp; OCI Push <p>Package your Helm chart and push it to an OCI-compliant registry for use in GitOps workflows (e.g., Argo CD, Flux).</p> Lint and package the chartPush to OCI registryWhy use OCI?Example: using in GitOps <pre><code>helm lint .\nhelm package . -d dist/\n</code></pre> <p>This validates your chart and creates a <code>.tgz</code> package in the <code>dist/</code> directory.</p> <pre><code>helm push dist/mcp-stack-*.tgz oci://ghcr.io/&lt;your-org&gt;/charts\n</code></pre> <p>Replace <code>&lt;your-org&gt;</code> with your GitHub container registry org. Make sure <code>HELM_EXPERIMENTAL_OCI=1</code> is set if using older Helm versions.</p> <ul> <li>Works with private registries</li> <li>Easily versioned and managed</li> <li>Supported by Argo CD and Flux natively</li> </ul> <p>Reference the chart by OCI URL in your GitOps tool:</p> <pre><code>oci://ghcr.io/your-org/charts/mcp-stack\n</code></pre> <p>Then sync as usual using your preferred tool.</p>"},{"location":"deployment/helm/#troubleshooting","title":"\ud83e\uddef Troubleshooting","text":"\ud83e\uddef Troubleshooting Common Issues <p>Quick fixes and diagnostic tips for common deployment problems.</p> <code>ImagePullBackOff</code><code>Ingress returns 404</code> or no external IP<code>CrashLoopBackOff</code> on a pod<code>Env vars missing</code> (e.g., BASIC_AUTH_USER)<code>RBAC access denied</code> <ul> <li>Cause: Image not found or access denied</li> <li>Fix:   <pre><code>kubectl describe pod -n mcp-private\n</code></pre></li> <li>Check <code>image:</code> field in <code>values.yaml</code></li> <li>Ensure the image tag exists and is publicly accessible (or add a pull secret)</li> </ul> <ul> <li>Cause: Ingress host mismatch or controller not ready</li> <li>Fix:   <pre><code>kubectl get ingress -n mcp-private\nkubectl get svc -A | grep ingress\n</code></pre></li> <li>Make sure the ingress hostname matches DNS or <code>/etc/hosts</code></li> <li>Confirm an Ingress Controller is deployed and available</li> </ul> <ul> <li>Fix:   <pre><code>kubectl logs -n mcp-private &lt;pod-name&gt;\nkubectl describe pod &lt;pod-name&gt; -n mcp-private\n</code></pre></li> </ul> <p>Check logs for configuration or secret injection issues.</p> <ul> <li>Cause: Secret or ConfigMap not mounted</li> <li>Fix: Confirm <code>envFrom</code> is configured in your <code>my-values.yaml</code> and the resources exist:</li> </ul> <pre><code>kubectl get secret mcp-gateway-secret -n mcp-private\nkubectl get configmap mcp-gateway-config -n mcp-private\n</code></pre> <ul> <li>Fix: Ensure RBAC roles are created properly:   <pre><code>kubectl get role,rolebinding -n mcp-private\n</code></pre></li> </ul> <p>You can also enable auto-RBAC creation with:</p> <pre><code>rbac:\n  create: true\n</code></pre>"},{"location":"deployment/helm/#valuesyaml-common-keys","title":"\ud83e\uddfe values.yaml - Common Keys","text":"\ud83e\uddfe values.yaml - Common Keys Reference <p>Most frequently used keys in <code>values.yaml</code> and what they control.</p> Key Default Description <code>mcpContextForge.image.tag</code> <code>latest</code> Image version for MCP Context Forge <code>mcpContextForge.ingress.enabled</code> <code>true</code> Enables ingress resource creation <code>mcpContextForge.ingress.host</code> <code>gateway.local</code> Hostname used in Ingress (change in production) <code>mcpContextForge.service.type</code> <code>ClusterIP</code> Use <code>LoadBalancer</code> if running in cloud <code>mcpContextForge.envFrom</code> <code>[]</code> Allows mounting Secrets/ConfigMaps as env vars <code>postgres.credentials.user</code> <code>admin</code> Default DB username (use secret in prod) <code>postgres.credentials.password</code> <code>test123</code> Default DB password (avoid hardcoding) <code>postgres.persistence.enabled</code> <code>true</code> Enables persistent volume claim for PostgreSQL <code>postgres.persistence.size</code> <code>10Gi</code> Size of the PostgreSQL volume <code>pgadmin.enabled</code> <code>false</code> Enable PgAdmin for DB UI <code>redisCommander.enabled</code> <code>false</code> Enable Redis Commander for Redis UI <code>rbac.create</code> <code>true</code> Automatically create Role/RoleBinding <p>\ud83d\udcdd For all possible options, see the full <code>values.yaml</code> file in the chart repository.</p> <p>See full annotations in <code>values.yaml</code>.</p>"},{"location":"deployment/helm/#further-reading","title":"\ud83d\udcda Further Reading","text":"\ud83d\udcda Further Reading &amp; References <p>Useful links to understand Helm, Kubernetes, and GitOps tools used with the MCP stack.</p> HelmKubernetesGitOps Tools <ul> <li>\ud83d\udcd8 Helm Documentation</li> <li>\ud83d\udd27 Helm Diff Plugin</li> <li>\ud83d\udce6 Helm OCI Registry Docs</li> </ul> <ul> <li>\ud83d\udcd8 Kubernetes Ingress</li> <li>\ud83d\udcbe Persistent Volumes</li> <li>\ud83d\udd10 Kubernetes Secrets</li> <li>\ud83d\udd12 Network Policies</li> </ul> <ul> <li>\ud83d\ude80 Argo CD</li> <li>\ud83d\udd01 Flux</li> </ul> <p>\u2705 You now have a production-ready Helm workflow for MCP Context Forge. It's CI-friendly, customizable, and tested across Kubernetes distributions.</p>"},{"location":"deployment/ibm-code-engine/","title":"\u2699\ufe0f IBM Code Engine","text":"<p>This guide covers two supported deployment paths for the MCP Gateway:</p> <ol> <li>Makefile automation - a single-command workflow that wraps <code>ibmcloud</code> CLI.</li> <li>Manual IBM Cloud CLI - the raw commands the Makefile executes, for fine-grained control.</li> </ol>"},{"location":"deployment/ibm-code-engine/#1-prerequisites","title":"1 - Prerequisites","text":"Requirement Details IBM Cloud account Create one if needed Docker or Podman Builds the production container image locally IBM Cloud CLI \u2265 2.16 Installed automatically with <code>make ibmcloud-cli-install</code> Code Engine project Create or select one in the IBM Cloud console <code>.env</code> file Runtime secrets &amp; config for the gateway <code>.env.ce</code> file Deployment credentials &amp; metadata for Code Engine / Container Reg."},{"location":"deployment/ibm-code-engine/#2-environment-files","title":"2 - Environment files","text":"<p>Both files are already in <code>.gitignore</code>. Template named <code>.env.example</code> <code>.env.ce.example</code> and are included; copy them:</p> <pre><code>cp .env.example .env         # runtime settings (inside the container)\ncp .env.ce.example .env.ce   # deployment credentials (CLI only)\n</code></pre>"},{"location":"deployment/ibm-code-engine/#env-runtime-settings","title":"<code>.env</code> - runtime settings","text":"<p>This file is mounted into the container (via <code>--env-file=.env</code>), so its keys live inside Code Engine at runtime. Treat it as an application secret store.</p> <pre><code># \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n#  Core gateway settings\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nAUTH_REQUIRED=true\n# Generate once:  openssl rand -hex 32\nJWT_SECRET_KEY=eef5e9f70ca7fe6f9677ad2acaf4d32c55e9d98e9cb74299b33f5c5d1a3c8ef\n\nHOST=0.0.0.0\nPORT=4444\n\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n#  Database configuration  - choose ONE block\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n## (A) Local SQLite  (good for smoke-tests / CI only)\n## --------------------------------------------------\n## - SQLite lives on the container's ephemeral file system.\n## - On Code Engine every new instance starts fresh; scale-out, restarts or\n##   deploys will wipe data.  **Not suitable for production.**\n## - If you still need file persistence, attach Code Engine's file-system\n##   mount or an external filesystem / COS bucket.\n#CACHE_TYPE=database\n#DATABASE_URL=sqlite:////tmp/mcp.db\n\n\n## (B) Managed PostgreSQL on IBM Cloud  (recommended for staging/production)\n## --------------------------------------------------------------------------\n## - Provision an IBM Cloud Databases for PostgreSQL instance (see below).\n## - Use the service credentials to build the URL.\n## - sslmode=require is mandatory for IBM Cloud databases.\nCACHE_TYPE=database\nDATABASE_URL=postgresql://pguser:pgpass@my-pg-host.databases.appdomain.cloud:32727/mcpgwdb?sslmode=require\n#            \u2502 \u2502      \u2502                                   \u2502           \u2502\n#            \u2502 \u2502      \u2502                                   \u2502           \u2514\u2500 database name\n#            \u2502 \u2502      \u2502                                   \u2514\u2500 hostname:port\n#            \u2502 \u2502      \u2514\u2500 password\n#            \u2502 \u2514\u2500 username\n#            \u2514\u2500 scheme\n</code></pre> <p>The <code>JWT_SECRET_KEY</code> variable is used to generate a Bearer token used to access the APIs. To access the APIs you need to generate your JWT token using the same <code>JWT_SECRET_KEY</code>, for example:</p> <pre><code># Generate a one-off token for the default admin user\nexport MCPGATEWAY_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token -u admin)\necho ${MCPGATEWAY_BEARER_TOKEN} # Check that the key was generated\n</code></pre>"},{"location":"deployment/ibm-code-engine/#envce-code-engine-deployment-settings","title":"<code>.env.ce</code> - Code Engine deployment settings","text":"<p>These keys are only consumed by Makefile / CLI. They never reach the running container.</p> <pre><code># \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n#  IBM Cloud / Code Engine deployment variables\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nIBMCLOUD_REGION=us-south\nIBMCLOUD_RESOURCE_GROUP=default\nIBMCLOUD_PROJECT=my-codeengine-project\nIBMCLOUD_CODE_ENGINE_APP=mcpgateway\n\n# Image details\nIBMCLOUD_IMAGE_NAME=us.icr.io/myspace/mcpgateway:latest  # target in IBM Container Registry\nIBMCLOUD_IMG_PROD=mcpgateway/mcpgateway                  # local tag produced by Make\n\n# Authentication\nIBMCLOUD_API_KEY=***your-api-key***    # leave blank to use SSO flow at login\n\n# Resource combo - see https://cloud.ibm.com/docs/codeengine?topic=codeengine-mem-cpu-combo\nIBMCLOUD_CPU=1                         # vCPU for the container\nIBMCLOUD_MEMORY=4G                     # Memory (must match a valid CPU/MEM pair)\n\n# Registry secret in Code Engine (first-time creation is automated)\nIBMCLOUD_REGISTRY_SECRET=my-regcred\n</code></pre> <p>Tip: run <code>make ibmcloud-check-env</code> to verify every required <code>IBMCLOUD_*</code> key is present in <code>.env.ce</code>.</p>"},{"location":"deployment/ibm-code-engine/#3-workflow-a-makefile-targets","title":"3 - Workflow A - Makefile targets","text":"Target Action it performs <code>podman</code> / <code>docker</code> Build the production image (<code>$IBMCLOUD_IMG_PROD</code>). <code>ibmcloud-cli-install</code> Install IBM Cloud CLI + container-registry and code-engine plugins. <code>ibmcloud-check-env</code> Ensure all <code>IBMCLOUD_*</code> vars exist in <code>.env.ce</code>; abort if any are missing. <code>ibmcloud-login</code> <code>ibmcloud login</code> - uses API key or interactive SSO. <code>ibmcloud-ce-login</code> <code>ibmcloud ce project select --name $IBMCLOUD_PROJECT</code>. <code>ibmcloud-list-containers</code> Show ICR images and existing Code Engine apps. <code>ibmcloud-tag</code> <code>podman tag $IBMCLOUD_IMG_PROD $IBMCLOUD_IMAGE_NAME</code>. <code>ibmcloud-push</code> <code>ibmcloud cr login</code> + <code>podman push</code> to ICR. <code>ibmcloud-deploy</code> Create or update the app, set CPU/MEM, attach registry secret, expose port 4444. <code>ibmcloud-ce-status</code> <code>ibmcloud ce application get</code> - see route URL, revisions, health. <code>ibmcloud-ce-logs</code> <code>ibmcloud ce application logs --follow</code> - live log stream. <code>ibmcloud-ce-rm</code> Delete the application entirely. <p>Typical first deploy</p> <pre><code>make ibmcloud-check-env\nmake ibmcloud-cli-install\nmake ibmcloud-login\nmake ibmcloud-ce-login\nmake podman            # or: make docker\nmake ibmcloud-tag\nmake ibmcloud-push\nmake ibmcloud-deploy\n</code></pre> <p>Redeploy after code changes</p> <pre><code>make podman ibmcloud-tag ibmcloud-push ibmcloud-deploy\n</code></pre>"},{"location":"deployment/ibm-code-engine/#4-workflow-b-manual-ibm-cloud-cli","title":"4 - Workflow B - Manual IBM Cloud CLI","text":"<pre><code># 1 - Install CLI + plugins\ncurl -fsSL https://clis.cloud.ibm.com/install/linux | sh\nibmcloud plugin install container-registry -f\nibmcloud plugin install code-engine      -f\n\n# 2 - Login\nibmcloud login --apikey \"$IBMCLOUD_API_KEY\" -r \"$IBMCLOUD_REGION\" -g \"$IBMCLOUD_RESOURCE_GROUP\"\nibmcloud resource groups # list resource groups\n\n# 3 - Target Code Engine project\nibmcloud ce project list # list current projects\nibmcloud ce project select --name \"$IBMCLOUD_PROJECT\"\n\n# 4 - Build + tag image\npodman build -t \"$IBMCLOUD_IMG_PROD\" .\npodman tag \"$IBMCLOUD_IMG_PROD\" \"$IBMCLOUD_IMAGE_NAME\"\n\n# 5 - Push image to ICR\nibmcloud cr login\nibmcloud cr namespaces       # Ensure your namespace exists\npodman push \"$IBMCLOUD_IMAGE_NAME\"\nibmcloud cr images # list images\n\n# 6 - Create registry secret (first time)\nibmcloud ce registry create-secret --name \"$IBMCLOUD_REGISTRY_SECRET\" \\\n    --server \"$(echo \"$IBMCLOUD_IMAGE_NAME\" | cut -d/ -f1)\" \\\n    --username iamapikey --password \"$IBMCLOUD_API_KEY\"\nibmcloud ce secret list # list every secret (generic, registry, SSH, TLS, etc.)\nibmcloud ce secret get --name \"$IBMCLOUD_REGISTRY_SECRET\"         # add --decode to see clear-text values\n\n# 7 - Deploy / update\nif ibmcloud ce application get --name \"$IBMCLOUD_CODE_ENGINE_APP\" &gt;/dev/null 2&gt;&amp;1; then\n  ibmcloud ce application update --name \"$IBMCLOUD_CODE_ENGINE_APP\" \\\n      --image \"$IBMCLOUD_IMAGE_NAME\" \\\n      --cpu \"$IBMCLOUD_CPU\" --memory \"$IBMCLOUD_MEMORY\" \\\n      --registry-secret \"$IBMCLOUD_REGISTRY_SECRET\"\nelse\n  ibmcloud ce application create --name \"$IBMCLOUD_CODE_ENGINE_APP\" \\\n      --image \"$IBMCLOUD_IMAGE_NAME\" \\\n      --cpu \"$IBMCLOUD_CPU\" --memory \"$IBMCLOUD_MEMORY\" \\\n      --port 4444 \\\n      --registry-secret \"$IBMCLOUD_REGISTRY_SECRET\"\nfi\n\n# 8 - Status &amp; logs\nibmcloud ce application get --name \"$IBMCLOUD_CODE_ENGINE_APP\"\nibmcloud ce application events --name \"$IBMCLOUD_CODE_ENGINE_APP\"\nibmcloud ce application get   --name \"$IBMCLOUD_CODE_ENGINE_APP\"\nibmcloud ce application logs  --name \"$IBMCLOUD_CODE_ENGINE_APP\" --follow\n</code></pre>"},{"location":"deployment/ibm-code-engine/#5-accessing-the-gateway","title":"5 - Accessing the gateway","text":"<pre><code>ibmcloud ce application get --name \"$IBMCLOUD_CODE_ENGINE_APP\" --output url\n</code></pre> <p>Open the returned URL (e.g. <code>https://mcpgateway.us-south.codeengine.appdomain.cloud/admin</code>) and log in with the basic-auth credentials from <code>.env</code>.</p> <p>Test the API endpoints with the generated <code>MCPGATEWAY_BEARER_TOKEN</code>:</p> <pre><code># Generate a one-off token for the default admin user\nexport MCPGATEWAY_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token -u admin)\n\n# Call a protected endpoint. Since there are not tools, initially this just returns `[]`\ncurl -H \"Authorization: Bearer ${MCPGATEWAY_BEARER_TOKEN}\" \\\n     https://mcpgateway.us-south.codeengine.appdomain.cloud/tools\n\n# Check the logs\nmake ibmcloud-ce-logs\n</code></pre>"},{"location":"deployment/ibm-code-engine/#6-cleanup","title":"6 - Cleanup","text":"<pre><code># via Makefile\nmake ibmcloud-ce-rm\n\n# or directly\nibmcloud ce application delete --name \"$IBMCLOUD_CODE_ENGINE_APP\" -f\n</code></pre>"},{"location":"deployment/ibm-code-engine/#7-using-ibm-cloud-databases-for-postgresql","title":"7 - Using IBM Cloud Databases for PostgreSQL","text":"<p>Need durable data, high availability, and automated backups? Provision IBM Cloud Databases for PostgreSQL and connect MCP Gateway to it.</p> <pre><code>###############################################################################\n# 1 - Provision PostgreSQL\n###############################################################################\n# Choose a plan:  standard (shared) or enterprise (dedicated). For small\n# workloads start with: standard / 1 member / 4 GB RAM.\nibmcloud resource service-instance-create mcpgw-db \\\n    databases-for-postgresql standard $IBMCLOUD_REGION\n\n###############################################################################\n# 2 - Create service credentials\n###############################################################################\nibmcloud resource service-key-create mcpgw-db-creds Administrator \\\n    --instance-name mcpgw-db\n\n###############################################################################\n# 3 - Retrieve credentials &amp; craft DATABASE_URL\n###############################################################################\ncreds_json=$(ibmcloud resource service-key mcpgw-db-creds --output json)\nhost=$(echo \"$creds_json\" | jq -r '.[0].credentials.connection.postgres.hosts[0].hostname')\nport=$(echo \"$creds_json\" | jq -r '.[0].credentials.connection.postgres.hosts[0].port')\nuser=$(echo \"$creds_json\" | jq -r '.[0].credentials.connection.postgres.authentication.username')\npass=$(echo \"$creds_json\" | jq -r '.[0].credentials.connection.postgres.authentication.password')\ndb=$(echo \"$creds_json\"   | jq -r '.[0].credentials.connection.postgres.database')\n\nDATABASE_URL=\"postgresql://${user}:${pass}@${host}:${port}/${db}?sslmode=require\"\n\n###############################################################################\n# 4 - Store DATABASE_URL as a Code Engine secret\n###############################################################################\nibmcloud ce secret create --name mcpgw-db-url \\\n    --from-literal DATABASE_URL=\"$DATABASE_URL\"\n\n###############################################################################\n# 5 - Mount the secret into the application\n###############################################################################\nibmcloud ce application update --name \"$IBMCLOUD_CODE_ENGINE_APP\" \\\n    --env-from-secret mcpgw-db-url\n</code></pre>"},{"location":"deployment/ibm-code-engine/#choosing-the-right-postgresql-size","title":"Choosing the right PostgreSQL size","text":"Workload profile Suggested plan Members \u00d7 RAM Notes Dev / PoC <code>standard</code> 1 \u00d7 4 GB Cheapest; no HA; easy to scale later Prod small <code>standard</code> 2 \u00d7 8 GB Two members enable HA &amp; automatic fail-over Prod heavy <code>enterprise</code> 3 \u00d7 16 GB Dedicated bare-metal; highest performance &amp; isolation <p>Scale up at any time with:</p> <pre><code>ibmcloud cdb deployment-scaling-set mcpgw-db \\\n    --members 3 --memory-gb 16\n\n# Update the number of maximum connections:\nibmcloud cdb deployment-configuration YOUR_DB_CRN '{\"configuration\":{\"max_connections\":215}}'\n\n# show max_connections;\n</code></pre> <p>The gateway will reconnect transparently because the host name remains stable. See the documentation for more details.</p>"},{"location":"deployment/ibm-code-engine/#local-sqlite-vs-managed-postgresql","title":"Local SQLite vs. Managed PostgreSQL","text":"Aspect Local SQLite (<code>sqlite:////tmp/mcp.db</code>) Managed PostgreSQL Persistence None - lost on restarts / scale-out Durable &amp; backed-up Concurrency Single-writer lock Multiple writers Scale-out ready No - state is per-pod Yes Best for Unit tests, CI pipelines Staging &amp; production <p>For production workloads you must switch to a managed database or mount a persistent file system.</p>"},{"location":"deployment/ibm-code-engine/#8-adding-ibm-cloud-databases-for-redis-optional-cache-layer","title":"8 - Adding IBM Cloud Databases for Redis (optional cache layer)","text":"<p>Need a high-performance shared cache? Provision IBM Cloud Databases for Redis and point MCP Gateway at it.</p> <pre><code>###############################################################################\n# 1 - Provision Redis\n###############################################################################\n# Choose a plan: standard (shared) or enterprise (dedicated).\nibmcloud resource service-instance-create mcpgw-redis \\\n    databases-for-redis standard $IBMCLOUD_REGION\n\n###############################################################################\n# 2 - Create service credentials\n###############################################################################\nibmcloud resource service-key-create mcpgw-redis-creds Administrator \\\n    --instance-name mcpgw-redis\n\n###############################################################################\n# 3 - Retrieve credentials &amp; craft REDIS_URL\n###############################################################################\ncreds_json=$(ibmcloud resource service-key mcpgw-redis-creds --output json)\nhost=$(echo \"$creds_json\" | jq -r '.[0].credentials.connection.rediss.hosts[0].hostname')\nport=$(echo \"$creds_json\" | jq -r '.[0].credentials.connection.rediss.hosts[0].port')\npass=$(echo \"$creds_json\" | jq -r '.[0].credentials.connection.rediss.authentication.password')\n\nREDIS_URL=\"rediss://:${pass}@${host}:${port}/0\"   # rediss = TLS-secured Redis\n\n###############################################################################\n# 4 - Store REDIS_URL as a Code Engine secret\n###############################################################################\nibmcloud ce secret create --name mcpgw-redis-url \\\n    --from-literal REDIS_URL=\"$REDIS_URL\"\n\n###############################################################################\n# 5 - Mount the secret and switch cache backend\n###############################################################################\nibmcloud ce application update --name \"$IBMCLOUD_CODE_ENGINE_APP\" \\\n    --env-from-secret mcpgw-redis-url \\\n    --env CACHE_TYPE=redis\n</code></pre>"},{"location":"deployment/ibm-code-engine/#choosing-the-right-redis-size","title":"Choosing the right Redis size","text":"Use-case Plan Memory Notes Dev / CI <code>standard</code> 256 MB Minimum footprint, single member Small production <code>standard</code> 1 GB Two-member HA cluster High-throughput <code>enterprise</code> \u22654 GB Dedicated nodes, persistence, AOF <p>Scale later with:</p> <pre><code>ibmcloud cdb deployment-scaling-set mcpgw-redis --memory-gb 4\n</code></pre> <p>Once redeployed, the gateway will use Redis for request-level caching, reducing latency and database load.</p>"},{"location":"deployment/ibm-code-engine/#9-gunicorn-configuration-optional-tuning","title":"9. Gunicorn configuration (optional tuning)","text":"<p>The container starts <code>gunicorn</code> with the settings defined in <code>gunicorn.conf.py</code> found at the project root. If you need to change worker counts, ports, or time-outs, edit this file before you build the image (<code>make podman</code> or <code>make docker</code>). The settings are baked into the container at build time.</p> <pre><code># -*- coding: utf-8 -*-\n\"\"\"\nGunicorn configuration\nDocs: https://docs.gunicorn.org/en/stable/settings.html\n\"\"\"\n\n# Network interface / port \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nbind = \"0.0.0.0:4444\"        # Listen on all interfaces, port 4444\n\n# Worker processes \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nworkers = 8                  # Rule of thumb: 2-4 \u00d7 NUM_CPU_CORES\n\n# Request/worker life-cycle \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ntimeout = 600                # Kill a worker after 600 s of no response\nmax_requests = 10000         # Restart worker after N requests\nmax_requests_jitter = 100    # Add randomness to avoid synchronized restarts\n\n# Logging &amp; verbosity \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nloglevel = \"info\"            # \"debug\", \"info\", \"warning\", \"error\", \"critical\"\n\n# Optimisations \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\npreload_app = True           # Load app code once in parent, fork workers (saves RAM)\nreuse_port  = True           # SO_REUSEPORT for quicker restarts\n\n# Alternative worker models (uncomment ONE and install extras) ----------\n# worker_class = \"gevent\"     # pip install \"gunicorn[gevent]\"\n# worker_class = \"eventlet\"   # pip install \"gunicorn[eventlet]\"\n# worker_class = \"tornado\"    # pip install \"gunicorn[tornado]\"\n# threads = 2                 # If using the 'sync' worker with threads\n\n# TLS certificates (if you terminate HTTPS inside the container)\n# certfile = 'certs/cert.pem'\n# keyfile  = 'certs/key.pem'\n\n# Server hooks (logging examples) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef when_ready(server):\n    server.log.info(\"Server is ready. Spawning workers\")\n\ndef post_fork(server, worker):\n    server.log.info(\"Worker spawned (pid: %s)\", worker.pid)\n\ndef worker_exit(server, worker):\n    server.log.info(\"Worker exit (pid: %s)\", worker.pid)\n</code></pre> <p>Typical tweaks</p> Scenario Setting(s) to adjust High-latency model calls \u2192 time-outs <code>timeout</code> (e.g. 1200 s) CPU-bound workload on 4-core instance <code>workers = 8</code> \u2192 <code>workers = 16</code> Memory-limited instance Reduce <code>workers</code> or disable <code>preload_app</code> Websocket / async traffic Switch <code>worker_class</code> to <code>gevent</code> or <code>eventlet</code> <p>After changing the file, rebuild and redeploy:</p> <pre><code>make podman ibmcloud-tag ibmcloud-push ibmcloud-deploy\n</code></pre>"},{"location":"deployment/kubernetes/","title":"\u2638\ufe0f Kubernetes / OpenShift Deployment","text":"<p>You can deploy MCP Gateway to any K8s-compliant platform - including vanilla Kubernetes, OpenShift, and managed clouds like GKE, AKS, and EKS.</p>"},{"location":"deployment/kubernetes/#quick-start-with-manifest-yaml","title":"\ud83d\ude80 Quick Start with Manifest (YAML)","text":"<p>A basic Kubernetes deployment might look like:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mcpgateway\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mcpgateway\n  template:\n    metadata:\n      labels:\n        app: mcpgateway\n    spec:\n      containers:\n        - name: gateway\n          image: ghcr.io/YOUR_ORG/mcpgateway:latest\n          ports:\n            - containerPort: 4444\n          envFrom:\n            - configMapRef:\n                name: mcpgateway-env\n          volumeMounts:\n            - mountPath: /app/.env\n              name: env-volume\n              subPath: .env\n      volumes:\n        - name: env-volume\n          configMap:\n            name: mcpgateway-env\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: mcpgateway\nspec:\n  selector:\n    app: mcpgateway\n  ports:\n    - port: 80\n      targetPort: 4444\n</code></pre> <p>Replace <code>ghcr.io/YOUR_ORG/mcpgateway</code> with your built image.</p>"},{"location":"deployment/kubernetes/#tls-ingress","title":"\ud83d\udd10 TLS &amp; Ingress","text":"<p>You can add:</p> <ul> <li>Cert-manager with TLS secrets</li> <li>An Ingress resource that routes to <code>/admin</code>, <code>/tools</code>, etc.</li> </ul> <p>Example Ingress snippet:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: mcpgateway\n  annotations:\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\nspec:\n  rules:\n    - host: gateway.example.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: mcpgateway\n                port:\n                  number: 80\n  tls:\n    - hosts:\n        - gateway.example.com\n      secretName: mcpgateway-tls\n</code></pre>"},{"location":"deployment/kubernetes/#configuration-via-configmap","title":"\ud83d\udce6 Configuration via ConfigMap","text":"<p>You can load your <code>.env</code> as a ConfigMap:</p> <pre><code>kubectl create configmap mcpgateway-env --from-env-file=.env\n</code></pre> <p>Make sure it includes <code>JWT_SECRET_KEY</code>, <code>AUTH_REQUIRED</code>, etc.</p>"},{"location":"deployment/kubernetes/#openshift-considerations","title":"\ud83d\udca1 OpenShift Considerations","text":"<ul> <li>Use <code>Route</code> instead of Ingress</li> <li>You may need to run the container as an unprivileged user</li> <li>Set <code>SECURITY_CONTEXT_RUNASUSER</code> if needed</li> </ul>"},{"location":"deployment/kubernetes/#health-check-probes","title":"\ud83e\uddea Health Check Probes","text":"<pre><code>livenessProbe:\n  httpGet:\n    path: /health\n    port: 4444\n  initialDelaySeconds: 10\n  periodSeconds: 15\n</code></pre>"},{"location":"deployment/local/","title":"\ud83d\udc0d Local Deployment","text":"<p>This guide walks you through running MCP Gateway on your local machine using a virtual environment or directly via Python.</p>"},{"location":"deployment/local/#one-liner-setup","title":"\ud83d\ude80 One-Liner Setup","text":"<p>The easiest way to start the server in development mode:</p> <pre><code>make venv install serve\n</code></pre> <p>This does the following:</p> <ol> <li>Creates a <code>.venv/</code> virtual environment</li> <li>Installs all dependencies (including dev tools)</li> <li>Launches Gunicorn on <code>http://localhost:4444</code></li> </ol>"},{"location":"deployment/local/#development-mode-with-live-reload","title":"\ud83e\uddea Development Mode with Live Reload","text":"<p>If you want auto-reload on code changes:</p> <pre><code>make run        # or:\n./run.sh --reload --log debug\n</code></pre> <p>Ensure your <code>.env</code> file includes:</p> <pre><code>DEV_MODE=true\nRELOAD=true\nDEBUG=true\n</code></pre>"},{"location":"deployment/local/#health-test","title":"\ud83e\uddea Health Test","text":"<pre><code>curl http://localhost:4444/health\n</code></pre> <p>Expected output:</p> <pre><code>{\"status\": \"healthy\"}\n</code></pre>"},{"location":"deployment/local/#admin-ui","title":"\ud83d\udd10 Admin UI","text":"<p>Visit http://localhost:4444/admin and login using your <code>BASIC_AUTH_USER</code> and <code>BASIC_AUTH_PASSWORD</code> from <code>.env</code>.</p>"},{"location":"deployment/local/#quick-jwt-setup","title":"\ud83d\udd01 Quick JWT Setup","text":"<pre><code>export MCPGATEWAY_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token -u admin)\ncurl -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" http://localhost:4444/tools\n</code></pre>"},{"location":"deployment/minikube/","title":"\u26a1\ufe0f Minikube","text":"<ol> <li>Install Minikube and kubectl (Docker or Podman driver required).</li> <li>Start a local cluster with Ingress and DNS addons.</li> <li>Load the <code>ghcr.io/ibm/mcp-context-forge:latest</code> image into Minikube.</li> <li>Apply your Kubernetes manifests.</li> <li>Access the Gateway at http://gateway.local or <code>127.0.0.1:80</code> via NGINX Ingress.</li> </ol> <p>Minikube provides a self-contained environment, enabling you to replicate production features like persistent volumes and TLS on your local machine.</p>"},{"location":"deployment/minikube/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"Requirement Notes CPU / RAM Minimum 2 vCPU + 2 GiB; recommended 4 vCPU / 6 GiB for smoother operation. Disk At least 20 GiB of free space. Container driver Docker 20.10+ or Podman 4.7+; Docker is the simplest choice on macOS and Windows. kubectl Automatically configured by <code>minikube start</code>; alternatively, use <code>minikube kubectl -- ...</code> if not installed."},{"location":"deployment/minikube/#architecture","title":"Architecture","text":"<pre><code>          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u2502      NGINX Ingress          \u2502\n          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502/          \u2502/\n      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n      \u2502  MCP Context Forge \u2502 \u2502 PgAdmin (opt.) \u2502\n      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502                 \u2502\n   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502    PostgreSQL     \u2502 \u2502 Redis Commander(opt)\u2502\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2502                     \u2502\n      \u250c\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510\n      \u2502   PV     \u2502          \u2502  Redis   \u2502\n      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"deployment/minikube/#step-1-install-minikube-and-kubectl","title":"\ud83d\ude80 Step 1 - Install Minikube and kubectl","text":"<p>Make target</p> <pre><code>make minikube-install\n</code></pre> <p>This target checks for existing installations of <code>minikube</code> and <code>kubectl</code>. If missing, it installs them using:</p> <ul> <li>Homebrew on macOS</li> <li>The official binary on Linux</li> <li>Chocolatey on Windows</li> </ul> Manual installation (optional)  ### macOS (Homebrew)  <pre><code>brew install minikube kubernetes-cli\n</code></pre>  ### Linux (Generic binary)  <pre><code># Minikube\ncurl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64\nsudo install minikube-linux-amd64 /usr/local/bin/minikube &amp;&amp; rm minikube-linux-amd64\n\n# kubectl (latest stable)\ncurl -LO \"https://dl.k8s.io/release/$(curl -sL https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\nchmod +x kubectl &amp;&amp; sudo mv kubectl /usr/local/bin/\n</code></pre>  ### Windows (PowerShell + Chocolatey)  <pre><code>choco install -y minikube kubernetes-cli\n</code></pre>"},{"location":"deployment/minikube/#step-2-start-the-cluster","title":"\u2699\ufe0f Step 2 - Start the cluster","text":"<p>Make target</p> <pre><code>make minikube-start\n</code></pre> Equivalent manual command <pre><code>minikube start \\\n  --driver=docker \\\n  --cpus=4 --memory=6g \\\n  --addons=ingress,ingress-dns \\\n  --profile=mcpgw\n</code></pre> <ul> <li><code>--driver=docker</code> avoids nested virtualization on macOS and Windows Home.</li> <li><code>ingress</code> provides an NGINX LoadBalancer on localhost.</li> <li><code>ingress-dns</code> resolves <code>*.local</code> domains when you add the Minikube IP to your OS DNS list.</li> <li><code>--cpus</code> and <code>--memory</code> can be set to <code>max</code> to utilize all available resources.</li> </ul> <p>Check cluster status:</p> <pre><code>make minikube-status\n# or:\nminikube status -p mcpgw\nkubectl get pods -n ingress-nginx\n</code></pre>"},{"location":"deployment/minikube/#step-3-load-the-gateway-image","title":"\ud83c\udfd7 Step 3 - Load the Gateway image","text":"<p>Make target</p> <pre><code>make minikube-image-load\n</code></pre> <p>This target builds the <code>ghcr.io/ibm/mcp-context-forge:latest</code> image and loads it into Minikube.</p>"},{"location":"deployment/minikube/#alternative-methods","title":"Alternative methods","text":"<ul> <li>Pre-cache a remote image:</li> </ul> <pre><code>minikube cache add ghcr.io/ibm/mcp-context-forge:latest\nminikube cache reload\n</code></pre> <ul> <li>Load a local tarball:</li> </ul> <pre><code>docker save ghcr.io/ibm/mcp-context-forge:latest | minikube image load -\n</code></pre>"},{"location":"deployment/minikube/#step-4-apply-kubernetes-manifests","title":"\ud83d\udcc4 Step 4 - Apply Kubernetes manifests","text":"<p>Make target</p> <pre><code>make minikube-k8s-apply\n</code></pre> <p>This applies the Kubernetes manifests. Alternative manual step:</p> <pre><code># PostgreSQL\nkubectl apply -f k8s/postgres-config.yaml\nkubectl apply -f k8s/postgres-pv.yaml\nkubectl apply -f k8s/postgres-pvc.yaml\nkubectl apply -f k8s/postgres-deployment.yaml\nkubectl apply -f k8s/postgres-service.yaml\n\n# Redis\nkubectl apply -f k8s/redis-deployment.yaml\nkubectl apply -f k8s/redis-service.yaml\n\n# MCP Gateway\nkubectl apply -f k8s/mcp-context-forge-deployment.yaml\nkubectl apply -f k8s/mcp-context-forge-service.yaml\nkubectl apply -f k8s/mcp-context-forge-ingress.yaml\n</code></pre> <p>If you've enabled <code>ingress-dns</code>, set the Ingress <code>host:</code> to <code>gateway.local</code>. Otherwise, omit the <code>host:</code> and access via NodePort.</p> <p>Note: Minikube automatically configures the <code>kubectl</code> context upon cluster creation. If not, set it manually:</p> <pre><code>kubectl config use-context minikube\n# or:\nminikube kubectl -- apply -f ...\n</code></pre>"},{"location":"deployment/minikube/#step-5-verify-deployment-status","title":"\ud83e\uddea Step 5 - Verify deployment status","text":"<p>Before hitting your endpoint, confirm the application is up and healthy.</p>"},{"location":"deployment/minikube/#check-pod-status","title":"\ud83d\udd0d Check pod status","text":"<pre><code>kubectl get pods\n</code></pre> <p>Expect output like:</p> <pre><code>NAME                                      READY   STATUS    RESTARTS   AGE\npostgres-5b66bdf445-rp8kl                 1/1     Running   0          15s\nredis-668976c4f9-2hljd                    1/1     Running   0          15s\nmcp-context-forge-6d87f8c5d8-nnmgx        1/1     Running   0          10s\n</code></pre>"},{"location":"deployment/minikube/#check-logs-optional","title":"\ud83d\udcdc Check logs (optional)","text":"<pre><code>kubectl logs deploy/mcp-context-forge\n</code></pre> <p>This can help diagnose startup errors or missing dependencies (e.g. bad env vars, Postgres connection issues).</p>"},{"location":"deployment/minikube/#wait-for-rollout-optional","title":"\ud83d\udea5 Wait for rollout (optional)","text":"<pre><code>kubectl rollout status deploy/mcp-context-forge\n</code></pre> <p>If the pod gets stuck in <code>CrashLoopBackOff</code>, run:</p> <pre><code>kubectl describe pod &lt;pod-name&gt;\n</code></pre> <p>And:</p> <pre><code>kubectl logs &lt;pod-name&gt;\n</code></pre>"},{"location":"deployment/minikube/#confirm-ingress-is-live","title":"\u2705 Confirm Ingress is live","text":"<pre><code>kubectl get ingress\n</code></pre> <p>Should show something like:</p> <pre><code>NAME                        CLASS    HOSTS           ADDRESS        PORTS   AGE\nmcp-context-forge-ingress   nginx    gateway.local   192.168.49.2   80      1m\n</code></pre> <p>If <code>ADDRESS</code> is empty, the ingress controller may still be warming up.</p> <p>You may want to add this to <code>/etc/hosts</code>. Ex:</p> <pre><code>192.168.49.2 gateway.local\n</code></pre>"},{"location":"deployment/minikube/#step-6-test-access","title":"\ud83c\udf10 Step 6 - Test access","text":"<pre><code># Via NodePort:\ncurl $(minikube service mcp-context-forge --url)/health\n\n# Via DNS:\ncurl http://gateway.local/health\n</code></pre>"},{"location":"deployment/minikube/#cleaning-up","title":"\ud83e\uddf9 Cleaning up","text":"Action Make target Manual command Pause cluster <code>make minikube-stop</code> <code>minikube stop -p mcpgw</code> Delete cluster <code>make minikube-delete</code> <code>minikube delete -p mcpgw</code> Remove cached image - <code>minikube cache delete ghcr.io/ibm/mcp-context-forge:latest</code>"},{"location":"deployment/minikube/#non-make-cheatsheet","title":"\ud83d\udee0 Non-Make cheatsheet","text":"Task Command Start with Podman driver <code>minikube start --driver=podman --network-plugin=cni</code> Open dashboard <code>minikube dashboard</code> SSH into node <code>minikube ssh</code> Enable metrics-server <code>minikube addons enable metrics-server</code> Upgrade Minikube (macOS) <code>minikube delete &amp;&amp; brew upgrade minikube</code>"},{"location":"deployment/minikube/#further-reading","title":"\ud83d\udcda Further reading","text":"<ol> <li> <p>Minikube Quick Start guide (official)    https://minikube.sigs.k8s.io/docs/start/</p> </li> <li> <p>Minikube Docker driver docs    https://minikube.sigs.k8s.io/docs/drivers/docker/</p> </li> <li> <p>Enable NGINX Ingress in Minikube    https://kubernetes.io/docs/tasks/access-application-cluster/ingress-minikube/</p> </li> <li> <p>Load / cache images inside Minikube    https://minikube.sigs.k8s.io/docs/handbook/pushing/</p> </li> <li> <p>Using Minikube's built-in kubectl    https://minikube.sigs.k8s.io/docs/handbook/kubectl/</p> </li> <li> <p>Allocate max CPU/RAM flags    https://minikube.sigs.k8s.io/docs/faq/#how-can-i-allocate-maximum-resources-to-minikube</p> </li> <li> <p>Ingress-DNS addon overview    https://minikube.sigs.k8s.io/docs/handbook/addons/ingress-dns/</p> </li> <li> <p>Stack Overflow: loading local images into Minikube    https://stackoverflow.com/questions/42564058/how-can-i-use-local-docker-images-with-minikube</p> </li> </ol> <p>Minikube gives you the fastest, vendor-neutral sandbox for experimenting with MCP Gateway-and everything above doubles as CI instructions for self-hosted GitHub runners or ephemeral integration tests.</p>"},{"location":"deployment/openshift/","title":"\u2728 Red Hat OpenShift","text":"<p>OpenShift (both OKD and Red Hat OpenShift Container Platform) adds opinionated security (SCC), integrated routing, and optional build pipelines on top of Kubernetes.  Deploying MCP Gateway therefore means (1) building or pulling a compatible image, (2) wiring database + cache back-ends, (3) obeying the default restricted-v2 SCC, and (4) exposing the service through a Route instead of an Ingress.  This guide walks through each step, offers ready-made YAML snippets, and explains the differences from the vanilla Kubernetes.</p>"},{"location":"deployment/openshift/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"<ul> <li><code>oc</code> CLI - log in as a developer to a project/namespace you can create objects in.</li> <li>A storage class for PVCs (or local PVs) to back the Postgres template.</li> <li>Either Podman or Docker on your workstation if you build locally.</li> <li>Access to an image registry that your cluster can pull from (e.g. <code>quay.io</code>).</li> </ul>"},{"location":"deployment/openshift/#build-push-images","title":"\ud83d\udee0\ufe0f Build &amp; push images","text":""},{"location":"deployment/openshift/#option-a-use-make","title":"Option A - Use Make","text":"Target Builds Dockerfile Notes <code>make podman</code> <code>mcpgateway-dev:latest</code> Containerfile Rootless Podman build <code>make podman-prod</code> <code>mcpgateway:latest</code> Containerfile.lite UBI 9-micro, multi-stage <code>make docker</code> <code>mcpgateway-dev:latest</code> Containerfile Docker Desktop <code>make docker-prod</code> <code>mcpgateway:latest</code> Containerfile.lite Same slim image <p>Push afterwards, for example:</p> <pre><code>podman tag mcpgateway:latest quay.io/YOUR_NS/mcpgateway:latest\npodman push quay.io/YOUR_NS/mcpgateway:latest\n</code></pre> <p>Apple-silicon note - <code>Containerfile.lite</code> uses <code>ubi9-micro</code> (x86_64). Buildx/QEMU works, but the image will run under emulation on macOS. If you need native arm64 choose the dev image or add <code>--platform linux/arm64</code>.</p>"},{"location":"deployment/openshift/#option-b-raw-cli-equivalents","title":"Option B - Raw CLI equivalents","text":"<pre><code># Dev (Containerfile)\npodman build -t mcpgateway-dev:latest -f Containerfile .\n\n# Prod (UBI micro, AMD64, squashed layers)\ndocker build --platform=linux/amd64 --squash \\\n  -t mcpgateway:latest -f Containerfile.lite .\n</code></pre>"},{"location":"deployment/openshift/#secrets-configmaps","title":"\ud83d\udd11 Secrets &amp; ConfigMaps","text":"<p>Create a ConfigMap from your <code>.env</code> file:</p> <pre><code>oc create configmap mcpgateway-env --from-env-file=.env   # Populates envFrom\n</code></pre> <p>OpenShift lets you inject all keys via <code>envFrom:</code> in the pod template.</p> <p>If you keep sensitive values (e.g. <code>JWT_SECRET_KEY</code>) separate, store them in a Secret and reference both resources under <code>envFrom:</code>.</p>"},{"location":"deployment/openshift/#postgresql-redis-back-ends","title":"\ud83d\uddc4 PostgreSQL &amp; Redis back-ends","text":""},{"location":"deployment/openshift/#postgresql-persistent-template","title":"PostgreSQL (persistent template)","text":"<pre><code>oc new-app -f https://raw.githubusercontent.com/openshift/origin/master/examples/db-templates/postgresql-persistent-template.json \\\n  -p POSTGRESQL_USER=postgres,POSTGRESQL_PASSWORD=secret,POSTGRESQL_DATABASE=mcp\n</code></pre> <p>The template creates a DeploymentConfig, Service and a 1 Gi PVC bound to the cluster's default storage class.</p>"},{"location":"deployment/openshift/#redis","title":"Redis","text":"<p>On OpenShift 4.x use the Redis Enterprise Operator from OperatorHub (UI or CLI) then create a RedisEnterpriseCluster CR; it provisions StatefulSets plus PVCs out-of-the-box.</p>"},{"location":"deployment/openshift/#deployment-service-gateway","title":"\ud83d\udce6 Deployment &amp; Service (gateway)","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mcpgateway\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mcpgateway\n  template:\n    metadata:\n      labels:\n        app: mcpgateway\n    spec:\n      securityContext:            # Must satisfy restricted-v2 SCC\n        runAsNonRoot: true\n      containers:\n      - name: gateway\n        image: quay.io/YOUR_NS/mcpgateway:latest\n        ports:\n        - containerPort: 4444\n        envFrom:\n        - configMapRef:\n            name: mcpgateway-env\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 4444\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 4444\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        securityContext:\n          allowPrivilegeEscalation: false\n          runAsUser: 1001        # UBI non-root UID works with restricted SCC\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: mcpgateway\nspec:\n  selector:\n    app: mcpgateway\n  ports:\n  - port: 80\n    targetPort: 4444\n</code></pre> <p>The readiness/liveness probes follow OpenShift's health-check guidance.</p>"},{"location":"deployment/openshift/#route-public-url","title":"\ud83c\udf0d Route (public URL)","text":"<pre><code>apiVersion: route.openshift.io/v1\nkind: Route\nmetadata:\n  name: mcpgateway\nspec:\n  to:\n    kind: Service\n    name: mcpgateway\n  port:\n    targetPort: 80\n  tls:\n    termination: edge\n</code></pre> <p>Routes are OpenShift's native form of ingress; the router automatically provisions a hostname such as <code>mcpgateway-myproj.apps.cluster.example.com</code>.</p>"},{"location":"deployment/openshift/#putting-it-together","title":"\ud83d\udcd1 Putting it together","text":"<pre><code># Apply manifests\noc apply -f postgres-template.yaml        # or Operator YAML\noc apply -f redis-operator.yaml           # if using Redis Operator\noc apply -f mcpgateway-deployment.yaml\noc apply -f mcpgateway-route.yaml\n</code></pre> <p>Verify:</p> <pre><code>oc get pods\noc get route mcpgateway -o jsonpath='{.spec.host}{\"\\n\"}'\ncurl https://$(oc get route mcpgateway -o jsonpath='{.spec.host}')/health\n</code></pre>"},{"location":"deployment/openshift/#openshift-buildconfig-optional","title":"\ud83d\udd04 OpenShift BuildConfig (optional)","text":"<p>If you prefer in-cluster builds, create a <code>BuildConfig</code> with the docker strategy. You can override the Dockerfile path via <code>spec.strategy.dockerStrategy.dockerfilePath</code>. Then trigger:</p> <pre><code>oc start-build mcpgateway --from-dir=.\n</code></pre> <p>The resulting image lands in an internal ImageStream, and the Deployment can auto-deploy the new tag.</p>"},{"location":"deployment/openshift/#persistence-pvcs","title":"\ud83d\uddc3 Persistence &amp; PVCs","text":"<p>The Postgres template already generates a PVC; you can create extra PVCs manually or via the web console. A general PVC manifest is shown in OpenShift Storage docs.</p>"},{"location":"deployment/openshift/#non-make-cheat-sheet","title":"\ud83d\udea6 Non-Make cheat-sheet","text":"Action Command Build dev image (local) <code>podman build -t mcpgateway-dev -f Containerfile .</code> Build prod (UBI lite) <code>docker build -t mcpgateway -f Containerfile.lite .</code> Push to Quay <code>podman push mcpgateway quay.io/NS/mcpgateway</code> Create project <code>oc new-project mcp-demo</code> Load .env <code>oc create configmap mcpgateway-env --from-env-file=.env</code> Deploy <code>oc apply -f mcpgateway-deployment.yaml</code> Expose <code>oc apply -f mcpgateway-route.yaml</code> Tail logs <code>oc logs -f deployment/mcpgateway</code>"},{"location":"deployment/openshift/#troubleshooting","title":"\ud83d\udee0 Troubleshooting","text":"Issue Fix <code>Error: container has runAsNonRoot and image has non-numeric user</code> Add <code>runAsUser: 1001</code> or pick <code>nonroot-v2</code> SCC. PVC stuck in <code>Pending</code> Check storage class or request size &gt; quota. Route returns 503 Verify pod readiness probe passes and the Service targets port 80 -&gt; 4444."},{"location":"deployment/openshift/#further-reading","title":"\ud83d\udcda Further reading","text":"<ol> <li>OpenShift Route documentation - creation &amp; TLS</li> <li>SCC and restricted-v2 / nonroot-v2 behaviour</li> <li>ConfigMap envFrom patterns</li> <li>Postgres persistent template example</li> <li>Redis Enterprise Operator on OCP (OperatorHub)</li> <li>Health-check probes in OpenShift</li> <li>BuildConfig Docker strategy &amp; <code>dockerfilePath</code></li> </ol>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/","title":"\ud83d\ude80 Deploying the MCP Gateway Stack to IBM Cloud Kubernetes Service with Argo CD","text":"<p>Work in progress</p> <p>This document is a WORK IN PROGRESS and is not yet ready for consumption.</p> <p>What you'll achieve</p> <ul> <li>Build or pull the OCI image(s) for MCP Gateway</li> <li>Push them to IBM Container Registry (ICR)</li> <li>Provision an IKS cluster with VPC-native networking</li> <li>Install &amp; bootstrap Argo CD for GitOps management</li> <li>Deploy the MCP Stack Helm chart via Argo CD</li> <li>Configure MCP Gateway with servers and tools</li> <li>Connect clients (VS Code Copilot, LangChain Agent, Claude Desktop)</li> <li>Set up observability, scaling, and managed databases</li> </ul>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#solution-architecture","title":"Solution Architecture","text":"<pre><code>flowchart TD\n    %% ---------------- Git ----------------\n    subgraph Git\n        repo[\"Helm values&lt;br/&gt;+ Argo App CR\"]\n    end\n\n    %% ---------------- CI/CD --------------\n    subgraph \"CI/CD\"\n        build[\"Build &amp;amp; Push&lt;br/&gt;OCI Image\"]\n    end\n\n    %% ---------------- IBM Cloud ----------\n    subgraph \"IBM Cloud\"\n        vpc[\"VPC + Subnets\"]\n        iks[\"IKS Cluster\"]\n        icr[\"ICR&lt;br/&gt;eu.icr.io\"]\n        argocd[\"Argo CD\"]\n        helm[\"Helm Release&lt;br/&gt;mcp-stack\"]\n        gateway[\"MCP Gateway Pods\"]\n        db[\"PostgreSQL PVC\"]\n        redis[\"Redis PVC\"]\n        kms[\"Key Protect KMS\"]\n        secrets[\"Secrets Manager\"]\n        logs[\"Cloud Logs\"]\n    end\n\n    %% ---------------- Clients ------------\n    subgraph Clients\n        vscode[\"VS Code Copilot\"]\n        claude[\"Claude Desktop\"]\n        langchain[\"LangChain Agent\"]\n    end\n\n    %% ---------- Styling for IBM Cloud ----\n    classDef cloud fill:#f5f5f5,stroke:#c6c6c6;\n    class vpc,iks,icr,argocd,helm,gateway,db,redis,kms,secrets,logs cloud;\n\n    %% ------------ Edges ------------------\n    repo   -- \"git push\"      --&gt; build\n    build  -- \"docker push\"   --&gt; icr\n    repo   -- \"App CR\"        --&gt; argocd\n    argocd -- \"helm upgrade\"  --&gt; iks\n    icr    -- \"ImagePull\"     --&gt; iks\n    iks    --&gt; db\n    iks    --&gt; redis\n    helm   -- \"Deploy\"        --&gt; gateway\n    secrets-- \"TLS certs\"     --&gt; iks\n    kms    -- \"encryption\"    --&gt; iks\n    logs   -- \"audit logs\"    --&gt; iks\n    gateway-- \"SSE/stdio\"     --&gt; vscode\n    gateway-- \"wrapper\"       --&gt; claude\n    gateway-- \"HTTP API\"      --&gt; langchain</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#prerequisites","title":"Prerequisites","text":"Requirement Minimum Reference IBM Cloud CLI \u2265 2.16 https://clis.cloud.ibm.com CLI plugins - <code>container-registry</code>, <code>kubernetes-service</code>, <code>vpc-infrastructure</code>, <code>secrets-manager</code>, <code>logs</code> latest <code>ibmcloud plugin install ...</code> kubectl \u2265 1.25 https://kubernetes.io/ Helm 3 \u2265 3.12 https://helm.sh/ git, podman/docker - distro packages Argo CD CLI \u2265 2.9 https://argo-cd.readthedocs.io IBM Cloud account with VPC quota - free tier works <p>Quick sanity check</p> <pre><code>kubectl version --short\nhelm version\nibmcloud --version\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#1-clone-prepare-the-repository","title":"1. Clone &amp; Prepare the Repository","text":"<pre><code>git clone https://github.com/IBM/mcp-context-forge.git\ncd mcp-context-forge\n\n# Optional local build for testing\npodman build -t mcp-context-forge:dev -f Containerfile .\n</code></pre> <p>Production deployments</p> <p>Production deployments can pull the signed image directly: <pre><code>ghcr.io/ibm/mcp-context-forge:0.3.0\n</code></pre></p>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#2-ibm-cloud-account-setup","title":"2. IBM Cloud Account Setup","text":""},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#21-authentication-region-resource-group","title":"2.1. Authentication, Region &amp; Resource Group","text":"<pre><code>ibmcloud login --sso                       # or: ibmcloud login --apikey \"$IBMCLOUD_API_KEY\"\nibmcloud target -r eu-de -g Default\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#22-install-required-cli-plugins","title":"2.2. Install Required CLI Plugins","text":"<pre><code>ibmcloud plugin install container-registry -f\nibmcloud plugin install kubernetes-service -f\nibmcloud plugin install vpc-infrastructure -f\nibmcloud plugin install secrets-manager -f\nibmcloud plugin install logs -f\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#23-create-vpc-and-networking-one-time","title":"2.3. Create VPC and Networking (one-time)","text":"<pre><code># Create VPC\nibmcloud is vpc-create mcp-vpc --resource-group Default\n\n# Create subnet in each zone for HA\nibmcloud is subnet-create mcp-subnet-eu-de-1 \\\n    $(ibmcloud is vpc mcp-vpc --output json | jq -r '.id') \\\n    --zone eu-de-1 --ipv4-cidr-block 10.10.1.0/24\n\nibmcloud is subnet-create mcp-subnet-eu-de-2 \\\n    $(ibmcloud is vpc mcp-vpc --output json | jq -r '.id') \\\n    --zone eu-de-2 --ipv4-cidr-block 10.10.2.0/24\n\nibmcloud is subnet-create mcp-subnet-eu-de-3 \\\n    $(ibmcloud is vpc mcp-vpc --output json | jq -r '.id') \\\n    --zone eu-de-3 --ipv4-cidr-block 10.10.3.0/24\n</code></pre> <p>Bring-your-own VPC</p> <p>You can reuse an existing VPC; just skip the commands above and note the IDs.</p>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#24-provision-ibm-cloud-services","title":"2.4. Provision IBM Cloud Services","text":"Service Purpose CLI Command Secrets Manager wildcard TLS certs, JWT secret <code>ibmcloud resource service-instance-create mcp-secrets secrets-manager standard eu-de</code> Key Protect (KMS) CSI envelope encryption <code>ibmcloud resource service-instance-create mcp-kms kms tiered-pricing eu-de</code> Cloud Logs audit &amp; app logs <code>ibmcloud resource service-instance-create mcp-logs logs standard eu-de</code> Container Registry host OCI images <code>ibmcloud cr namespace-add mcp-gw</code>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#25-push-images-to-ibm-container-registry","title":"2.5. Push Images to IBM Container Registry","text":"<pre><code># Login to Container Registry\nibmcloud cr login\n\n# Tag and push the image\npodman tag mcp-context-forge:dev eu.icr.io/mcp-gw/mcpgateway:0.3.0\npodman push eu.icr.io/mcp-gw/mcpgateway:0.3.0\n\n# Verify the image\nibmcloud cr images --restrict mcp-gw\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#3-create-ibm-kubernetes-service-iks-cluster","title":"3. Create IBM Kubernetes Service (IKS) Cluster","text":""},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#31-provision-the-cluster","title":"3.1. Provision the Cluster","text":"<pre><code># Get subnet IDs\nSUBNET_1=$(ibmcloud is subnets --output json | jq -r '.[] | select(.name==\"mcp-subnet-eu-de-1\") | .id')\nSUBNET_2=$(ibmcloud is subnets --output json | jq -r '.[] | select(.name==\"mcp-subnet-eu-de-2\") | .id')\nSUBNET_3=$(ibmcloud is subnets --output json | jq -r '.[] | select(.name==\"mcp-subnet-eu-de-3\") | .id')\n\n# Create the cluster with HA across zones\nibmcloud ks cluster create vpc-gen2 \\\n  --name mcp-cluster \\\n  --vpc-id $(ibmcloud is vpc mcp-vpc --output json | jq -r '.id') \\\n  --subnet-id $SUBNET_1 \\\n  --subnet-id $SUBNET_2 \\\n  --subnet-id $SUBNET_3 \\\n  --flavor bx2.4x16 \\\n  --workers 1 \\\n  --zones eu-de-1,eu-de-2,eu-de-3 \\\n  --kms-instance $(ibmcloud resource service-instance mcp-kms --output json | jq -r '.[0].guid')\n</code></pre> <p>Cluster Provisioning Time</p> <p>Cluster creation takes 15-30 minutes. Monitor progress with: <pre><code>ibmcloud ks cluster get --cluster mcp-cluster\n</code></pre></p>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#32-configure-kubectl-access","title":"3.2. Configure kubectl Access","text":"<pre><code>ibmcloud ks cluster config --cluster mcp-cluster\nkubectl config current-context   # should display mcp-cluster\nkubectl get nodes                # verify nodes are Ready\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#33-enable-storage-classes","title":"3.3. Enable Storage Classes","text":"<pre><code># List available storage classes\nibmcloud ks storage ls --cluster mcp-cluster\n\n# Enable File Storage (for RWX volumes)\nibmcloud ks storage file enable --cluster mcp-cluster\n\n# Verify storage classes\nkubectl get sc\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#4-prepare-kubernetes-namespaces-and-rbac","title":"4. Prepare Kubernetes Namespaces and RBAC","text":"<pre><code># Create application namespace\nkubectl create namespace mcp\nkubectl label namespace mcp app=mcp-gateway environment=prod\n\n# Create Argo CD namespace\nkubectl create namespace argocd\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#41-optional-network-policies","title":"4.1. Optional Network Policies","text":"<pre><code>cat &lt;&lt;'EOF' | kubectl apply -n mcp -f -\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: deny-by-default\nspec:\n  podSelector: {}\n  policyTypes: [Ingress, Egress]\n  egress:\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 53\n    - protocol: UDP\n      port: 53\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: kube-system\n  ingress:\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: ingress-nginx\n    - namespaceSelector:\n        matchLabels:\n          name: argocd\nEOF\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#5-install-and-configure-argo-cd","title":"5. Install and Configure Argo CD","text":""},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#51-install-argo-cd-server","title":"5.1. Install Argo CD Server","text":"<pre><code>kubectl apply -n argocd \\\n  -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml\n\n# Wait for rollout to complete\nkubectl -n argocd rollout status deploy/argocd-server\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#52-initial-login-and-configuration","title":"5.2. Initial Login and Configuration","text":"<pre><code># Port forward Argo CD UI (run in background)\nkubectl -n argocd port-forward svc/argocd-server 8080:443 &amp;\n\n# Get initial admin password\nPASSWORD=$(kubectl -n argocd get secret argocd-initial-admin-secret \\\n          -o jsonpath='{.data.password}' | base64 -d)\n\n# Login to Argo CD CLI\nargocd login localhost:8080 \\\n      --username admin --password \"$PASSWORD\" --insecure\n\necho \"Argo CD admin password: $PASSWORD\"\n</code></pre> <p>Change Default Password</p> <p>Browse to http://localhost:8080 and change the admin password via the UI.</p>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#6-configure-git-repository-structure","title":"6. Configure Git Repository Structure","text":""},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#61-create-argo-cd-application-definition","title":"6.1. Create Argo CD Application Definition","text":"<p>Create <code>argocd/apps/mcp-stack.yaml</code> in your Git repository:</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: mcp-stack\n  namespace: argocd\n  finalizers:\n    - resources-finalizer.argocd.argoproj.io\nspec:\n  project: default\n  source:\n    repoURL: https://github.com/IBM/mcp-context-forge\n    path: charts/mcp-stack\n    targetRevision: main\n    helm:\n      valueFiles:\n        - values.yaml\n        - envs/iks/values.yaml   # custom overrides\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: mcp\n  syncPolicy:\n    automated:\n      prune: true\n      selfHeal: true\n    syncOptions:\n    - CreateNamespace=true\n    - PrunePropagationPolicy=foreground\n    - PruneLast=true\n  revisionHistoryLimit: 10\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#62-create-custom-values-override","title":"6.2. Create Custom Values Override","text":"<p>Create <code>charts/mcp-stack/envs/iks/values.yaml</code>:</p> <pre><code># MCP Gateway Configuration\nmcpContextForge:\n  replicaCount: 2\n\n  image:\n    repository: eu.icr.io/mcp-gw/mcpgateway\n    tag: \"0.3.0\"\n    pullPolicy: IfNotPresent\n\n  # Service configuration\n  service:\n    type: ClusterIP\n    port: 80\n    targetPort: 4444\n\n  # Ingress configuration\n  ingress:\n    enabled: true\n    className: \"public-iks-k8s-nginx\"\n    annotations:\n      kubernetes.io/ingress.class: \"public-iks-k8s-nginx\"\n      cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    hosts:\n      - host: mcp-gateway.&lt;CLUSTER_INGRESS_SUBDOMAIN&gt;\n        paths:\n          - path: /\n            pathType: Prefix\n    tls:\n      - secretName: mcp-gateway-tls\n        hosts:\n          - mcp-gateway.&lt;CLUSTER_INGRESS_SUBDOMAIN&gt;\n\n  # Environment variables\n  env:\n    - name: AUTH_REQUIRED\n      value: \"true\"\n    - name: HOST\n      value: \"0.0.0.0\"\n    - name: PORT\n      value: \"4444\"\n    - name: LOG_LEVEL\n      value: \"INFO\"\n    - name: CACHE_TYPE\n      value: \"redis\"\n    - name: FEDERATION_ENABLED\n      value: \"true\"\n\n  # Resource limits\n  resources:\n    limits:\n      cpu: 1000m\n      memory: 1Gi\n    requests:\n      cpu: 500m\n      memory: 512Mi\n\n  # Health checks\n  livenessProbe:\n    httpGet:\n      path: /health\n      port: http\n    initialDelaySeconds: 30\n    periodSeconds: 10\n\n  readinessProbe:\n    httpGet:\n      path: /health\n      port: http\n    initialDelaySeconds: 5\n    periodSeconds: 5\n\n  # Horizontal Pod Autoscaler\n  autoscaling:\n    enabled: true\n    minReplicas: 2\n    maxReplicas: 10\n    targetCPUUtilizationPercentage: 70\n    targetMemoryUtilizationPercentage: 80\n\n# PostgreSQL Configuration\npostgres:\n  enabled: true\n  auth:\n    username: mcpgateway\n    database: mcpgateway\n    existingSecret: postgres-secret\n\n  primary:\n    persistence:\n      enabled: true\n      storageClass: \"ibmc-vpc-block-metro-10iops-tier\"\n      size: 20Gi\n\n    resources:\n      limits:\n        cpu: 1000m\n        memory: 1Gi\n      requests:\n        cpu: 500m\n        memory: 512Mi\n\n# Redis Configuration\nredis:\n  enabled: true\n  auth:\n    enabled: true\n    existingSecret: redis-secret\n\n  master:\n    persistence:\n      enabled: true\n      storageClass: \"ibmc-vpc-block-metro-10iops-tier\"\n      size: 8Gi\n\n    resources:\n      limits:\n        cpu: 500m\n        memory: 512Mi\n      requests:\n        cpu: 250m\n        memory: 256Mi\n\n# RBAC\nrbac:\n  create: true\n\n# ServiceAccount\nserviceAccount:\n  create: true\n  annotations:\n    iks.ibm.com/pod-security-policy: \"ibm-privileged-psp\"\n\n# PodSecurityPolicy for IKS\npodSecurityContext:\n  runAsNonRoot: true\n  runAsUser: 1001\n  fsGroup: 1001\n\nsecurityContext:\n  allowPrivilegeEscalation: false\n  readOnlyRootFilesystem: true\n  runAsNonRoot: true\n  runAsUser: 1001\n  capabilities:\n    drop:\n    - ALL\n\n# Network Policy\nnetworkPolicy:\n  enabled: true\n  ingress:\n    - from:\n      - namespaceSelector:\n          matchLabels:\n            name: ingress-nginx\n      ports:\n      - protocol: TCP\n        port: 4444\n  egress:\n    - to: []\n      ports:\n      - protocol: TCP\n        port: 53\n      - protocol: UDP\n        port: 53\n    - to:\n      - namespaceSelector:\n          matchLabels:\n            name: kube-system\n</code></pre> <p>Replace Placeholder</p> <p>Replace <code>&lt;CLUSTER_INGRESS_SUBDOMAIN&gt;</code> with your actual cluster's ingress subdomain: <pre><code>ibmcloud ks cluster get --cluster mcp-cluster | grep \"Ingress Subdomain\"\n</code></pre></p>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#63-create-required-secrets","title":"6.3. Create Required Secrets","text":"<pre><code># Generate strong passwords\nPOSTGRES_PASSWORD=$(openssl rand -base64 32)\nREDIS_PASSWORD=$(openssl rand -base64 32)\nJWT_SECRET=$(openssl rand -hex 32)\nBASIC_AUTH_PASSWORD=$(openssl rand -base64 16)\n\n# Create PostgreSQL secret\nkubectl create secret generic postgres-secret -n mcp \\\n  --from-literal=postgres-password=\"$POSTGRES_PASSWORD\"\n\n# Create Redis secret\nkubectl create secret generic redis-secret -n mcp \\\n  --from-literal=redis-password=\"$REDIS_PASSWORD\"\n\n# Create MCP Gateway config\nkubectl create secret generic mcp-gateway-secret -n mcp \\\n  --from-literal=JWT_SECRET_KEY=\"$JWT_SECRET\" \\\n  --from-literal=BASIC_AUTH_PASSWORD=\"$BASIC_AUTH_PASSWORD\" \\\n  --from-literal=DATABASE_URL=\"postgresql://mcpgateway:$POSTGRES_PASSWORD@mcp-stack-postgres:5432/mcpgateway\" \\\n  --from-literal=REDIS_URL=\"redis://:$REDIS_PASSWORD@mcp-stack-redis:6379/0\"\n\n# Store passwords securely for later use\necho \"POSTGRES_PASSWORD=$POSTGRES_PASSWORD\" &gt;&gt; ~/mcp-credentials.env\necho \"REDIS_PASSWORD=$REDIS_PASSWORD\" &gt;&gt; ~/mcp-credentials.env\necho \"JWT_SECRET=$JWT_SECRET\" &gt;&gt; ~/mcp-credentials.env\necho \"BASIC_AUTH_PASSWORD=$BASIC_AUTH_PASSWORD\" &gt;&gt; ~/mcp-credentials.env\nchmod 600 ~/mcp-credentials.env\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#7-deploy-via-argo-cd","title":"7. Deploy via Argo CD","text":""},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#71-create-and-sync-the-application","title":"7.1. Create and Sync the Application","text":"<pre><code># Create the application\nargocd app create -f argocd/apps/mcp-stack.yaml\n\n# Sync the application\nargocd app sync mcp-stack\n\n# Wait for synchronization\nargocd app wait mcp-stack --health\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#72-verify-deployment","title":"7.2. Verify Deployment","text":"<pre><code># Check all resources in the mcp namespace\nkubectl get all -n mcp\n\n# Check pod logs\nkubectl logs -n mcp deployment/mcp-stack-mcpcontextforge -f\n\n# Check ingress\nkubectl get ingress -n mcp\n\n# Check persistent volumes\nkubectl get pv,pvc -n mcp\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#8-test-and-configure-mcp-gateway","title":"8. Test and Configure MCP Gateway","text":""},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#81-generate-api-token","title":"8.1. Generate API Token","text":"<pre><code># Generate JWT token for API access\nsource ~/mcp-credentials.env\nexport MCPGATEWAY_BEARER_TOKEN=$(kubectl exec -n mcp deployment/mcp-stack-mcpcontextforge -- \\\n  python3 -m mcpgateway.utils.create_jwt_token \\\n  --username admin --exp 0 --secret \"$JWT_SECRET\")\n\necho \"Bearer token: $MCPGATEWAY_BEARER_TOKEN\"\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#82-test-api-endpoints","title":"8.2. Test API Endpoints","text":"<pre><code># Get cluster ingress subdomain\nINGRESS_SUBDOMAIN=$(ibmcloud ks cluster get --cluster mcp-cluster --output json | jq -r '.ingressHostname')\nGATEWAY_URL=\"https://mcp-gateway.$INGRESS_SUBDOMAIN\"\n\n# Test health endpoint\ncurl -s \"$GATEWAY_URL/health\"\n\n# Test authenticated endpoints\ncurl -s -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     \"$GATEWAY_URL/version\" | jq\n\ncurl -s -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     \"$GATEWAY_URL/tools\" | jq\n\n# Open admin UI\necho \"Admin UI: $GATEWAY_URL/admin\"\necho \"Username: admin\"\necho \"Password: $BASIC_AUTH_PASSWORD\"\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#83-add-mcp-servers","title":"8.3. Add MCP Servers","text":"<p>You can add MCP servers through the Admin UI or API:</p> <pre><code># Example: Add a time server via API\ncurl -X POST -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"name\": \"time_server\",\n       \"url\": \"http://time-server:8000/sse\",\n       \"description\": \"Time utilities server\"\n     }' \\\n     \"$GATEWAY_URL/gateways\"\n\n# Create a virtual server with selected tools\ncurl -X POST -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"name\": \"production_tools\",\n       \"description\": \"Production tool set\",\n       \"associatedTools\": [\"1\", \"2\"]\n     }' \\\n     \"$GATEWAY_URL/servers\"\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#9-configure-ai-clients","title":"9. Configure AI Clients","text":""},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#91-vs-code-copilot-integration","title":"9.1. VS Code Copilot Integration","text":"<p>Add this to your VS Code <code>settings.json</code>:</p> <pre><code>{\n  \"chat.mcp.enabled\": true,\n  \"mcp.servers\": {\n    \"mcp-gateway\": {\n      \"type\": \"sse\",\n      \"url\": \"https://mcp-gateway.&lt;CLUSTER_INGRESS_SUBDOMAIN&gt;/servers/UUID_OF_SERVER_1/sse\",\n      \"headers\": {\n        \"Authorization\": \"Bearer &lt;MCPGATEWAY_BEARER_TOKEN&gt;\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#92-claude-desktop-configuration","title":"9.2. Claude Desktop Configuration","text":"<p>Add to your Claude Desktop configuration:</p> <pre><code>{\n  \"mcpServers\": {\n    \"mcp-gateway\": {\n      \"command\": \"python\",\n      \"args\": [\"-m\", \"mcpgateway.wrapper\"],\n      \"env\": {\n        \"MCP_AUTH_TOKEN\": \"&lt;MCPGATEWAY_BEARER_TOKEN&gt;\",\n        \"MCP_SERVER_CATALOG_URLS\": \"https://mcp-gateway.&lt;CLUSTER_INGRESS_SUBDOMAIN&gt;/servers/UUID_OF_SERVER_1\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#93-langchain-agent-integration","title":"9.3. LangChain Agent Integration","text":"<pre><code>from mcpgateway_wrapper import MCPClient\n\nclient = MCPClient(\n    catalog_urls=[\"https://mcp-gateway.&lt;CLUSTER_INGRESS_SUBDOMAIN&gt;/servers/UUID_OF_SERVER_1\"],\n    token=\"&lt;MCPGATEWAY_BEARER_TOKEN&gt;\",\n)\n\n# List available tools\ntools = client.tools_list()\nprint(tools)\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#10-upgrade-and-database-migration","title":"10. Upgrade and Database Migration","text":""},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#101-rolling-upgrades","title":"10.1. Rolling Upgrades","text":"<p>Update the image tag in your values file and commit:</p> <pre><code># Update values file\nsed -i 's/tag: \"0.3.0\"/tag: \"0.4.0\"/' charts/mcp-stack/envs/iks/values.yaml\n\n# Commit and push\ngit add charts/mcp-stack/envs/iks/values.yaml\ngit commit -m \"Upgrade MCP Gateway to v0.4.0\"\ngit push\n\n# Argo CD will automatically sync the changes\nargocd app sync mcp-stack\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#102-monitor-migration","title":"10.2. Monitor Migration","text":"<pre><code># Watch the rollout\nkubectl rollout status deployment/mcp-stack-mcpcontextforge -n mcp\n\n# Check for migration jobs\nkubectl get jobs -n mcp\n\n# Follow migration logs if present\nkubectl logs -f job/mcp-stack-postgres-migrate -n mcp\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#11-operations-scaling-backup-security-logging-observability","title":"11. Operations: Scaling, Backup, Security, Logging, Observability","text":""},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#111-horizontal-pod-autoscaling","title":"11.1. Horizontal Pod Autoscaling","text":"<p>The HPA is configured automatically. Monitor it:</p> <pre><code>kubectl get hpa -n mcp\nkubectl describe hpa mcp-stack-mcpcontextforge -n mcp\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#112-manual-scaling","title":"11.2. Manual Scaling","text":"<pre><code># Scale replicas manually\nkubectl scale deployment mcp-stack-mcpcontextforge --replicas=5 -n mcp\n\n# Or update via Helm values\nhelm upgrade mcp-stack charts/mcp-stack -n mcp \\\n  --set mcpContextForge.replicaCount=5 \\\n  -f charts/mcp-stack/envs/iks/values.yaml\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#113-database-backup","title":"11.3. Database Backup","text":"<pre><code># Create a backup using IBM Cloud Snapshots\nibmcloud ks storage snapshot-create --cluster mcp-cluster \\\n  --pvc $(kubectl get pvc -n mcp -o jsonpath='{.items[0].metadata.name}') \\\n  --description \"MCP Gateway backup $(date +%Y%m%d)\"\n\n# List snapshots\nibmcloud ks storage snapshots --cluster mcp-cluster\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#114-monitoring-and-logs","title":"11.4. Monitoring and Logs","text":"<pre><code># View application logs\nkubectl logs -n mcp deployment/mcp-stack-mcpcontextforge -f\n\n# Check resource usage\nkubectl top pods -n mcp\nkubectl top nodes\n\n# Access IBM Cloud Logs\nibmcloud logs tail -r eu-de\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#115-grafana-dashboards","title":"11.5 Grafana Dashboards","text":"<p>TODO</p>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#12-database-migration-ibm-cloud-databases","title":"12. Database Migration: IBM Cloud Databases","text":""},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#121-provision-ibm-cloud-databases-for-postgresql","title":"12.1. Provision IBM Cloud Databases for PostgreSQL","text":"<pre><code># Create managed PostgreSQL instance\nibmcloud resource service-instance-create mcp-postgres \\\n    databases-for-postgresql standard eu-de \\\n    -p '{\"members_memory_allocation_mb\": 4096, \"members_disk_allocation_mb\": 10240}'\n\n# Create service credentials\nibmcloud resource service-key-create mcp-postgres-creds Administrator \\\n    --instance-name mcp-postgres\n\n# Get connection details\nibmcloud resource service-key mcp-postgres-creds --output json\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#122-database-migration-process","title":"12.2. Database Migration Process","text":"<pre><code># 1. Create backup of current database\nkubectl exec -n mcp deployment/mcp-stack-postgres -- \\\n  pg_dump -U mcpgateway mcpgateway &gt; /tmp/mcp-backup.sql\n\n# 2. Get managed database connection string\nCREDS=$(ibmcloud resource service-key mcp-postgres-creds --output json)\nHOST=$(echo \"$CREDS\" | jq -r '.[0].credentials.connection.postgres.hosts[0].hostname')\nPORT=$(echo \"$CREDS\" | jq -r '.[0].credentials.connection.postgres.hosts[0].port')\nUSER=$(echo \"$CREDS\" | jq -r '.[0].credentials.connection.postgres.authentication.username')\nPASS=$(echo \"$CREDS\" | jq -r '.[0].credentials.connection.postgres.authentication.password')\nDATABASE=$(echo \"$CREDS\" | jq -r '.[0].credentials.connection.postgres.database')\n\nMANAGED_DB_URL=\"postgresql://${USER}:${PASS}@${HOST}:${PORT}/${DATABASE}?sslmode=require\"\n\n# 3. Update database URL secret\nkubectl patch secret mcp-gateway-secret -n mcp \\\n  --patch=\"{\\\"data\\\":{\\\"DATABASE_URL\\\":\\\"$(echo -n \"$MANAGED_DB_URL\" | base64 -w 0)\\\"}}\"\n\n# 4. Update PostgreSQL settings in values\ncat &gt;&gt; charts/mcp-stack/envs/iks/values.yaml &lt;&lt; EOF\n\n# Disable embedded PostgreSQL\npostgres:\n  enabled: false\n\n# Use external database\nmcpContextForge:\n  env:\n    - name: DATABASE_URL\n      valueFrom:\n        secretKeyRef:\n          name: mcp-gateway-secret\n          key: DATABASE_URL\nEOF\n\n# 5. Commit and deploy\ngit add charts/mcp-stack/envs/iks/values.yaml\ngit commit -m \"Migrate to IBM Cloud Databases for PostgreSQL\"\ngit push\n\n# 6. Sync the application\nargocd app sync mcp-stack\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#123-setup-ibm-cloud-databases-for-redis","title":"12.3. Setup IBM Cloud Databases for Redis","text":"<pre><code># Create managed Redis instance\nibmcloud resource service-instance-create mcp-redis \\\n    databases-for-redis standard eu-de \\\n    -p '{\"members_memory_allocation_mb\": 1024}'\n\n# Create service credentials\nibmcloud resource service-key-create mcp-redis-creds Administrator \\\n    --instance-name mcp-redis\n\n# Get Redis connection details\nREDIS_CREDS=$(ibmcloud resource service-key mcp-redis-creds --output json)\nREDIS_HOST=$(echo \"$REDIS_CREDS\" | jq -r '.[0].credentials.connection.rediss.hosts[0].hostname')\nREDIS_PORT=$(echo \"$REDIS_CREDS\" | jq -r '.[0].credentials.connection.rediss.hosts[0].port')\nREDIS_PASS=$(echo \"$REDIS_CREDS\" | jq -r '.[0].credentials.connection.rediss.authentication.password')\n\nMANAGED_REDIS_URL=\"rediss://:${REDIS_PASS}@${REDIS_HOST}:${REDIS_PORT}/0\"\n\n# Update Redis URL secret\nkubectl patch secret mcp-gateway-secret -n mcp \\\n  --patch=\"{\\\"data\\\":{\\\"REDIS_URL\\\":\\\"$(echo -n \"$MANAGED_REDIS_URL\" | base64 -w 0)\\\"}}\"\n\n# Update values to disable embedded Redis\ncat &gt;&gt; charts/mcp-stack/envs/iks/values.yaml &lt;&lt; EOF\n\n# Disable embedded Redis\nredis:\n  enabled: false\nEOF\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#13-troubleshooting","title":"13. Troubleshooting","text":""},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#131-common-issues","title":"13.1. Common Issues","text":"<p>Pod ImagePullBackOff</p> <ul> <li>Verify image name and tag in values.yaml</li> <li>Check that worker nodes can reach ICR:   <pre><code>kubectl describe pod &lt;pod-name&gt; -n mcp\n</code></pre></li> <li>Ensure image exists in registry:   <pre><code>ibmcloud cr images --restrict mcp-gw\n</code></pre></li> </ul> <p>Ingress 404/502 Errors</p> <ul> <li>Verify ingress subdomain matches cluster:   <pre><code>ibmcloud ks cluster get --cluster mcp-cluster | grep \"Ingress\"\n</code></pre></li> <li>Check ingress controller status:   <pre><code>kubectl get pods -n kube-system | grep nginx\n</code></pre></li> </ul> <p>Argo CD Sync Failed</p> <ul> <li>Check application status:   <pre><code>argocd app get mcp-stack\n</code></pre></li> <li>View detailed sync errors:   <pre><code>kubectl describe application mcp-stack -n argocd\n</code></pre></li> </ul>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#132-resource-debugging","title":"13.2. Resource Debugging","text":"<pre><code># Check cluster capacity\nkubectl describe nodes\n\n# View resource usage\nkubectl top pods -n mcp\nkubectl top nodes\n\n# Check events\nkubectl get events -n mcp --sort-by='.lastTimestamp'\n\n# Debug pod issues\nkubectl describe pod &lt;pod-name&gt; -n mcp\nkubectl logs &lt;pod-name&gt; -n mcp --previous\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#133-network-troubleshooting","title":"13.3. Network Troubleshooting","text":"<pre><code># Test internal DNS resolution\nkubectl run -it --rm debug --image=busybox --restart=Never -- nslookup mcp-stack-postgres.mcp.svc.cluster.local\n\n# Test external connectivity\nkubectl run -it --rm debug --image=busybox --restart=Never -- wget -O- https://google.com\n\n# Check network policies\nkubectl get networkpolicy -n mcp\nkubectl describe networkpolicy deny-by-default -n mcp\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#14-performance-testing","title":"14. Performance Testing","text":"<p>Performance testing helps validate the stability, scalability, and responsiveness of the MCP Gateway under different workloads. This section outlines how to perform load tests using <code>hey</code> and how to inspect performance metrics.</p>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#141-run-basic-load-test-with-hey","title":"14.1. Run Basic Load Test with <code>hey</code>","text":"<p><code>hey</code> is a CLI load-testing tool for HTTP endpoints. You can use it to simulate traffic to the MCP Gateway's <code>/health</code> or <code>/version</code> endpoint:</p> <pre><code># Install hey (if not already installed)\nbrew install hey  # on macOS\ngo install github.com/rakyll/hey@latest  # if using Go\n\n# Run a basic test against the public health endpoint\nhey -z 30s -c 10 https://mcp-gateway.&lt;CLUSTER_INGRESS_SUBDOMAIN&gt;/health\n</code></pre> <p>Options explained:</p> <ul> <li><code>-z 30s</code>: Duration of test</li> <li><code>-c 10</code>: Number of concurrent connections</li> </ul> <p>For authenticated endpoints:</p> <pre><code># Replace with your actual token\nexport TOKEN=\"&lt;MCPGATEWAY_BEARER_TOKEN&gt;\"\n\n# Target authenticated endpoint\nhey -z 30s -c 10 \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  https://mcp-gateway.&lt;CLUSTER_INGRESS_SUBDOMAIN&gt;/version\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#142-analyze-gateway-performance","title":"14.2. Analyze Gateway Performance","text":"<p>Check metrics through Kubernetes and the API:</p> <pre><code># Observe resource usage\nkubectl top pods -n mcp\nkubectl top nodes\n\n# Inspect autoscaler activity\nkubectl get hpa -n mcp\nkubectl describe hpa mcp-stack-mcpcontextforge -n mcp\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#143-inspect-tool-level-metrics","title":"14.3. Inspect Tool-Level Metrics","text":"<p>Each tool invocation is tracked with:</p> <ul> <li>Response time (min/max/avg)</li> <li>Success/failure rate</li> <li>Total executions</li> </ul> <p>Fetch aggregated metrics from the API:</p> <pre><code>curl -H \"Authorization: Bearer $TOKEN\" \\\n     https://mcp-gateway.&lt;CLUSTER_INGRESS_SUBDOMAIN&gt;/metrics | jq\n</code></pre> <p>You can also inspect per-tool or per-server metrics via the Admin UI at:</p> <pre><code>https://mcp-gateway.&lt;CLUSTER_INGRESS_SUBDOMAIN&gt;/admin\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#144-advanced-stress-test-specific-tool","title":"14.4. Advanced: Stress Test Specific Tool","text":"<pre><code># Invoke a specific tool multiple times in parallel\nfor i in {1..50}; do\n  curl -s -H \"Authorization: Bearer $TOKEN\" \\\n       -X POST \\\n       -H \"Content-Type: application/json\" \\\n       -d '{\"name\":\"clock_tool\",\"arguments\":{\"timezone\":\"UTC\"}}' \\\n       https://mcp-gateway.&lt;CLUSTER_INGRESS_SUBDOMAIN&gt;/rpc &amp;\ndone\nwait\n</code></pre>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#15-faq","title":"15. FAQ","text":"<p>Q: How do I rotate the JWT secret without downtime? A: Update the secret and restart the MCP Gateway pods: <pre><code>NEW_JWT_SECRET=$(openssl rand -hex 32)\nkubectl patch secret mcp-gateway-secret -n mcp \\\n  --patch=\"{\\\"data\\\":{\\\"JWT_SECRET_KEY\\\":\\\"$(echo -n \"$NEW_JWT_SECRET\" | base64 -w 0)\\\"}}\"\nkubectl rollout restart deployment/mcp-stack-mcpcontextforge -n mcp\n</code></pre></p> <p>Q: Can I use custom storage classes? A: Yes, update the storageClass in your values.yaml: <pre><code>postgres:\n  primary:\n    persistence:\n      storageClass: \"your-custom-storage-class\"\n</code></pre></p> <p>Q: How do I enable TLS termination at the ingress? A: Install cert-manager and configure Let's Encrypt: <pre><code>kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.0/cert-manager.yaml\n</code></pre></p> <p>Q: How do I backup the entire application? A: Use Velero for full cluster backups or create database dumps and store them in IBM Cloud Object Storage.</p> <p>\u2705 You now have a production-ready MCP Gateway stack on IBM Cloud Kubernetes Service with GitOps management, managed databases, and comprehensive observability!</p>"},{"location":"deployment/tutorials/argocd-helm-deployment-ibm-cloud-iks/#next-steps","title":"Next Steps","text":"<ol> <li>Set up monitoring: Deploy Prometheus and Grafana for detailed metrics</li> <li>Configure alerts: Set up IBM Cloud Monitoring alerts for critical metrics</li> <li>Implement CI/CD: Automate image builds and deployments with IBM Cloud Toolchain</li> <li>Scale across regions: Deploy additional clusters for global availability</li> <li>Security hardening: Implement pod security standards and network policies</li> </ol>"},{"location":"development/","title":"Development","text":"<p>Welcome! This guide is for developers contributing to MCP Gateway. Whether you're fixing bugs, adding features, or extending federation or protocol support, this doc will help you get up and running quickly and consistently.</p>"},{"location":"development/#what-youll-find-here","title":"\ud83e\uddf0 What You'll Find Here","text":"Page Description Building Locally How to install dependencies, set up a virtual environment, and run the gateway Packaging How to build a release, container image, or prebuilt binary Doctest Coverage Comprehensive doctest coverage implementation and guidelines DEVELOPING.md Coding standards, commit conventions, and review workflow"},{"location":"development/#developer-environment","title":"\ud83d\udee0 Developer Environment","text":"<p>MCP Gateway is built with:</p> <ul> <li>Python 3.10+</li> <li>FastAPI + SQLAlchemy (async) + Pydantic Settings</li> <li>HTMX, Alpine.js, TailwindCSS for the Admin UI</li> </ul> <p>Development tools:</p> <ul> <li>Linters: <code>ruff</code>, <code>mypy</code>, <code>black</code>, <code>isort</code></li> <li>Testing: <code>pytest</code>, <code>httpx</code></li> <li>Serving: <code>uvicorn</code>, <code>gunicorn</code></li> </ul> <p>Code style and consistency is enforced via:</p> <pre><code>make lint          # runs ruff, mypy, black, isort\nmake pre-commit    # runs pre-commit hooks on staged files\n</code></pre> <p>As well as GitHub Actions code scanning.</p>"},{"location":"development/#testing","title":"\ud83e\uddea Testing","text":"<p>Test coverage includes:</p> <ul> <li>Unit tests under <code>tests/unit/</code></li> <li>Integration tests under <code>tests/integration/</code></li> <li>End-to-end tests under <code>tests/e2e/</code></li> <li>Example payload performance testing under <code>tests/hey/</code></li> </ul> <p>Use:</p> <pre><code>make test          # run all tests\nmake test-unit     # run only unit tests\nmake test-e2e      # run end-to-end\n</code></pre>"},{"location":"development/#linting-and-hooks","title":"\ud83d\udd0d Linting and Hooks","text":"<p>CI will fail your PR if code does not pass lint checks.</p> <p>You should manually run:</p> <pre><code>make lint\nmake pre-commit\n</code></pre> <p>Enable hooks with:</p> <pre><code>pre-commit install\n</code></pre>"},{"location":"development/#containers","title":"\ud83d\udc33 Containers","text":"<p>Build and run with Podman or Docker:</p> <pre><code>make podman            # build production image\nmake podman-run-ssl    # run with self-signed TLS at https://localhost:4444\n</code></pre>"},{"location":"development/#authentication","title":"\ud83d\udd10 Authentication","text":"<p>Admin UI and API are protected by Basic Auth or JWT.</p> <p>To generate a JWT token:</p> <pre><code>export MCPGATEWAY_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token --username admin --exp 0 --secret my-test-key)\necho $MCPGATEWAY_BEARER_TOKEN\n</code></pre> <p>Then test:</p> <pre><code>curl -k -sX GET \\\n  -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n  https://localhost:4444/tools | jq\n</code></pre>"},{"location":"development/#configuration","title":"\ud83d\udce6 Configuration","text":"<p>Edit <code>.env</code> or set environment variables. A complete list is documented in the README.</p> <p>Use:</p> <pre><code>cp .env.example .env\n</code></pre> <p>Key configs include:</p> Variable Purpose <code>DATABASE_URL</code> Database connection <code>JWT_SECRET_KEY</code> Signing key for JWTs <code>DEV_MODE=true</code> Enables hot reload and debug <code>CACHE_TYPE=memory</code> Options: memory, redis, none"},{"location":"development/#contribution-tips","title":"\ud83d\udea7 Contribution Tips","text":"<ul> <li>Pick a <code>good first issue</code></li> <li>Read the <code>CONTRIBUTING.md</code></li> <li>Fork, branch, commit with purpose</li> <li>Submit PRs against <code>main</code> with clear titles and linked issues</li> </ul>"},{"location":"development/#cicd","title":"\u2705 CI/CD","text":"<p>GitHub Actions enforce:</p> <ul> <li>CodeQL security scanning</li> <li>Pre-commit linting</li> <li>Dependency audits</li> <li>Docker image builds</li> </ul> <p>CI configs live in <code>.github/workflows/</code>.</p>"},{"location":"development/building/","title":"Building Locally","text":"<p>Follow these instructions to set up your development environment, build the gateway from source, and run it interactively.</p>"},{"location":"development/building/#prerequisites","title":"\ud83e\udde9 Prerequisites","text":"<ul> <li>Python \u2265 3.10</li> <li><code>make</code></li> <li>(Optional) Docker or Podman for container builds</li> </ul>"},{"location":"development/building/#one-liner-setup-recommended","title":"\ud83d\udd27 One-Liner Setup (Recommended)","text":"<pre><code>make venv install serve\n</code></pre> <p>This will:</p> <ol> <li>Create a virtual environment in <code>.venv/</code></li> <li>Install Python dependencies including dev extras</li> <li>Run the gateway using Gunicorn</li> </ol>"},{"location":"development/building/#manual-python-setup","title":"\ud83d\udc0d Manual Python Setup","text":"<pre><code>python3 -m venv .venv\nsource .venv/bin/activate\npip install -e \".[dev]\"\n</code></pre> <p>This installs:</p> <ul> <li>Core app dependencies</li> <li>Dev tools (<code>ruff</code>, <code>black</code>, <code>mypy</code>, etc.)</li> <li>Test runners (<code>pytest</code>, <code>coverage</code>)</li> </ul>"},{"location":"development/building/#running-the-app","title":"\ud83d\ude80 Running the App","text":"<p>You can run the gateway with:</p> <pre><code>make serve         # production-mode Gunicorn (http://localhost:4444)\nmake run           # dev-mode Uvicorn (reloads on change)\n./run.sh --reload  # same as 'make run', with CLI flags\n</code></pre> <p>Use <code>make run</code> or <code>./run.sh</code> during development for auto-reload.</p>"},{"location":"development/building/#live-reload-tips","title":"\ud83d\udd04 Live Reload Tips","text":"<p>Ensure <code>RELOAD=true</code> and <code>DEV_MODE=true</code> are set in your <code>.env</code> during development.</p> <p>Also set:</p> <pre><code>DEBUG=true\nLOG_LEVEL=debug\n</code></pre>"},{"location":"development/building/#test-it","title":"\ud83e\uddea Test It","text":"<pre><code>curl http://localhost:4444/health\ncurl http://localhost:4444/tools\n</code></pre> <p>You should see <code>[]</code> or registered tools (once added).</p>"},{"location":"development/developer-onboarding/","title":"\u2705 Developer Onboarding Checklist","text":"<p>Follow this checklist to set up your development environment, verify all features, and ensure consistent onboarding across the MCP Gateway project.</p>"},{"location":"development/developer-onboarding/#environment-setup","title":"\ud83d\udee0 Environment Setup","text":"System prerequisites <ul> <li> Python \u2265 3.10</li> <li> Node.js and npm, npx (used for testing with <code>supergateway</code> and the HTML/JS Admin UI)</li> <li> Docker, Docker Compose, and Podman</li> <li> Make, GitHub CLI (<code>gh</code>), <code>curl</code>, <code>jq</code>, <code>openssl</code></li> <li> Optional: Visual Studio Code + Dev Containers extension (or WSL2 if on Windows) + Pyrefly</li> <li> Optional: On Windows, install the WSL and Remote Development extensions</li> </ul> Python tooling <ul> <li> <code>pip install --upgrade pip</code></li> <li> <code>uv</code> and <code>uvx</code> installed - install uv</li> <li> <code>.venv</code> created with <code>make venv install install-dev</code></li> </ul> Additional tools <ul> <li> <code>helm</code> installed for Kubernetes deployments (Helm install docs)</li> <li> Security tools in <code>$PATH</code>: <code>hadolint</code>, <code>dockle</code>, <code>trivy</code>, <code>osv-scanner</code></li> </ul> Useful VS Code extensions <ul> <li> Python, Pylance</li> <li> YAML, Even Better TOML</li> <li> Docker, Dev Containers (useful on Windows)</li> </ul> GitHub setup <ul> <li> GitHub email configured in <code>git config</code></li> <li> See GitHub config guide</li> </ul> .env configuration <ul> <li> Copy <code>.env.example</code> to <code>.env</code></li> <li> Set various env variables, such as:<ul> <li><code>JWT_SECRET_KEY</code></li> <li><code>BASIC_AUTH_PASSWORD</code></li> </ul> </li> </ul>"},{"location":"development/developer-onboarding/#makefile-targets","title":"\ud83d\udd27 Makefile Targets","text":"Local setup <ul> <li> <code>make check-env</code> (validates .env is complete)</li> <li> <code>make venv install install-dev serve</code></li> <li> <code>make smoketest</code> runs and passes</li> </ul> Container builds <ul> <li> Docker: <code>make docker-prod docker-run-ssl-host compose-up</code></li> <li> Podman: <code>make podman podman-prod podman-run-ssl-host</code></li> </ul> Packaging <ul> <li> <code>make dist verify</code> builds packages</li> <li> <code>make devpi-install devpi-init devpi-start devpi-setup-user devpi-upload devpi-test</code></li> <li> Install and test <code>mcpgateway</code> CLI locally</li> </ul> Minikube &amp; Helm <ul> <li> <code>make helm-install minikube-install minikube-start minikube-k8s-apply helm-package helm-deploy</code></li> <li> See minikube deployment</li> </ul>"},{"location":"development/developer-onboarding/#testing","title":"\ud83e\uddea Testing","text":"Code quality <ul> <li> <code>make lint</code>, <code>make lint-web</code></li> <li> <code>make shell-linters-install</code>, <code>make shell-lint</code></li> <li> <code>make hadolint</code> (Dockerfile linting)</li> </ul> Unit tests <ul> <li> <code>make test</code> passes all cases</li> </ul>"},{"location":"development/developer-onboarding/#security","title":"\ud83d\udd10 Security","text":"Vulnerability scans <ul> <li> Run:     <pre><code>make hadolint dockle osv-scan trivy pip-audit\n</code></pre></li> </ul> SonarQube analysis <ul> <li> <code>make sonar-up-docker</code></li> <li> <code>make sonar-submit-docker</code> - ensure no critical violations</li> </ul>"},{"location":"development/developer-onboarding/#jwt-authentication","title":"\ud83d\udd11 JWT Authentication","text":"Generate and use a Bearer token <ul> <li> <p> Export a token with:     <pre><code>export MCPGATEWAY_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token --username admin --exp 0 --secret my-test-key)\n</code></pre></p> </li> <li> <p> Verify authenticated API access:     <pre><code>curl -k -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" https://localhost:4444/version | jq\n</code></pre></p> </li> </ul>"},{"location":"development/developer-onboarding/#client-integration","title":"\ud83e\udd16 Client Integration","text":"Run wrapper and test transports <ul> <li> Run: <code>python3 -m mcpgateway.wrapper</code> (stdio support)</li> <li> Test transports:<ul> <li>Streamable HTTP</li> <li>Server-Sent Events (SSE)</li> </ul> </li> <li> Optional: Integrate with Claude, Copilot, Continue (usage guide)</li> </ul>"},{"location":"development/developer-onboarding/#api-testing","title":"\ud83e\udded API Testing","text":"Authentication required <ul> <li> Unauthenticated:     <pre><code>curl http://localhost:4444/tools\n# -&gt; should return 401 Unauthorized\n</code></pre></li> <li> Authenticated:     <pre><code>curl -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" http://localhost:4444/version | jq\n</code></pre></li> </ul> Endpoint coverage <ul> <li> Confirm key routes:<ul> <li><code>/version</code></li> <li><code>/health</code></li> <li><code>/tools</code></li> <li><code>/servers</code></li> <li><code>/resources</code></li> <li><code>/prompts</code></li> <li><code>/gateways</code></li> </ul> </li> <li> Browse Redoc docs</li> </ul>"},{"location":"development/developer-onboarding/#admin-ui","title":"\ud83d\udda5 Admin UI","text":"Login and diagnostics <ul> <li> Navigate to <code>/admin</code></li> <li> Log in with Basic Auth credentials from <code>.env</code></li> <li> <code>/version</code> shows healthy DB and Redis</li> </ul> CRUD verification <ul> <li> Create / edit / delete:<ul> <li>Servers</li> <li>Tools</li> <li>Resources</li> <li>Prompts</li> <li>Gateways</li> </ul> </li> <li> Toggle active/inactive switches</li> <li> JWT stored in <code>HttpOnly</code> cookie, no errors in DevTools Console</li> </ul> Metrics <ul> <li> Confirm latency and error rate display under load</li> </ul>"},{"location":"development/developer-onboarding/#documentation","title":"\ud83d\udcda Documentation","text":"Build and inspect docs <ul> <li> <code>cd docs &amp;&amp; make venv serve</code></li> <li> Open http://localhost:8000</li> <li> Confirm:<ul> <li><code>.pages</code> ordering</li> <li>nav structure</li> <li>working images</li> <li>Mermaid diagrams</li> </ul> </li> </ul> Read and understand <ul> <li> <code>README.md</code> in root</li> <li> Official docs site</li> <li> MkDocs Admonitions guide</li> </ul>"},{"location":"development/developer-onboarding/#final-review","title":"\u2705 Final Review","text":"Ready to contribute <ul> <li> All items checked</li> <li> PR description links to this checklist</li> <li> Stuck? Open a discussion or issue</li> </ul>"},{"location":"development/developer-workstation/","title":"Developer Workstation","text":"<p>This guide helps you to set up your local environment for contributing to the Model Context Protocol (MCP) Gateway. It provides detailed instructions for tooling requirements, OS-specific notes, common pitfalls, and commit signing practices.</p>"},{"location":"development/developer-workstation/#tooling-requirements","title":"Tooling Requirements","text":"<ul> <li>Python (&gt;= 3.10)<ul> <li>Download from python.org or use your package manager (e.g., <code>brew install python</code> on macOS, <code>sudo apt-get install python3</code> on Ubuntu).</li> <li>Verify: <code>python3 --version</code>.</li> </ul> </li> <li>Docker or Podman<ul> <li>Docker: Install <code>docker.io</code>, <code>buildx</code>, and <code>docker-compose v2</code>.<ul> <li>Docker Desktop for macOS/Windows.</li> <li>Linux: <code>sudo apt-get install docker.io docker-buildx-plugin docker-compose-plugin</code> (Debian/Ubuntu) or <code>sudo dnf install docker docker-buildx docker-compose</code> (Fedora).</li> </ul> </li> <li>Podman: Install Podman Desktop for a rootless alternative.</li> <li>Verify: <code>docker --version</code> or <code>podman --version</code>.</li> </ul> </li> <li>Permissions Setup<ul> <li>Docker: Add your user to the <code>docker</code> group: <code>sudo usermod -aG docker $USER</code>, then log out and back in (Linux). Restart Docker Desktop (Windows/macOS).</li> <li>Podman: Configure rootless mode with <code>podman system service</code>.</li> </ul> </li> <li>Docker Compose or Compatible Wrapper<ul> <li>Included with Docker Desktop or as <code>docker-compose-plugin</code>.</li> <li>For Podman: <code>pip install podman-compose</code>.</li> <li>Verify: <code>docker compose version</code> or <code>podman-compose --version</code>.</li> </ul> </li> <li>GNU Make<ul> <li>macOS: <code>brew install make</code>.</li> <li>Linux: <code>sudo apt-get install make</code> or <code>sudo dnf install make</code>.</li> <li>Windows: Install via Chocolatey (<code>choco install make</code>) or use WSL2.</li> <li>Verify: <code>make --version</code>.</li> </ul> </li> <li>(Optional) uv, ruff, mypy, isort<ul> <li>Install: <code>pip install uv ruff mypy isort</code>.</li> <li>Usage: Run <code>ruff check .</code> or <code>mypy .</code> for linting/type checking.</li> </ul> </li> <li>Node.js and npm (for UI linters)<ul> <li>Install from nodejs.org.</li> <li>Verify: <code>node --version</code> and <code>npm --version</code>.</li> <li>Install linters: <code>npm install -g eslint stylelint</code>.</li> </ul> </li> <li>(Optional)Visual Studio Code and useful plugins<ul> <li>Download from code.visualstudio.com.</li> </ul> </li> </ul>"},{"location":"development/developer-workstation/#os-specific-setup","title":"OS-Specific Setup","text":""},{"location":"development/developer-workstation/#macos","title":"macOS","text":"<ul> <li>Installation:<ul> <li>Install Homebrew: <code>/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"</code>.</li> <li>Run: <code>brew install python docker make node</code>.</li> </ul> </li> <li>Apple Silicon: Use Docker Desktop with ARM64 support. Homebrew handles architecture natively.</li> <li>Troubleshooting: Ensure Rosetta 2 is installed for Intel-based tools if needed (<code>softwareupdate --install-rosetta</code>).</li> </ul>"},{"location":"development/developer-workstation/#linux","title":"Linux","text":"<ul> <li>Installation:<ul> <li>Debian/Ubuntu: <code>sudo apt-get update &amp;&amp; sudo apt-get install python3 docker.io docker-buildx-plugin docker-compose-plugin make nodejs npm</code>.</li> <li>Fedora: <code>sudo dnf install python3 docker docker-buildx docker-compose make nodejs npm</code>.</li> </ul> </li> <li>Permissions: Add user to <code>docker</code> group: <code>sudo usermod -aG docker $USER</code>, then reboot.</li> <li>Troubleshooting: Use <code>systemctl start docker</code> if the service isn't running.</li> </ul>"},{"location":"development/developer-workstation/#windows","title":"Windows","text":"<ul> <li>Recommended: WSL2<ul> <li>Install WSL2 and Ubuntu: <code>wsl --install</code>.</li> <li>Install Docker Desktop with WSL2 integration.</li> </ul> </li> <li>File Paths and Volume Mounting<ul> <li>Use forward slashes (e.g., <code>/f/All/ibm/mcp-forge/mcp-context-forge</code>).</li> <li>Avoid spaces/special characters; use absolute paths in <code>docker run -v</code>.</li> </ul> </li> <li>Podman in WSL2<ul> <li>Install: <code>sudo apt-get install podman</code> in WSL2.</li> <li>Port exposure: Use <code>podman system service</code> and configure firewall (<code>sudo ufw allow 4444</code>).</li> </ul> </li> <li>Windows Terminal<ul> <li>Install from Microsoft Store. set WSL2 as default profile.</li> </ul> </li> <li>Make Alternatives<ul> <li>Use WSL2's <code>make</code> or install via Chocolatey (<code>choco install make</code>).</li> </ul> </li> </ul>"},{"location":"development/developer-workstation/#common-gotchas","title":"Common Gotchas","text":""},{"location":"development/developer-workstation/#docker-socket-permissions","title":"Docker Socket Permissions","text":"<ul> <li>Problem: You may encounter \"permission denied while connecting to the Docker daemon\" if your user lacks access to the Docker socket.</li> <li>Fix:<ul> <li>Linux: Add your user to the <code>docker</code> group with <code>sudo usermod -aG docker $USER</code>, then log out and log back in. Verify with <code>docker ps</code>.</li> <li>Windows/macOS: Restart Docker Desktop from the system tray or settings menu.</li> </ul> </li> <li>Troubleshooting: If the issue persists, ensure the Docker service is running (<code>systemctl status docker</code> on Linux) or reinstall Docker Desktop.</li> </ul>"},{"location":"development/developer-workstation/#venv-activation-across-shells","title":".venv Activation Across Shells","text":"<ul> <li>Problem: The virtual environment (<code>.venv</code>) may not activate automatically when opening new terminal sessions.</li> <li>Fix:<ul> <li>Activate: Use <code>source .venv/bin/activate</code> (Linux/macOS) or <code>.venv\\Scripts\\activate</code> (Windows) for each session.</li> <li>Persist: Add to your shell profile (e.g., <code>echo \"source ./.venv/bin/activate\" &gt;&gt; ~/.bashrc</code> for Bash on Linux). Replace <code>.</code> with the relative path to your <code>.venv</code> if different.</li> </ul> </li> <li>Troubleshooting: Verify activation with <code>which python</code> (should point to <code>.venv/bin/python</code>); deactivate with <code>deactivate</code> if needed.</li> </ul>"},{"location":"development/developer-workstation/#port-4444-already-in-use","title":"Port 4444 Already in Use","text":"<ul> <li>Problem: Port 4444, used by the MCP Gateway and MkDocs, may be occupied by another process, causing conflicts.</li> <li>Fix:<ul> <li>Check: Run <code>netstat -aon | findstr :4444</code> (Windows) or <code>ss -tuln | grep 4444</code> (Linux) to identify the process ID (PID).</li> <li>Resolve: Use a different port for MkDocs with <code>mkdocs serve --dev-addr=127.0.0.1:8001</code>, or stop the conflicting process (e.g., <code>taskkill /PID &lt;PID&gt;</code> on Windows or <code>kill &lt;PID&gt;</code> on Linux).</li> </ul> </li> <li>Troubleshooting: If unsure which process to stop, check with <code>docker ps</code> (if a container) or review running services.</li> </ul>"},{"location":"development/developer-workstation/#snippet-examples","title":"Snippet Examples","text":""},{"location":"development/developer-workstation/#set-up-and-serve-documentation","title":"Set Up and Serve Documentation","text":"<pre><code># Create and activate virtual environment\nmake venv\nsource .venv/bin/activate  # Linux/macOS\n.venv\\Scripts\\activate     # Windows\n\n# Install dependencies\nmake install\n\n# Serve documentation locally\nmake serve\n</code></pre>"},{"location":"development/developer-workstation/#signing-commits","title":"Signing commits","text":"<p>To ensure commit integrity and comply with the DCO, sign your commits with a <code>Signed-off-by</code> trailer. Configure your Git settings:</p> <pre><code># ~/.gitconfig\n[user]\n    name = Your Name\n    email = your-exail@example.com\n\n[init]\n    defaultBranch = main  # Use 'main' instead of 'master' when creating new repos\n\n[core]\n    autocrlf = input       # On commit: convert CRLF to LF (Windows \u2192 Linux)\n                           # On checkout: leave LF alone (no conversion)\n    eol = lf               # Ensure all files in the repo use LF internally\n\n[alias]\n    cm = commit -s -m      # Short alias: 'git cm \"message\"' creates signed-off commit\n    ca = commit --amend -s # Amend last commit and ensure it has a Signed-off-by trailer\n\n[commit]\n    template = ~/.git-commit-template\n</code></pre> <ul> <li>Setup: Replace Your Name and your-exail@example.com with your details.</li> <li>Signing: Use git cm \"Your message\" to create signed commits automatically with the configured alias.</li> <li>Sign-off: Use git commit -s -m \"Your message\" for manual signed commits without the alias.</li> </ul>"},{"location":"development/doctest-coverage/","title":"Doctest Coverage","text":"<p>This page documents the comprehensive doctest coverage implementation in MCP Context Forge, which ensures that all code examples in documentation are tested and verified automatically.</p>"},{"location":"development/doctest-coverage/#overview","title":"Overview","text":"<p>MCP Context Forge implements comprehensive doctest coverage across all modules to ensure:</p> <ul> <li>Code Quality: All documented examples are tested and verified</li> <li>Documentation Accuracy: Examples in docstrings are always up-to-date with actual code behavior</li> <li>Developer Experience: Developers can run examples directly from documentation</li> <li>Regression Prevention: Changes that break documented behavior are caught early</li> </ul>"},{"location":"development/doctest-coverage/#what-is-doctest","title":"What is Doctest?","text":"<p>Doctest is a Python testing framework that extracts interactive examples from docstrings and runs them as tests. It's built into Python's standard library and provides:</p> <ul> <li>Inline Testing: Examples in docstrings are automatically tested</li> <li>Documentation Verification: Ensures examples match actual code behavior</li> <li>Google Style Support: Works seamlessly with Google-style docstrings</li> <li>CI/CD Integration: Can be integrated into automated testing pipelines</li> </ul>"},{"location":"development/doctest-coverage/#coverage-status","title":"Coverage Status","text":""},{"location":"development/doctest-coverage/#current-coverage","title":"Current Coverage","text":"Module Category Status Coverage Transport Modules \u2705 Complete 100% Utility Functions \u2705 Complete 100% Validation Modules \u2705 Complete 100% Configuration \u2705 Complete 100% Service Classes \ud83d\udd04 In Progress ~60% Complex Classes \ud83d\udd04 In Progress ~40%"},{"location":"development/doctest-coverage/#modules-with-full-coverage","title":"Modules with Full Coverage","text":"<ul> <li><code>mcpgateway/transports/base.py</code> - Base transport interface</li> <li><code>mcpgateway/transports/stdio_transport.py</code> - Standard I/O transport</li> <li><code>mcpgateway/transports/sse_transport.py</code> - Server-Sent Events transport</li> <li><code>mcpgateway/transports/websocket_transport.py</code> - WebSocket transport</li> <li><code>mcpgateway/transports/streamablehttp_transport.py</code> - Streamable HTTP transport</li> <li><code>mcpgateway/transports/__init__.py</code> - Transport module exports</li> <li><code>mcpgateway/utils/create_slug.py</code> - Slug generation utilities</li> <li><code>mcpgateway/validation/jsonrpc.py</code> - JSON-RPC validation</li> <li><code>mcpgateway/config.py</code> - Configuration management</li> </ul>"},{"location":"development/doctest-coverage/#running-doctests","title":"Running Doctests","text":""},{"location":"development/doctest-coverage/#local-development","title":"Local Development","text":"<pre><code># Run all doctests\nmake doctest\n\n# Run with verbose output\nmake doctest-verbose\n\n# Generate coverage report\nmake doctest-coverage\n\n# Check coverage percentage (fails if &lt; 100%)\nmake doctest-check\n</code></pre>"},{"location":"development/doctest-coverage/#individual-modules","title":"Individual Modules","text":"<pre><code># Test a specific module\npython -m doctest mcpgateway/transports/base.py -v\n\n# Test with programmatic approach\npython -c \"import doctest; doctest.testmod(mcpgateway.transports.base)\"\n</code></pre>"},{"location":"development/doctest-coverage/#cicd-integration","title":"CI/CD Integration","text":"<p>Doctests are automatically run in the GitHub Actions pipeline:</p> <pre><code># .github/workflows/pytest.yml\n- name: Run doctests\n  run: |\n    pytest --doctest-modules mcpgateway/ -v\n</code></pre>"},{"location":"development/doctest-coverage/#doctest-standards","title":"Doctest Standards","text":""},{"location":"development/doctest-coverage/#google-docstring-format","title":"Google Docstring Format","text":"<p>All doctests follow the Google docstring format with an \"Examples:\" section:</p> <pre><code>def create_slug(text: str) -&gt; str:\n    \"\"\"Convert text to URL-friendly slug.\n\n    Args:\n        text: Input text to convert\n\n    Returns:\n        URL-friendly slug string\n\n    Examples:\n        &gt;&gt;&gt; create_slug(\"Hello World!\")\n        'hello-world'\n\n        &gt;&gt;&gt; create_slug(\"Special@#$Characters\")\n        'special-characters'\n\n        &gt;&gt;&gt; create_slug(\"  Multiple   Spaces  \")\n        'multiple-spaces'\n    \"\"\"\n    # Implementation here\n</code></pre>"},{"location":"development/doctest-coverage/#best-practices","title":"Best Practices","text":"<ol> <li>Comprehensive Examples: Cover normal cases, edge cases, and error conditions</li> <li>Async Support: Use <code>asyncio.run()</code> for async function examples</li> <li>Mock Objects: Use <code>unittest.mock</code> for external dependencies</li> <li>Clear Expectations: Make expected output obvious and unambiguous</li> <li>Error Testing: Include examples that demonstrate error handling</li> </ol>"},{"location":"development/doctest-coverage/#async-function-examples","title":"Async Function Examples","text":"<pre><code>async def connect(self) -&gt; None:\n    \"\"\"Set up transport connection.\n\n    Examples:\n        &gt;&gt;&gt; transport = MyTransport()\n        &gt;&gt;&gt; import asyncio\n        &gt;&gt;&gt; asyncio.run(transport.connect())\n        &gt;&gt;&gt; transport.is_connected()\n        True\n    \"\"\"\n</code></pre>"},{"location":"development/doctest-coverage/#mock-usage-examples","title":"Mock Usage Examples","text":"<pre><code>def send_message(self, message: Dict[str, Any]) -&gt; None:\n    \"\"\"Send message over transport.\n\n    Examples:\n        &gt;&gt;&gt; from unittest.mock import Mock, AsyncMock\n        &gt;&gt;&gt; mock_transport = Mock()\n        &gt;&gt;&gt; mock_transport.send = AsyncMock()\n        &gt;&gt;&gt; import asyncio\n        &gt;&gt;&gt; asyncio.run(mock_transport.send({\"test\": \"data\"}))\n        &gt;&gt;&gt; mock_transport.send.called\n        True\n    \"\"\"\n</code></pre>"},{"location":"development/doctest-coverage/#pre-commit-integration","title":"Pre-commit Integration","text":"<p>Doctests are integrated into the pre-commit workflow:</p> <pre><code># .pre-commit-config.yaml\n- repo: local\n  hooks:\n    - id: doctest\n      name: Doctest\n      entry: pytest --doctest-modules mcpgateway/\n      language: system\n      types: [python]\n</code></pre> <p>This ensures that: - All doctests pass before commits are allowed - Documentation examples are always verified - Code quality is maintained automatically</p>"},{"location":"development/doctest-coverage/#coverage-metrics","title":"Coverage Metrics","text":""},{"location":"development/doctest-coverage/#current-statistics","title":"Current Statistics","text":"<ul> <li>Total Functions/Methods: ~200</li> <li>Functions with Doctests: ~150</li> <li>Coverage Percentage: ~75%</li> <li>Test Examples: ~500+</li> </ul>"},{"location":"development/doctest-coverage/#coverage-goals","title":"Coverage Goals","text":"<ul> <li>Phase 1: \u2705 Infrastructure setup (100%)</li> <li>Phase 2: \u2705 Utility modules (100%)</li> <li>Phase 3: \u2705 Configuration and schemas (100%)</li> <li>Phase 4: \u2705 Service classes (100%)</li> <li>Phase 5: \u2705 Transport modules (100%)</li> <li>Phase 6: \ud83d\udd04 Documentation integration (100%)</li> </ul>"},{"location":"development/doctest-coverage/#contributing-guidelines","title":"Contributing Guidelines","text":""},{"location":"development/doctest-coverage/#adding-doctests","title":"Adding Doctests","text":"<p>When adding new functions or methods:</p> <ol> <li>Include Examples: Always add an \"Examples:\" section to docstrings</li> <li>Test Edge Cases: Cover normal usage, edge cases, and error conditions</li> <li>Use Google Format: Follow the established Google docstring format</li> <li>Async Support: Use <code>asyncio.run()</code> for async functions</li> <li>Mock Dependencies: Use mocks for external dependencies</li> </ol>"},{"location":"development/doctest-coverage/#example-template","title":"Example Template","text":"<pre><code>def new_function(param1: str, param2: int) -&gt; bool:\n    \"\"\"Brief description of what the function does.\n\n    Longer description explaining the function's purpose, behavior,\n    and any important implementation details.\n\n    Args:\n        param1: Description of first parameter\n        param2: Description of second parameter\n\n    Returns:\n        Description of return value\n\n    Raises:\n        ValueError: When parameters are invalid\n\n    Examples:\n        &gt;&gt;&gt; # Normal usage\n        &gt;&gt;&gt; new_function(\"test\", 42)\n        True\n\n        &gt;&gt;&gt; # Edge case\n        &gt;&gt;&gt; new_function(\"\", 0)\n        False\n\n        &gt;&gt;&gt; # Error condition\n        &gt;&gt;&gt; try:\n        ...     new_function(\"test\", -1)\n        ... except ValueError as e:\n        ...     print(\"Expected error:\", str(e))\n        Expected error: Invalid parameter\n    \"\"\"\n</code></pre>"},{"location":"development/doctest-coverage/#running-tests","title":"Running Tests","text":"<p>Before submitting a PR:</p> <pre><code># Run all tests including doctests\nmake test\n\n# Run only doctests\nmake doctest\n\n# Check linting\nmake flake8\n\n# Run pre-commit hooks\nmake pre-commit\n</code></pre>"},{"location":"development/doctest-coverage/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/doctest-coverage/#common-issues","title":"Common Issues","text":"<ol> <li>Async Functions: Remember to use <code>asyncio.run()</code> in examples</li> <li>Mock Objects: Use appropriate mocks for external dependencies</li> <li>Import Issues: Ensure all imports are available in doctest context</li> <li>Whitespace: Be careful with trailing whitespace in expected output</li> </ol>"},{"location":"development/doctest-coverage/#debugging-doctests","title":"Debugging Doctests","text":"<pre><code># Run with maximum verbosity\npython -m doctest module.py -v\n\n# Run specific function\npython -c \"import doctest; doctest.run_docstring_examples(function, globals())\"\n\n# Check for syntax errors\npython -m py_compile module.py\n</code></pre>"},{"location":"development/doctest-coverage/#benefits","title":"Benefits","text":""},{"location":"development/doctest-coverage/#for-developers","title":"For Developers","text":"<ul> <li>Self-Documenting Code: Examples show exactly how to use functions</li> <li>Regression Testing: Changes that break documented behavior are caught</li> <li>Learning Tool: New developers can run examples to understand code</li> <li>Quality Assurance: Ensures documentation stays accurate</li> </ul>"},{"location":"development/doctest-coverage/#for-users","title":"For Users","text":"<ul> <li>Reliable Examples: All examples in documentation are tested</li> <li>Up-to-Date Documentation: Examples reflect actual code behavior</li> <li>Interactive Learning: Can copy-paste examples and run them</li> <li>Confidence: Know that documented behavior is verified</li> </ul>"},{"location":"development/doctest-coverage/#for-maintainers","title":"For Maintainers","text":"<ul> <li>Automated Testing: Doctests run automatically in CI/CD</li> <li>Quality Gates: Pre-commit hooks prevent broken examples</li> <li>Coverage Tracking: Clear metrics on documentation quality</li> <li>Maintenance: Easier to keep documentation in sync with code</li> </ul>"},{"location":"development/doctest-coverage/#future-enhancements","title":"Future Enhancements","text":""},{"location":"development/doctest-coverage/#planned-improvements","title":"Planned Improvements","text":"<ol> <li>Coverage Reporting: Generate detailed coverage reports</li> <li>Performance Testing: Add performance benchmarks to examples</li> <li>Integration Testing: More complex multi-module examples</li> <li>Visual Documentation: Generate visual documentation from doctests</li> </ol>"},{"location":"development/doctest-coverage/#tools-and-integration","title":"Tools and Integration","text":"<ul> <li>Coverage.py: Track doctest coverage metrics</li> <li>pytest-doctestplus: Enhanced doctest features</li> <li>sphinx-doctest: Integration with Sphinx documentation</li> <li>doctest-ellipsis: Support for ellipsis in expected output</li> </ul>"},{"location":"development/doctest-coverage/#related-documentation","title":"Related Documentation","text":"<ul> <li>Development Guide - General development information</li> <li>Testing Guide - Testing strategies and tools</li> <li>Contributing Guidelines - How to contribute to the project</li> <li>Makefile Targets - Available make targets including doctest commands</li> </ul>"},{"location":"development/documentation/","title":"Writing &amp; Publishing Documentation","text":"<p>Follow this guide when you need to add or update markdown pages under <code>docs/</code> and preview the documentation locally.</p>"},{"location":"development/documentation/#prerequisites","title":"\ud83e\udde9 Prerequisites","text":"<ul> <li>Python \u2265 3.10 (only for the initial virtual env - not required if you already have one)</li> <li><code>make</code> (GNU Make 4+)</li> <li>(First-time only) <code>mkdocs-material</code> and plugins are installed automatically by the docs <code>Makefile</code>.</li> <li>One-time GitHub setup, e.g. gitconfig setup</li> </ul>"},{"location":"development/documentation/#one-liner-for-a-live-preview","title":"\u26a1 One-liner for a live preview","text":"<pre><code>cd docs\nmake venv     # First-time only, installs dependencies into a venv under `~/.venv/mcpgateway-docs`\nmake serve    # http://localhost:8000 (auto-reload on save)\n</code></pre> <p>The <code>serve</code> target automatically creates a project-local virtual environment (under <code>~/.venv/mcpgateway-docs</code>) the first time you run it and installs all doc dependencies before starting MkDocs in live-reload mode.</p>"},{"location":"development/documentation/#folder-layout","title":"\ud83d\udcc2 Folder layout","text":"<pre><code>repo-root/\n\u251c\u2500 docs/              # MkDocs project (DO NOT put .md files here!)\n\u2502  \u251c\u2500 docs/           # &lt;-- \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6  place Markdown pages here\n\u2502  \u2502  \u2514\u2500 ...\n\u2502  \u251c\u2500 mkdocs.yml      # MkDocs config &amp; navigation\n\u2502  \u2514\u2500 Makefile        # build / serve / clean targets\n\u2514\u2500 Makefile           # repo-wide helper targets (lint, spellcheck, ...)\n</code></pre> <ul> <li>Add new pages inside <code>docs/docs/</code> - organise them in folders that make sense for navigation.</li> <li>Update navigation: edit <code>.pages</code> for your section so your page shows up in the left-hand nav.</li> </ul> <p>Tip: MkDocs Material auto-generates \"Edit this page\" links - keep file names lowercase-hyphen-case.</p>"},{"location":"development/documentation/#editing-tips","title":"\u270f\ufe0f Editing tips","text":"<ol> <li>Write in standard Markdown; we also support admonitions, call-outs, and Mermaid diagrams.</li> <li>Use relative links between pages: <code>[Gateway API](../api/index.md)</code>.</li> <li>For local images place them under <code>docs/docs/images/</code> and reference with <code>![](../images/example.png)</code>.</li> <li>Never edit <code>mkdocs.yml</code> - all nav structure is defined in <code>.pages</code> files (one per directory).</li> </ol>"},{"location":"development/documentation/#writing-docs","title":"\u270f\ufe0f Writing docs","text":"<p>Start each new Markdown file with a clear <code># Heading 1</code> title - this becomes the visible page title and is required for proper rendering in MkDocs.</p> <p>Follow the conventions and layout guidelines from the official MkDocs Material reference for callouts, tables, code blocks, and more. This ensures consistent formatting across the docs.</p> <p>Keep file names in <code>lowercase-hyphen-case.md</code> and use relative links when referencing other docs or images.</p>"},{"location":"development/documentation/#ordering-pages-with-pages","title":"\ud83d\uddc2\ufe0f Ordering pages with <code>.pages</code>","text":"<p>For directories that contain multiple Markdown files, we rely on the awesome-pages MkDocs plugin.</p> <p>Creating a <code>.pages</code> file inside a folder lets you:</p> <ul> <li>Set the section title (different from the folder name).</li> <li>Control the left-nav order without touching the root <code>mkdocs.yml</code>.</li> <li>Hide specific files from the navigation.</li> </ul> <p>We do not auto-generate the <code>nav:</code> structure - you must create <code>.pages</code> manually.</p> <p>Example - docs for the development section:</p> <pre><code># docs/docs/development/.pages\n# This file affects ONLY this folder and its sub-folders\n\n# Optional: override the title shown in the nav\n# title: Development Guide\n\nnav:\n  - index.md        # \u279f /development/ (landing page)\n  - github.md       # contribution workflow\n  - building.md     # local build guide\n  - packaging.md    # release packaging steps\n</code></pre> <p>Guidelines:</p> <ol> <li>Always include <code>index.md</code> first so the folder has a clean landing URL.</li> <li>List files in the exact order you want them to appear; anything omitted is still built but won't show in the nav.</li> <li>You can nest <code>.pages</code> files in deeper folders - rules apply hierarchically.</li> <li>Avoid circular references: do not include files from other directories.</li> </ol> <p>After saving a <code>.pages</code> file, simply refresh the browser running <code>make serve</code>; MkDocs will hot-reload and the navigation tree will update instantly.</p>"},{"location":"development/documentation/#pre-commit-checklist","title":"\u2705 Pre-commit checklist","text":"<p>From the repository root run all lint &amp; QA checks before pushing:</p> <pre><code>make spellcheck           # Spell-check the codebase\nmake spellcheck-sort      # Sort local spellcheck dictionary\nmake markdownlint         # Lint Markdown files with markdownlint (requires markdownlint-cli)\nmake pre-commit           # Run all configured pre-commit hooks\n</code></pre> <p>These targets are defined in the top-level <code>Makefile</code>. Make sure you're in the repository root when running these targets.</p>"},{"location":"development/documentation/#cleaning-up","title":"\ud83e\uddf9 Cleaning up","text":"<pre><code>cd docs\nmake clean       # remove generated site/\nmake git-clean   # remove ignored files per .gitignore\nmake git-scrub   # blow away *all* untracked files - use with care!\n</code></pre>"},{"location":"development/documentation/#rebuilding-the-static-site","title":"\ud83d\udd04 Rebuilding the static site","text":"<p>This is not necessary, as this will be done automatically when publishing.</p> <pre><code>cd docs\nmake build    # outputs HTML into docs/site/\n</code></pre> <p>The <code>build</code> target produces a fully-static site (used by CI for docs previews and by GitHub Pages).</p>"},{"location":"development/documentation/#publishing-ci","title":"\ud83d\udce4 Publishing (CI)","text":"<p>Docs are tested, but not deployed automatically by GitHub Actions on every push to <code>main</code>. The workflow runs <code>cd docs &amp;&amp; make build</code>.</p> <p>Publishing is done manually by repo maintainers with <code>make deploy</code> which publishes the generated site to GitHub Pages.</p>"},{"location":"development/documentation/#related-reading","title":"\ud83d\udd17 Related reading","text":"<ul> <li>Building Locally - how to run the gateway itself</li> </ul>"},{"location":"development/github/","title":"GitHub Workflow Guide","text":"<p>This mini-handbook covers the daily Git tasks we use on mcp-context-forge - from the first clone to the last merge.</p>"},{"location":"development/github/#1-one-time-setup","title":"1. One-Time Setup","text":"<pre><code># Fork on GitHub from https://github.com/IBM/mcp-context-forge.git first, then:\ngit clone https://github.com/&lt;your-user&gt;/mcp-context-forge.git\ncd mcp-context-forge\n\n# Add the canonical repo so you can pull upstream changes\ngit remote add upstream https://github.com/IBM/mcp-context-forge.git\ngit remote -v   # sanity-check remotes\n</code></pre>"},{"location":"development/github/#15-installing-github-cli-gh","title":"1.5 Installing GitHub CLI (<code>gh</code>)","text":""},{"location":"development/github/#macos-homebrew","title":"macOS (Homebrew)","text":"<pre><code>brew install gh\n</code></pre>"},{"location":"development/github/#windows-winget","title":"Windows (winget)","text":"<p>While you can run all this through Powershell, the recommended way to develop on Windows is through WSL2 and Visual Studio Code. The same steps as Ubuntu/Debian apply.</p> <pre><code>winget install GitHub.cli\n</code></pre>"},{"location":"development/github/#ubuntu-debian","title":"Ubuntu / Debian","text":"<pre><code>curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | \\\n  sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg\nsudo chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg\n\necho \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main\" | \\\n  sudo tee /etc/apt/sources.list.d/github-cli.list\n\nsudo apt update\nsudo apt install gh\n</code></pre>"},{"location":"development/github/#fedora-rhel","title":"Fedora / RHEL","text":"<pre><code>sudo dnf install 'https://github.com/cli/cli/releases/download/v2.74.0/gh_2.74.0_linux_amd64.rpm'\n</code></pre> <p>Tip: Replace the version number (<code>2.74.0</code>) with the latest release from https://github.com/cli/cli/releases.</p>"},{"location":"development/github/#first-time-authentication","title":"First-time authentication","text":"<pre><code>gh auth login             # follow the interactive prompts\n</code></pre> <p>Choose:</p> <ol> <li>GitHub.com</li> <li>HTTPS</li> <li>Either Paste an authentication token or Authorize in browser.</li> </ol>"},{"location":"development/github/#verify-configuration","title":"Verify configuration","text":"<pre><code>gh auth status            # should say \"Logged in to github.com as &lt;your-user&gt;\"\ngh repo view              # shows repo info if run inside a clone\n</code></pre>"},{"location":"development/github/#everyday-commands","title":"Everyday commands","text":"Command Purpose <code>gh pr checkout &lt;id&gt;</code> Fetch &amp; switch to a PR locally (used in \u00a74). <code>gh pr create -w</code> Create a PR and open it in the browser. <code>gh pr status</code> Show which PR is checked out and any requested reviews. <code>gh pr merge &lt;id&gt;</code> Squash / rebase / merge the PR from the terminal."},{"location":"development/github/#16-personal-git-configuration-recommended","title":"1.6 Personal Git Configuration (Recommended)","text":"<p>Setting a few global Git options makes everyday work friction-free and guarantees that every commit passes DCO checks.</p>"},{"location":"development/github/#161-commit-template","title":"1.6.1 Commit template","text":"<p>Create a single-line template that Git pre-pends to every commit message so you never forget the sign-off:</p> <pre><code>echo 'Signed-off-by: &lt;Your Name&gt; &lt;you@example.com&gt;' &gt; ~/.git-commit-template\n</code></pre>"},{"location":"development/github/#162-gitconfig-example","title":"1.6.2 <code>~/.gitconfig</code> example","text":"<p>Put this in <code>~/.gitconfig</code> (or append the bits you're missing):</p> <pre><code># ~/.gitconfig\n[user]\n    name = &lt;Your Name&gt;\n    email = &lt;you@example.com&gt;\n\n[init]\n    defaultBranch = main  # Use 'main' instead of 'master' when creating new repos\n\n[core]\n    autocrlf = input       # On commit: convert CRLF to LF (Windows \u2192 Linux)\n    eol = lf               # Ensure all files in the repo use LF internally\n\n[alias]\n    cm = commit -s -m      # `git cm \"message\"` \u2192 signed commit\n    ca = commit --amend -s # `git ca` \u2192 amend + sign-off\n\n[commit]\n    template = ~/.git-commit-template\n</code></pre> <p>Or run the one-liners:</p> <pre><code>git config --global user.name  \"Your Name\"\ngit config --global user.email \"you@example.com\"\ngit config --global alias.cm   \"commit -s -m\"\ngit config --global alias.ca   \"commit --amend -s\"\ngit config --global commit.template ~/.git-commit-template\n</code></pre> <p>Replace placeholders with your real details, and you're good to go.</p>"},{"location":"development/github/#2-staying-in-sync-with-upstream","title":"2. Staying in Sync with Upstream","text":"<pre><code># From any branch:\ngit fetch upstream\ngit switch main                 # or master, depending on the project\ngit merge --ff-only upstream/main\n\ngit push origin main             # keep your fork up to date\n</code></pre>"},{"location":"development/github/#3-creating-your-own-work-branch","title":"3. Creating Your Own Work Branch","text":"<pre><code>git switch -c feat/my-great-idea\n# ...hack away...\ngit add .\n# Always sign your commits for DCO compliance:\ngit commit -s -m \"feat: explain context-merging algorithm\"\n\ngit push -u origin HEAD          # publishes the branch\n# Then open a Pull Request (PR) on GitHub.\n</code></pre> <p>Why <code>-s</code>? The <code>-s / --signoff</code> flag appends a <code>Signed-off-by: Your Name &lt;email&gt;</code> trailer that lets CI verify Developer Certificate of Origin (DCO) compliance.</p>"},{"location":"development/github/#4-fetching-reviewing-an-existing-pr","title":"4. Fetching &amp; Reviewing an Existing PR","text":""},{"location":"development/github/#41-with-plain-git-works-everywhere","title":"4.1 With Plain Git (works everywhere)","text":"<pre><code>git fetch upstream pull/29/head:pr-29   # Pull Request #29\ngit switch pr-29\n</code></pre>"},{"location":"development/github/#42-with-github-cli-fastest-if-installed","title":"4.2 With GitHub CLI (fastest if installed)","text":"<pre><code>gh pr checkout 29\n</code></pre>"},{"location":"development/github/#5-smoke-testing-every-pr-before-you-comment","title":"5. Smoke-Testing Every PR Before You Comment \ud83c\udf0b","text":"<p>Hard rule: No PR gets a \"Looks good to me\" without passing both the local and container builds below.</p>"},{"location":"development/github/#51-local-build-sqlite-self-signed-https","title":"5.1 Local build (SQLite + self-signed HTTPS)","text":"<pre><code>make venv install install-dev serve-ssl\n</code></pre> <ul> <li>Sets up a Python virtualenv</li> <li>Installs runtime + dev dependencies</li> <li>Runs the HTTPS dev server against SQLite</li> </ul>"},{"location":"development/github/#52-container-build-postgresql-redis","title":"5.2 Container build (PostgreSQL + Redis)","text":"<pre><code>make compose-up\n</code></pre> <ul> <li>Spins up the full Docker Compose stack</li> <li>Uses PostgreSQL for persistence and Redis for queueing</li> <li>Rebuilds images so you catch Docker-specific issues</li> </ul>"},{"location":"development/github/#53-gateway-jwt-local-api-access","title":"5.3 Gateway JWT (local API access)","text":"<p>Quickly confirm that authentication works and the gateway is healthy:</p> <pre><code>export MCPGATEWAY_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token -u admin --secret my-test-key)\ncurl -s -k -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" https://localhost:4444/health\n</code></pre> <p>Expected output:</p> <pre><code>{\"status\": \"ok\"}\n</code></pre> <p>If you see anything other than <code>{\"status\":\"ok\"}</code>, investigate before approving the PR.</p> <p>Quickly confirm that the MCP Gateway is configured with the correct database, and it is reachable:</p> <pre><code>curl -s -k -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" https://localhost:4444/version | jq\n</code></pre> <p>Then proceed to register an MCP Server under Gateways using the UI, ensuring that Tools work, creating a Virtual Server and testing that from UI, API and a MCP Client.</p> <p>These steps are described in Basic Testing.</p>"},{"location":"development/github/#54-run-the-automated-test-suite","title":"5.4 Run the automated test suite","text":"<pre><code>make test         # or `pytest` directly\n</code></pre> <p>All tests must pass locally. If you add or modify functionality, ensure new tests cover the change.</p>"},{"location":"development/github/#55-lint-static-analysis","title":"5.5 Lint &amp; static analysis","text":"<pre><code>make lint         # runs ruff, mypy, black --check, etc.\n</code></pre> <p>Code should come back clean. Fix any warnings before pushing.</p> <p>If any of the above steps fail, leave a review requesting fixes and paste the relevant logs inline or as a gist.</p>"},{"location":"development/github/#6-squashing-commits","title":"6. Squashing Commits \ud83e\udd5e","text":"<p>Keeping a clean, single-commit history per PR makes <code>git bisect</code> and blame easier.</p>"},{"location":"development/github/#61-squash-interactively-local-recommended","title":"6.1 Squash interactively (local, recommended)","text":"<pre><code># In your feature branch, before pushing OR after addressing review feedback:\n\ngit fetch upstream  # make sure refs are fresh\ngit rebase -i upstream/main\n</code></pre> <p>In the interactive list, mark the first commit as <code>pick</code> and every subsequent one as <code>squash</code> (or <code>fixup</code> for no extra message). Save &amp; quit; Git opens an editor so you can craft the final commit message-remember to keep the <code>Signed-off-by</code> line!</p> <p>If the branch is already on GitHub and you've squashed locally, force-push the updated, single-commit branch:</p> <pre><code>git push --force-with-lease\n</code></pre>"},{"location":"development/github/#62-squash-via-github-ui-simple-but-last-minute","title":"6.2 Squash via GitHub UI (simple, but last-minute)","text":"<ol> <li>In the PR, click \"Merge\" \u2192 \"Squash and merge.\"</li> <li>Tweak the commit title/description as needed.</li> <li>Ensure the <code>Signed-off-by:</code> trailer is present (GitHub adds it automatically if you enabled DCO in the repo).</li> </ol> <p>Use the UI method only if reviewers are done-every push re-triggers CI.</p>"},{"location":"development/github/#7-functional-code-review-checklist","title":"7. Functional &amp; Code Review Checklist","text":"Check Why it matters Does it build locally? Fastest signal that the code even compiles. Does it build in Docker? Catches missing OS packages or env-var mishaps. Unit tests green? Ensures regressions are caught immediately. No new lint errors? Keeps the CI pipeline and codebase clean. Commits squashed &amp; signed? One commit history + DCO compliance. Docs / comments updated? Future devs will thank you."},{"location":"development/github/#8-merging-the-pr","title":"8. Merging the PR","text":"<ul> <li>Squash-and-merge is the default merge strategy.</li> <li>Confirm the final commit message follows Conventional Commits and retains a <code>Signed-off-by:</code> trailer.</li> <li>GitHub automatically deletes the source branch after a successful merge-no manual cleanup required.</li> </ul> <p>Verify GitHub CI status checks</p> <p>Before requesting review, confirm that all required status checks on the PR page are green \u2705 (\"All checks have passed\"). You should now see something like:</p> <pre><code>Bandit / bandit (pull_request)                  \u2705  Successful in 21s\nBuild Python Package / build-package (3.10)     \u2705  Successful in 12s\nCode scanning results / Bandit                  \u2705  No new alerts in code changed by this pull request\nCode scanning results / Dockle                  \u2705  No new alerts in code changed by this pull request\nCode scanning results / Hadolint                \u2705  No new alerts in code changed by this pull request\nCode scanning results / Trivy                   \u2705  No new alerts in code changed by this pull request\nCodeQL Advanced / CodeQL (javascript-typescript)\u2705  Successful in 1m\nCodeQL Advanced / CodeQL (python)               \u2705  Successful in 1m\nDCO                                             \u2705  Passed\nDependency Review / dependency-review           \u2705  Successful in 4s\nSecure Docker Build / build-scan-sign           \u2705  Successful in 4m\nTravis CI - Branch                              \u2705  Build Passed\nTravis CI - Pull Request                        \u2705  Build Passed\n</code></pre> <p>If anything is red or still running, wait or push a fix in the same PR until every line is green. Ensure that a CODEOWNER is assigned to review the PR.</p> <p>Once the PR is merged, double-check that the CI/CD pipeline deploys the change to all environments without errors.</p> <p>If any of the above steps fail after the PR is merged or cannot deploy, leave a review requesting fixes and paste the relevant logs inline or as a gist.</p>"},{"location":"development/github/#9-cleaning-up-locally","title":"9. Cleaning Up Locally","text":"<p>After the PR is merged: * Switch back to the main branch * Delete the local feature branch * Prune deleted remote branches <pre><code>git switch main\ngit branch -D pr-29                # or the feature branch name (replace pr-29 with your branch name)\ngit fetch -p                       # prune remotes that GitHub deleted\n</code></pre> This removes references to remote branches that GitHub deleted after the merge. This keeps your local environment clean and up to date.</p>"},{"location":"development/github/#10-handy-git-aliases-optional","title":"10. Handy Git Aliases (Optional)","text":"<p><pre><code>git config --global alias.co checkout\ngit config --global alias.cm 'commit -s -m'\ngit config --global alias.ca 'commit --amend -s'\ngit config --global alias.rb \"rebase -i --autosquash\"\ngit config --global alias.pr '!f() { git fetch upstream pull/$1/head:pr-$1 &amp;&amp; git switch pr-$1; }; f'\n</code></pre> Now you can run <code>git pr 42</code> to fetch-and-switch to PR #42 in one go. These aliases are optional, but they save time and make Git commands easier to type.</p>"},{"location":"development/github/#11-troubleshooting-faq","title":"11. Troubleshooting FAQ","text":"Symptom Fix <code>error: cannot lock ref</code> Run <code>git gc --prune=now</code> and retry. <code>docker: no space left</code> <code>docker system prune -af &amp;&amp; docker volume prune</code> Unit tests hang on macOS Ensure you aren't on an Apple-Silicon image that needs platform flags."},{"location":"development/github/#happy-hacking","title":"Happy hacking! \ud83d\udee0\ufe0f","text":"<p>Submit improvements to this doc via another signed, squashed PR so everyone benefits.</p>"},{"location":"development/packaging/","title":"Packaging &amp; Distribution","text":"<p>This guide covers how to package MCP Gateway for deployment in various environments, including building production containers and generating releases.</p>"},{"location":"development/packaging/#production-container-podman-or-docker","title":"\ud83d\udce6 Production Container (Podman or Docker)","text":"<p>Build an OCI-compliant container image using:</p> <pre><code>make podman\npodman build -t mcpgateway:latest -f Containerfile .\n</code></pre> <p>Or with Docker (if Podman is not available):</p> <pre><code>make docker\n# or manually\ndocker build -t mcpgateway:latest -f Containerfile .\n</code></pre> <p>A lite image is also available for use in production, see <code>Containerfile.lite</code></p>"},{"location":"development/packaging/#run-with-tls-self-signed","title":"\ud83d\udd10 Run with TLS (self-signed)","text":"<pre><code>make podman-run-ssl\n</code></pre> <p>This uses self-signed certs from <code>./certs/</code> and runs HTTPS on port <code>4444</code>.</p>"},{"location":"development/packaging/#container-run-http","title":"\ud83d\udee0 Container Run (HTTP)","text":"<pre><code>make podman-run\n</code></pre> <p>This runs the container without TLS on port <code>4444</code>.</p>"},{"location":"development/packaging/#versioning","title":"\ud83d\udcdd Versioning","text":"<p>MCP Gateway uses semantic versioning (<code>MAJOR.MINOR.PATCH</code>) and the version is defined in:</p> <pre><code>mcpgateway/__init__.py\n</code></pre> <p>You can bump the version manually or automate it via Git tags or CI/CD.</p>"},{"location":"development/packaging/#release-artifacts","title":"\ud83d\udcc1 Release Artifacts","text":"<p>If you need to ship ZIPs, wheels, or a full binary:</p> <pre><code>python3 -m build\n</code></pre> <p>Outputs will be under <code>dist/</code>. You can then:</p> <ul> <li>Push to PyPI (internal or public)</li> <li>Upload to GitHub Releases</li> <li>Package in a <code>.deb</code>, <code>.rpm</code>, etc.</li> </ul>"},{"location":"development/packaging/#whats-in-the-container","title":"\ud83d\udcc2 What's in the Container?","text":"<p>A typical image includes:</p> <ul> <li>Gunicorn running with <code>mcpgateway.main:app</code></li> <li>All code, static files, and compiled assets</li> </ul> <p>You can override settings using environment variables at runtime.</p>"},{"location":"development/review/","title":"Reviewing a Pull Request","text":"<p>This guide explains the day-to-day steps for reviewing a PR on GitHub, using both Git and the GitHub CLI (<code>gh</code>). It assumes you have already completed the one-time setup from the main workflow guide.</p>"},{"location":"development/review/#1-prerequisites","title":"1. Prerequisites","text":"<p>You should already have:</p> <ul> <li>A local clone of the forked repository, with <code>origin</code> pointing to your fork and <code>upstream</code> pointing to the canonical repo.</li> <li>The GitHub CLI (<code>gh</code>) installed and authenticated.</li> <li>Your <code>main</code> branch up to date with upstream:</li> </ul> <pre><code>  git fetch upstream\n  git switch main\n  git merge --ff-only upstream/main\n</code></pre>"},{"location":"development/review/#2-fetching-checking-out-the-pr","title":"2. Fetching &amp; Checking Out the PR","text":""},{"location":"development/review/#21-using-github-cli","title":"2.1 Using GitHub CLI","text":"<pre><code>gh pr checkout &lt;PR-number&gt;\n</code></pre> <p>This automatically fetches the PR and switches to a branch named <code>pr-&lt;PR-number&gt;</code>.</p>"},{"location":"development/review/#22-using-plain-git","title":"2.2 Using Plain Git","text":"<pre><code>git fetch upstream pull/&lt;PR-number&gt;/head:pr-&lt;PR-number&gt;\ngit switch pr-&lt;PR-number&gt;\n</code></pre>"},{"location":"development/review/#3-smoke-testing-the-changes","title":"3. Smoke-Testing the Changes","text":"<p>Before you read code or leave comments, always verify the PR builds and tests cleanly.</p>"},{"location":"development/review/#31-local-build","title":"3.1 Local Build","text":"<pre><code>make venv install install-dev serve   # Install into a fresh venv, and test it runs locally\n</code></pre>"},{"location":"development/review/#32-container-build-and-testing-with-postgres-and-redis-compose","title":"3.2 Container Build and testing with Postgres and Redis (compose)","text":"<pre><code>make docker-prod    # Build a new image\n# Change: image: mcpgateway/mcpgateway:latest in docker-compose.yml to use the local image\nmake compose-up     # spins up the Docker Compose stack\n\n# Test the basics\ncurl -k https://localhost:4444/health` # {\"status\":\"healthy\"}\nexport MCPGATEWAY_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token --username admin --exp 0 --secret my-test-key)\ncurl -sk -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" http://localhost:4444/version  | jq -c '.database, .redis'\n\n# Add an MCP server to http://localhost:4444 then check logs:\nmake compose-logs\n</code></pre>"},{"location":"development/review/#33-automated-tests","title":"3.3 Automated Tests","text":"<pre><code>make test           # or `pytest`\n</code></pre>"},{"location":"development/review/#34-lint-static-analysis","title":"3.4 Lint &amp; Static Analysis","text":"<pre><code>make lint           # runs ruff, mypy, black --check, eslint, etc.\n</code></pre> <p>If any step fails, request changes and paste the relevant error logs.</p>"},{"location":"development/review/#4-functional-code-review-checklist","title":"4. Functional &amp; Code Review Checklist","text":"<p>Use this checklist as you browse the changes:</p> Check Why it matters Does it build locally? Ensures no missing dependencies or compile errors. Does it build in Docker? Catches environment-specific issues. Tests are green? Guards against regressions. No new lint errors? Maintains code quality and consistency. Commits are clean &amp; signed? One-commit history &amp; DCO compliance. Code follows style guidelines Consistency in formatting, naming, and patterns. Security checks passed No secrets leaked, inputs validated, etc. Docs / comments updated? Documentation stays in sync with code. Edge cases &amp; error handling Robustness against invalid inputs or failures."},{"location":"development/review/#5-leaving-feedback","title":"5. Leaving Feedback","text":""},{"location":"development/review/#51-inline-comments","title":"5.1 Inline Comments","text":"<p>Use <code>gh pr review</code> to leave comments:</p> <pre><code># To comment without approving\ngh pr review --comment --body \"Nit: rename this variable for clarity.\"\n\n# To request changes\ngh pr review --request-changes --body \"Tests are failing on CI, please fix.\"\n\n# To approve\ngh pr review --approve --body \"Looks good to me!\"\n</code></pre>"},{"location":"development/review/#52-approving-in-the-ui","title":"5.2 Approving in the UI","text":"<ol> <li>On the PR page, click \"Files changed\".</li> <li>Hover over a line and click the + to leave an inline comment.</li> <li>After addressing all comments, click Review changes \u2192 Approve.</li> </ol>"},{"location":"development/review/#6-merging-the-pr-as-a-maintainer","title":"6. Merging the PR (as a Maintainer)","text":"<p>Only merge once all approvals, status checks, and CI jobs are green.</p> <ol> <li>On GitHub, click Merge pull request.</li> <li>Choose Squash and merge (default) or Rebase and merge.</li> <li>Verify the commit title and body follow Conventional Commits.</li> <li>Confirm the Signed-off-by trailer is present.</li> <li>Click Confirm merge.</li> </ol> <p>GitHub will delete the <code>pr-&lt;number&gt;</code> branch automatically.</p>"},{"location":"development/review/#7-cleaning-up-locally","title":"7. Cleaning Up Locally","text":"<p>After the PR is merged: * Switch back to the main branch * Delete the local feature branch * Prune deleted remote branches <pre><code>git switch main\ngit branch -D pr-&lt;PR-number&gt;             # replace &lt;PR-number&gt; with your branch name\ngit fetch -p                             # prune deleted remotes\n</code></pre> This removes references to remote branches that GitHub deleted after the merge. This keeps your local environment clean and up to date.</p>"},{"location":"faq/","title":"ContextForge MCP Gateway - Frequently Asked Questions","text":""},{"location":"faq/#quickstart","title":"\u26a1 Quickstart","text":"\ud83d\ude80 How can I install and run MCP Gateway in one command? <p>PyPI (pipx / uvx makes an isolated venv):</p> <pre><code># Using pipx - pip install pipx\npipx run mcp-contextforge-gateway\n\n# Or uvx - pip install uv (default: admin/changeme)\nuvx mcp-contextforge-gateway --port 4444\n</code></pre> <p>OCI image (Docker/Podman) - shares host network so localhost works:</p> <pre><code>podman run --network=host -p 4444:4444 ghcr.io/ibm/mcp-context-forge:latest\n</code></pre> \ud83d\uddc2\ufe0f What URLs are available for the admin interface and API docs? <ul> <li>Admin UI \u2192 https://localhost:4444</li> <li>Swagger \u2192 https://localhost:4444/docs</li> <li>ReDoc \u2192 https://localhost:4444/redoc</li> </ul>"},{"location":"faq/#what-is-mcp-model-context-protocol","title":"\ud83e\udd14 What is MCP (Model Context Protocol)?","text":"\ud83d\udca1 What is MCP in a nutshell? <p>MCP is an open-source protocol released by Anthropic in Nov 2024 that lets language models invoke external tools via a typed JSON-RPC envelope. Community folks call it \"USB-C for AI\"-one connector for many models.</p> \ud83c\udf0d Who supports MCP and what's the ecosystem like? <ul> <li>Supported by GitHub &amp; Microsoft Copilot, AWS Bedrock, Google Cloud Vertex AI, IBM watsonx, AgentBee, LangChain, CrewAI and 15,000+ community servers.</li> <li>Contracts enforced via JSON Schema.</li> <li>Multiple transports (STDIO, SSE, HTTP) - still converging.</li> </ul>"},{"location":"faq/#media-kit","title":"\ud83e\uddf0 Media Kit","text":"\ud83d\uddbc\ufe0f I want to make a social media post, where can I find samples and logos? <p>See the provided media kit</p> \ud83d\udcc4 How do I describe the gateway in boilerplate copy? <p>\"ContextForge MCP Gateway is an open-source reverse-proxy that unifies MCP and REST tool servers under a single secure HTTPS endpoint with discovery, auth and observability baked in.\"</p>"},{"location":"faq/#installation-configuration","title":"\ud83d\udee0\ufe0f Installation &amp; Configuration","text":"\ud83d\udd27 What is the minimal .env setup required? <pre><code>cp .env.example .env\n</code></pre> <p>Then edit:</p> <pre><code>BASIC_AUTH_USER=admin\nBASIC_AUTH_PASSWORD=changeme\nJWT_SECRET_KEY=my-test-key\n</code></pre> \ud83e\ude9b What are some advanced environment variables I can configure? <ul> <li>Basic: <code>HOST</code>, <code>PORT</code>, <code>APP_ROOT_PATH</code></li> <li>Auth: <code>AUTH_REQUIRED</code>, <code>BASIC_AUTH_*</code>, <code>JWT_SECRET_KEY</code></li> <li>Logging: <code>LOG_LEVEL</code>, <code>LOG_FORMAT</code>, <code>LOG_FILE</code></li> <li>Transport: <code>TRANSPORT_TYPE</code>, <code>WEBSOCKET_PING_INTERVAL</code>, <code>SSE_RETRY_TIMEOUT</code></li> <li>Tools: <code>TOOL_TIMEOUT</code>, <code>MAX_TOOL_RETRIES</code>, <code>TOOL_RATE_LIMIT</code>, <code>TOOL_CONCURRENT_LIMIT</code></li> <li>Federation: <code>FEDERATION_ENABLED</code>, <code>FEDERATION_PEERS</code>, <code>FEDERATION_SYNC_INTERVAL</code></li> </ul>"},{"location":"faq/#running-deployment","title":"\ud83d\ude80 Running &amp; Deployment","text":"\ud83c\udfe0 How do I run MCP Gateway locally using PyPI? <pre><code>python3 -m venv .venv &amp;&amp; source .venv/bin/activate\npip install mcp-contextforge-gateway\nmcpgateway\n</code></pre> \ud83d\udc33 How do I use the provided Makefile and Docker/Podman setup? <pre><code>make podman # or make docker\nmake podman-run-ssl # or make docker-run-ssl\nmake podman-run-ssl-host # or make docker-run-ssl-host\n</code></pre> <p>Docker Compose is also available, ex: <code>make compose-up</code>.</p> \u2601\ufe0f How can I deploy MCP Gateway on Google Cloud Run, Code Engine, Kubernetes, AWS, etc? <p>See the Deployment Documentation for detailed deployment instructions across local, docker, podman, compose, AWS, Azure, GCP, IBM Cloud, Helm, Minikube, Kubernetes, OpenShift and more.</p>"},{"location":"faq/#databases-persistence","title":"\ud83d\udcbe Databases &amp; Persistence","text":"\ud83d\uddc4\ufe0f What databases are supported for persistence? <ul> <li>SQLite (default) - used for development / small deployments.</li> <li>PostgreSQL / MySQL / MariaDB via <code>DATABASE_URL</code></li> <li>Redis (optional) for high performance session management. Sessions can also be stored in the DB or memory.</li> <li>Other databases supported by SQLAlchemy.</li> </ul> \ud83d\udce6 How do I persist SQLite across container restarts? <p>Include a persistent volume with your container or Kubernetes deployment. Ex:</p> <pre><code>docker run -v $(pwd)/data:/app ghcr.io/ibm/mcp-context-forge:latest\n</code></pre> <p>For production use, we recommend PostgreSQL. A Docker Compose target with PostgreSQL and Redis is provided.</p>"},{"location":"faq/#security-auth","title":"\ud83d\udd10 Security &amp; Auth","text":"\ud83c\udd93 How do I disable authentication for development? <p>Set <code>AUTH_REQUIRED=false</code> - disables login for local testing.</p> \ud83d\udd11 How do I generate and use a JWT token? <pre><code>export MCPGATEWAY_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token -u admin -exp 0 --secret my-test-key)\ncurl -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" https://localhost:4444/tools\n</code></pre> <p>The token is used for all API interactions and can be configured to expire using <code>-exp</code>.</p> \ud83d\udee1\ufe0f How do I enable TLS and configure CORS? <ul> <li>Use <code>make podman-run-ssl</code> for self-signed certs or drop your own certificate under <code>certs</code>.</li> <li>Set <code>ALLOWED_ORIGINS</code> or <code>CORS_ENABLED</code> for CORS headers.</li> </ul>"},{"location":"faq/#tools-servers-federation","title":"\ud83d\udce1 Tools, Servers &amp; Federation","text":"\u2795 How do I register a tool with the gateway? <pre><code>curl -X POST -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\\\n     -H \"Content-Type: application/json\" \\\\\n     -d '{\"name\":\"clock_tool\",\"url\":\"http://localhost:9000/rpc\",\"input_schema\":{\"type\":\"object\"}}' \\\\\n     http://localhost:4444/tools\n</code></pre> \ud83c\udf09 How do I add a peer MCP gateway? <p>A \"Gateway\" is another MCP Server. The MCP Gateway itself is an MCP Server. This means you can add any MCP Server under \"Gateways\" and it will retrieve Tools/Resources/Prompts.</p> <pre><code>curl -X POST -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\\\n     -d '{\"name\":\"peer\",\"url\":\"http://peer:4444\"}' \\\\\n     http://localhost:4444/gateways\n</code></pre> \ud83d\udd87\ufe0f What are virtual servers and how do I use them? <p>A Virtual Server is a MCP Server composed from Tools/Resources/Prompts from multiple servers. Add one or more MCP Servers under \"Gateways\", then select which Tools/Prompts/Resources to use to create your Virtual Server.</p>"},{"location":"faq/#performance-tuning-scaling","title":"\ud83c\udfce\ufe0f Performance Tuning &amp; Scaling","text":"\u2699\ufe0f What environment variables affect performance? <ul> <li><code>TOOL_CONCURRENT_LIMIT</code></li> <li><code>TOOL_RATE_LIMIT</code></li> <li><code>WEBSOCKET_PING_INTERVAL</code></li> <li><code>SSE_RETRY_TIMEOUT</code></li> </ul> \ud83e\uddf5 How do I scale the number of worker processes? <ul> <li><code>GUNICORN_WORKERS</code> (for Gunicorn)</li> <li><code>UVICORN_WORKERS</code> (for Uvicorn)</li> </ul> \ud83d\udcca How can I benchmark performance? <p>Use <code>ab</code> or <code>wrk</code> against <code>/health</code> to measure raw latency. Check out the detail performance testing harness under <code>tests/hey</code>.</p>"},{"location":"faq/#observability-logging","title":"\ud83d\udcc8 Observability &amp; Logging","text":"\ud83d\udd0d What metrics are available? <ul> <li>Prometheus-style <code>/metrics</code> endpoint</li> <li>Tool/server/prompt stats via Admin UI</li> </ul> \ud83d\udcdc What log formats are supported? <ul> <li><code>LOG_FORMAT=json</code> or <code>text</code></li> <li>Adjust with <code>LOG_LEVEL</code></li> </ul>"},{"location":"faq/#smoke-tests-troubleshooting","title":"\ud83e\uddea Smoke Tests &amp; Troubleshooting","text":"\ud83d\udeeb Is there a full test script I can run? <p>Yes - see <code>docs/basic.md</code>.</p> \ud83d\udea8 What common errors should I watch for? Symptom Resolution 401 Unauthorized Refresh token / check Authorization database is locked Use Postgres / increase DB_POOL_SIZE already exists errors Use Show inactive toggle in UI SSE drops every 30 s Raise <code>SSE_RETRY_TIMEOUT</code>"},{"location":"faq/#integration-recipes","title":"\ud83d\udcbb Integration Recipes","text":"\ud83e\udd9c How do I use MCP Gateway with LangChain? <pre><code>from langchain.tools import MCPTool\ntool = MCPTool(endpoint=\"https://localhost:4444/json-rpc\",\n               token=os.environ[\"MCPGATEWAY_BEARER_TOKEN\"])\n</code></pre> \ud83e\uddbe How do I connect GitHub's mcp-server-git via SuperGateway? <pre><code>npx -y supergateway --stdio \"uvx mcp-server-git\"\n</code></pre>"},{"location":"faq/#roadmap","title":"\ud83d\uddfa\ufe0f Roadmap","text":"\ud83e\udded What features are planned for future versions? <ul> <li>\ud83d\udd10 OAuth2 client-credentials upstream auth with full spec compliance</li> <li>\ud83c\udf19 Dark-mode UI</li> <li>\ud83e\uddfe Add \"Version and Environment Info\" tab to Admin UI</li> <li>\ud83d\udd12 Fine-grained role-based access control (RBAC) for Admin UI and API routes and per-virtual-server API keys</li> <li>\ud83d\udce6 Marketplace-style tool catalog with categories, tags, and search</li> <li>\ud83d\udd01 Support for long-running / async tool executions with polling endpoints</li> <li>\ud83d\udcc2 UI-driven prompt and resource file management (upload/edit from browser)</li> <li>\ud83d\udee0\ufe0f Visual \"tool builder\" UI to design new tools with schema and auth interactively</li> <li>\ud83e\uddea Auto-validation tests for registered tools (contract + mock invocation)</li> <li>\ud83d\udea8 Event subscription framework: trigger hooks or alerts on Gateway changes</li> <li>\ud83e\uddf5 Real-time tool logs and debug traces in Admin UI</li> <li>\ud83e\udde0 Adaptive routing based on tool health, model, or load</li> <li>\ud83d\udd0d Filterable tool invocation history with replay support</li> <li>\ud83d\udce1 Plugin-based architecture for custom transports or auth methods</li> </ul> <p>Check out the Feature issues tagged <code>enhancement</code> on GitHub for more upcoming features!</p>"},{"location":"faq/#rarely-asked-questions-raq","title":"\u2753 Rarely Asked Questions (RAQ)","text":"\ud83d\udc19 Does MCP Gateway work on a Raspberry Pi? <p>Yes - build as <code>arm64</code> and reduce RAM/workers.</p>"},{"location":"faq/#contributing-community","title":"\ud83e\udd1d Contributing &amp; Community","text":"\ud83d\udc69\ud83d\udcbb How can I file issues or contribute? <p>Use GitHub Issues and <code>CONTRIBUTING.md</code>.</p> \ud83e\uddd1\ud83c\udf93 What code style and CI tools are used? <ul> <li>Pre-commit: <code>ruff</code>, <code>black</code>, <code>mypy</code>, <code>isort</code></li> <li>Run <code>make lint</code> before PRs</li> </ul> \ud83d\udcac Where can I chat or ask questions? <p>Join the GitHub Discussions board.</p>"},{"location":"faq/#need-more-help","title":"\ud83d\ude4b Need more help?","text":"<p>Open an Issue or discussion on GitHub.</p>"},{"location":"manage/","title":"Management Overview","text":"<p>This section provides operational guidance for running and maintaining a production instance of MCP Gateway.</p> <p>Whether you're self-hosting, running in the cloud, or deploying to Kubernetes, this section helps you monitor, back up, and maintain the system.</p>"},{"location":"manage/#whats-covered","title":"\ud83e\udded What's Covered","text":"Page Description Backups How to persist and restore your database, configs, and resource state Logging Configure structured logging, log destinations, and log rotation"},{"location":"manage/#runtime-config-via-env","title":"\ud83d\udd10 Runtime Config via <code>.env</code>","text":"<p>Most operational settings (logging level, database pool size, auth mode) are controlled through <code>.env</code> or environment variables.</p> <p>Update the file and restart the container or process to apply changes.</p>"},{"location":"manage/#health-readiness","title":"\ud83e\uddea Health &amp; Readiness","text":"<p>Expose the <code>/health</code> endpoint for use with:</p> <ul> <li>Cloud load balancer health checks</li> <li>Kubernetes probes</li> <li>CI/CD smoke tests</li> </ul> <p>Sample check:</p> <pre><code>curl http://localhost:4444/health\n</code></pre> <p>Expected response:</p> <pre><code>{ \"status\": \"healthy\"}\n</code></pre>"},{"location":"manage/#service-restart-commands","title":"\ud83d\udd01 Service Restart Commands","text":"<p>Depending on your environment:</p> <ul> <li><code>docker restart mcpgateway</code></li> <li><code>kubectl rollout restart deployment/mcpgateway</code></li> </ul>"},{"location":"manage/backup/","title":"Backups","text":"<p>MCP Gateway stores its runtime state in a SQL database and optionally in Redis (for sessions and caching). This guide explains how to persist and restore that state safely.</p>"},{"location":"manage/backup/#what-needs-to-be-backed-up","title":"\ud83d\udce6 What Needs to Be Backed Up","text":"Component What It Contains Database (<code>mcp.db</code> or PostgreSQL) All tools, prompts, resources, servers, metrics <code>.env</code> file Environment variables and secrets (e.g. JWT secret, DB URL) Volume-mounted uploads (if any) User-uploaded data or TLS certs Redis (optional) Session tokens, cached resources (only if using <code>CACHE_TYPE=redis</code>)"},{"location":"manage/backup/#backup-strategies","title":"\ud83d\udcbe Backup Strategies","text":""},{"location":"manage/backup/#for-sqlite-default","title":"For SQLite (default)","text":"<pre><code>cp mcp.db backups/mcp-$(date +%F).db\n</code></pre>"},{"location":"manage/backup/#for-postgresql","title":"For PostgreSQL","text":"<pre><code>pg_dump -U youruser -h yourhost -F c -f backups/mcp-$(date +%F).pgdump\n</code></pre> <p>You can also automate this via <code>cron</code> or a container sidecar.</p>"},{"location":"manage/backup/#restore-instructions","title":"\ud83d\udd01 Restore Instructions","text":""},{"location":"manage/backup/#sqlite","title":"SQLite","text":"<pre><code>cp backups/mcp-2024-05-10.db mcp.db\n</code></pre> <p>Restart the gateway afterward.</p>"},{"location":"manage/backup/#postgresql","title":"PostgreSQL","text":"<pre><code>pg_restore -U youruser -d mcp -h yourhost backups/mcp-2024-05-10.pgdump\n</code></pre>"},{"location":"manage/backup/#storing-secrets","title":"\ud83d\uddc3 Storing Secrets","text":"<p>Use a secrets manager (e.g., AWS Secrets Manager, Azure Key Vault, or Kubernetes Secrets) to manage <code>.env</code> contents securely in production.</p>"},{"location":"manage/backup/#verify-your-backup","title":"\ud83e\uddea Verify Your Backup","text":"<p>Run smoke tests:</p> <pre><code>curl -s -k -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" http://localhost:4444/tools\ncurl -s -k -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" http://localhost:4444/prompts\n</code></pre> <p>You should see previously registered tools and templates.</p>"},{"location":"manage/backup/#understanding-the-database-schema","title":"\ud83e\uddec Understanding the Database Schema","text":"<p>MCP Gateway uses a relational database (e.g. SQLite or PostgreSQL) to persist all registered entities and track tool/server usage. When session storage is configured as <code>CACHE_TYPE=database</code>, it also persists active user sessions and streamed message content.</p>"},{"location":"manage/backup/#key-tables","title":"Key Tables","text":"Table Purpose <code>tools</code> Stores registered tools, including schemas and auth configs <code>tool_metrics</code> Tracks execution stats per tool (latency, success/fail) <code>resources</code> Stores static or dynamic URI-based resources <code>resource_metrics</code> Logs usage of resources (access count, latency, etc.) <code>resource_subscriptions</code> Tracks SSE client subscriptions to resources <code>prompts</code> Jinja2 prompt templates with input arguments <code>prompt_metrics</code> Usage metrics for each prompt <code>servers</code> Virtual servers that group tools/resources under an SSE stream <code>server_metrics</code> Invocation stats per server <code>gateways</code> External federated MCP servers added by the admin <code>mcp_sessions</code> Persistent session registry when using <code>CACHE_TYPE=database</code> <code>mcp_messages</code> Persisted streamed content (text/image/etc.) tied to sessions <code>*_association</code> tables Many-to-many mapping between tools/resources/prompts and their servers/gateways"},{"location":"manage/backup/#session-and-message-tables","title":"Session and Message Tables","text":"<p>These only appear when session/messaging backend is set to <code>database</code>:</p> <ul> <li><code>mcp_sessions</code>: Each record is an open session ID (used for SSE streams and client context).</li> <li><code>mcp_messages</code>: Stores streamed messages (text, image, resource) linked to a session-useful for debugging or offline playback.</li> </ul> <p>You can query active sessions:</p> <pre><code>SELECT session_id, created_at FROM mcp_sessions ORDER BY created_at DESC;\n</code></pre> <p>Or inspect message content (JSON-encoded):</p> <pre><code>SELECT content FROM mcp_messages WHERE session_id = 'abc123';\n</code></pre> <p>These tables are cleaned automatically when session TTLs expire, but can also be purged manually if needed.</p>"},{"location":"manage/logging/","title":"Logging","text":"<p>MCP Gateway emits structured logs that can be viewed locally or forwarded to a log aggregation service. This guide shows how to configure log levels, formats, and destinations.</p>"},{"location":"manage/logging/#log-structure","title":"\ud83e\uddfe Log Structure","text":"<p>Logs are emitted in JSON or text format, depending on your configuration.</p> <p>Example (JSON format):</p> <pre><code>{\n  \"timestamp\": \"2025-05-15T10:32:10Z\",\n  \"level\": \"INFO\",\n  \"module\": \"gateway_service\",\n  \"message\": \"Registered gateway: peer-gateway-1\"\n}\n</code></pre>"},{"location":"manage/logging/#configuring-logs","title":"\ud83d\udd27 Configuring Logs","text":"<p>You can control logging behavior using <code>.env</code> settings:</p> Variable Description Example <code>LOG_LEVEL</code> Minimum log level <code>INFO</code>, <code>DEBUG</code>, <code>ERROR</code> <code>LOG_FORMAT</code> Log output format <code>json</code> or <code>text</code> <code>LOG_FILE</code> Write logs to a file (optional) <code>/var/log/mcpgateway.log</code>"},{"location":"manage/logging/#streaming-logs-containers","title":"\ud83d\udce1 Streaming Logs (Containers)","text":"<pre><code>docker logs -f mcpgateway\n# or with Podman\npodman logs -f mcpgateway\n</code></pre>"},{"location":"manage/logging/#shipping-logs-to-external-services","title":"\ud83d\udce4 Shipping Logs to External Services","text":"<p>MCP Gateway can write to stdout or a file. To forward logs to services like:</p> <ul> <li>ELK (Elastic Stack)</li> <li>LogDNA / IBM Log Analysis</li> <li>Datadog</li> <li>Fluentd / Loki</li> </ul> <p>You can:</p> <ul> <li>Mount log files to a sidecar container</li> <li>Use a logging agent (e.g., Filebeat)</li> <li>Pipe logs to syslog-compatible services</li> </ul>"},{"location":"manage/logging/#debug-mode","title":"\ud83e\uddea Debug Mode","text":"<p>For development, enable verbose logs by setting:</p> <pre><code>LOG_LEVEL=debug\nLOG_FORMAT=text\nDEBUG=true\n</code></pre> <p>This enables detailed request traces and internal service logs.</p>"},{"location":"manage/tuning/","title":"Gateway Tuning Guide","text":"<p>This page collects practical levers for squeezing the most performance, reliability, and observability out of MCP Gateway-no matter where you run the container (Code Engine, Kubernetes, Docker Compose, Nomad, etc.).</p> <p>TL;DR</p> <ol> <li>Tune the runtime environment via <code>.env</code> and configure mcpgateway to use PostgreSQL and Redis.</li> <li>Adjust Gunicorn workers &amp; time-outs in <code>gunicorn.conf.py</code>.</li> <li>Right-size CPU/RAM for the container or spin up more instances (with shared Redis state) and change the database settings (ex: connection limits).</li> <li>Benchmark with hey (or your favourite load-generator) before &amp; after. See also: performance testing guide</li> </ol>"},{"location":"manage/tuning/#1-environment-variables-env","title":"1 - Environment variables (<code>.env</code>)","text":"Variable Default Why you might change it <code>AUTH_REQUIRED</code> <code>true</code> Disable for internal/behind-VPN deployments to shave a few ms per request. <code>JWT_SECRET_KEY</code> random Longer key \u279c slower HMAC verify; still negligible-leave as is. <code>CACHE_TYPE</code> <code>database</code> Switch to <code>redis</code> or <code>memory</code> if your workload is read-heavy and latency-sensitive. <code>DATABASE_URL</code> SQLite Move to managed PostgreSQL + connection pooling for anything beyond dev tests. <code>HOST</code>/<code>PORT</code> <code>0.0.0.0:4444</code> Expose a different port or bind only to <code>127.0.0.1</code> behind a reverse-proxy. <p>Tip  Any change here requires rebuilding or restarting the container if you pass the file with <code>--env-file</code>.</p>"},{"location":"manage/tuning/#2-gunicorn-settings-gunicornconfpy","title":"2 - Gunicorn settings (<code>gunicorn.conf.py</code>)","text":"Knob Purpose Rule of thumb <code>workers</code> Parallel processes <code>2-4 \u00d7 vCPU</code> for CPU-bound work; fewer if memory-bound. <code>threads</code> Per-process threads Use only with <code>sync</code> worker; keeps memory low for I/O workloads. <code>timeout</code> Kill stuck worker Set \u2265 end-to-end model latency. E.g. 600 s for LLM calls. <code>preload_app</code> Load app once Saves RAM; safe for pure-Python apps. <code>worker_class</code> Async workers <code>gevent</code> or <code>eventlet</code> for many concurrent requests / websockets. <code>max_requests(+_jitter)</code> Self-healing Recycle workers to mitigate memory leaks. <p>Edit the file before building the image, then redeploy.</p>"},{"location":"manage/tuning/#3-container-resources","title":"3 - Container resources","text":"vCPU \u00d7 RAM Good for Notes <code>0.5 \u00d7 1 GB</code> Smoke tests / CI Smallest footprint; likely CPU-starved under load. <code>1 \u00d7 4 GB</code> Typical dev / staging Handles a few hundred RPS with default 8 workers. <code>2 \u00d7 8 GB</code> Small prod Allows ~16-20 workers; good concurrency. <code>4 \u00d7 16 GB</code>+ Heavy prod Combine with async workers or autoscaling. <p>Always test with your workload; JSON-RPC payload size and backend model latency change the equation.</p> <p>To change your database connection settings, see the respective documentation for your selected database or managed service. For example, when using IBM Cloud Databases for PostgreSQL - you can raise the maximum number of connections.</p>"},{"location":"manage/tuning/#4-performance-testing","title":"4 - Performance testing","text":""},{"location":"manage/tuning/#41-tooling-hey","title":"4.1 Tooling: hey","text":"<p>Install one of:</p> <pre><code>brew install hey            # macOS\nsudo apt install hey         # Debian/Ubuntu\n# or build from source\ngo install github.com/rakyll/hey@latest  # $GOPATH/bin must be in PATH\n</code></pre>"},{"location":"manage/tuning/#42-sample-load-test-script-testsheysh","title":"4.2 Sample load-test script (<code>tests/hey.sh</code>)","text":"<pre><code>#!/usr/bin/env bash\n# Run 10 000 requests with 200 concurrent workers.\nJWT=\"$(cat jwt.txt)\"   # &lt;- place a valid token here\nhey -n 10000 -c 200 \\\n    -m POST \\\n    -T application/json \\\n    -H \"Authorization: Bearer ${JWT}\" \\\n    -D tests/hey/payload.json \\\n    http://localhost:4444/rpc\n</code></pre> <p>Payload (<code>tests/hey/payload.json</code>)</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"convert_time\",\n  \"params\": {\n    \"source_timezone\": \"Europe/Berlin\",\n    \"target_timezone\": \"Europe/Dublin\",\n    \"time\": \"09:00\"\n  }\n}\n</code></pre>"},{"location":"manage/tuning/#43-reading-the-output","title":"4.3 Reading the output","text":"<p><code>hey</code> prints latency distribution, requests/second, and error counts. Focus on:</p> <ul> <li>99<sup>th</sup> percentile latency - adjust <code>timeout</code> if it clips.</li> <li>Errors - 5xx under load often mean too few workers or DB connections.</li> <li>Throughput (RPS) - compare before/after tuning.</li> </ul>"},{"location":"manage/tuning/#44-common-bottlenecks-fixes","title":"4.4 Common bottlenecks &amp; fixes","text":"Symptom Likely cause Mitigation High % of 5xx under load Gunicorn workers exhausted Increase <code>workers</code>, switch to async workers, raise CPU. Latency &gt; timeout Long model call / external API Increase <code>timeout</code>, add queueing, review upstream latency. Memory OOM Too many workers / large batch size Lower <code>workers</code>, disable <code>preload_app</code>, add RAM."},{"location":"manage/tuning/#5-logging-observability","title":"5 - Logging &amp; observability","text":"<ul> <li>Set <code>loglevel = \"debug\"</code> in <code>gunicorn.conf.py</code> during tests; revert to <code>info</code> in prod.</li> <li>Forward <code>stdout</code>/<code>stderr</code> from the container to your platform's log stack (e.g. <code>kubectl logs</code>, <code>docker logs</code>).</li> <li>Expose <code>/metrics</code> via Prometheus exporter (coming soon) for request timing &amp; queue depth.</li> </ul>"},{"location":"manage/tuning/#6-security-tips-while-tuning","title":"6 - Security tips while tuning","text":"<ul> <li>Never commit real <code>JWT_SECRET_KEY</code>, DB passwords, or tokens-use <code>.env.example</code> as a template.</li> <li>Prefer platform secrets (K8s Secrets, Code Engine secrets) over baking creds into the image.</li> <li>If you enable <code>gevent</code>/<code>eventlet</code>, pin their versions and run bandit or trivy scans.</li> </ul>"},{"location":"manage/upgrade/","title":"Upgrading MCP Gateway and Managing Database Migrations","text":"<p>This guide provides step-by-step instructions for upgrading the MCP Gateway and handling associated database migrations to ensure a smooth transition with minimal downtime.</p>"},{"location":"manage/upgrade/#upgrade-overview","title":"\ud83d\udd04 Upgrade Overview","text":"<p>MCP Gateway is under active development, and while we strive for backward compatibility, it's essential to review version changes carefully when upgrading. Due to rapid iterations, documentation updates may sometimes lag. If you encounter issues, consult our GitHub repository or reach out via GitHub Issues.</p>"},{"location":"manage/upgrade/#upgrade-steps","title":"\ud83d\udee0 Upgrade Steps","text":""},{"location":"manage/upgrade/#1-backup-current-configuration-and-data","title":"1. Backup Current Configuration and Data","text":"<p>Before initiating an upgrade:</p> <ul> <li>Export Configuration: Backup your current configuration files.</li> <li>Database Backup: Create a full backup of your database to prevent data loss.</li> </ul>"},{"location":"manage/upgrade/#2-review-release-notes","title":"2. Review Release Notes","text":"<p>Check the release notes for:</p> <ul> <li>Breaking Changes: Identify any changes that might affect your current setup.</li> <li>Migration Scripts: Look for any provided scripts or instructions for database migrations.</li> </ul>"},{"location":"manage/upgrade/#3-update-mcp-gateway","title":"3. Update MCP Gateway","text":"<p>Depending on your deployment method: podman, docker, kubernetes, etc.</p>"},{"location":"manage/upgrade/#4-apply-database-migrations","title":"4. Apply Database Migrations","text":"<p>If the new version includes database schema changes:</p> <ul> <li>Migration Scripts: Execute any provided migration scripts.</li> <li>Manual Migrations: If no scripts are provided, consult the release notes for manual migration instructions.</li> </ul>"},{"location":"manage/upgrade/#5-verify-the-upgrade","title":"5. Verify the Upgrade","text":"<p>Post-upgrade, ensure:</p> <ul> <li>Service Availability: MCP Gateway is running and accessible.</li> <li>Functionality: All features and integrations are working as expected.</li> <li>Logs: Check logs for any errors or warnings.</li> </ul>"},{"location":"manage/upgrade/#testing-and-validation","title":"\ud83e\uddea Testing and Validation","text":"<ul> <li>Staging Environment: Test the upgrade process in a staging environment before applying to production.</li> <li>Automated Tests: Run your test suite to catch any regressions.</li> <li>User Acceptance Testing (UAT): Engage end-users to validate critical workflows.</li> </ul>"},{"location":"manage/upgrade/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>MCP Gateway GitHub Repository</li> <li>MCP Gateway Documentation</li> </ul>"},{"location":"media/","title":"Media","text":"<p>This section collects press coverage, social-media highlights, customer testimonials, and a ready-to-use media kit:</p> <ul> <li>Press Coverage</li> <li>Social Highlights</li> <li>Testimonials</li> <li>Media Kit</li> </ul>"},{"location":"media/#other-catalogs","title":"Other catalogs:","text":"<ul> <li>https://mcp.so/server/mcp-context-forge/IBM</li> </ul>"},{"location":"media/kit/","title":"\ud83e\uddf0 Media Kit","text":"<p>Everything you need to write about ContextForge MCP Gateway-assets, ready-to-use copy, badges, images, and quick-start commands.</p>"},{"location":"media/kit/#what-is-mcp-model-context-protocol","title":"\ud83e\udd14 What is MCP (Model Context Protocol)?","text":"<p>MCP is an open-source protocol released by Anthropic in November 2024 that lets AI agents communicate with external tools through a standard JSON-RPC envelope. It's often described as the \"USB-C of AI\"-a universal connector for language models.</p> <p>It's widely supported by GitHub Copilot, Microsoft Copilot, AWS Bedrock, Google Cloud AI, IBM watsonx, and 15,000+ servers in the community.</p>"},{"location":"media/kit/#why-it-matters","title":"\u26a1 Why it matters","text":"<ul> <li>\u2705 Standardized interface contracts via typed JSON Schema</li> <li>\u2705 Supported across the ecosystem - GitHub/Microsoft Copilot, AWS Bedrock, Google Cloud AI, IBM watsonx, AgentBee, LangChain, CrewAI, and more</li> <li>\u2705 Strong ecosystem - 15,000+ MCP-compatible servers and multiple clients, with announcements from multiple major vendors</li> </ul>"},{"location":"media/kit/#current-challenges","title":"\u274c Current challenges","text":"<ul> <li>\u274c Fragmented transports: STDIO, SSE, HTTP - with some methods already deprecated</li> <li>\u274c Inconsistent authentication: none, JWT, OAuth</li> <li>\u274c Operational overhead: managing endpoints, credentials, retries, and logs for each tool</li> <li>\u274c Version mismatch: clients and servers may support different MCP versions</li> </ul>"},{"location":"media/kit/#why-contextforge-mcp-gateway","title":"\ud83d\udca1 Why ContextForge MCP Gateway?","text":"<p>Problem: Most teams build one-off adapters for each tool or model, leading to maintenance burden and slow development.</p> <p>ContextForge MCP Gateway solves this by proxying all MCP and REST tool servers through a single HTTPS + JSON-RPC endpoint, with discovery, security, and observability built in.</p> <p>It lets you create Virtual Servers - remixing tools/prompts/resources from multiple servers, introduce strong Auth - and change protocol versions on the fly. It lets you easily create new MCP Servers without having to write any code - by proxing existing REST services.</p> <p>And is readily available as open source, published a container image and as a Python module published on PyPi - so you can get started with a single command - and scale all the way up to multi-regional Kubernetes clusters.</p> Pain Point How Gateway Solves It Transport fragmentation (STDIO/SSE/HTTP) Unifies everything under HTTPS + JSON-RPC DIY wrappers &amp; retry logic Automatic, schema-validated retry handling Weak auth layers Built-in JWT (or OAuth) &amp; rate limiting No visibility Per-call and per-server metrics &amp; logging Onboarding difficulties Built-in admin UI for tools, prompts, and resources <p></p>"},{"location":"media/kit/#sample-announcements","title":"\ud83d\udcd1 Sample Announcements","text":"\ud83d\udce3 Non-Technical Post \ud83d\udee0\ufe0f Technical Post \ud83d\udee0\ufe0f Connect Cline VS Code Extension to ContextForge MCP Gateway <p>A great idea is to create posts, videos or articles on using specific clients or with MCP Gateway. Provide details on how to run and register a number of useful MCP Servers, adding them to the gateway, then using specific clients to connect. For example, Visual Studio Cline, GitHub Copilot, Langchain, etc. Example:</p>"},{"location":"media/kit/#meet-contextforge-mcp-gateway-simplify-ai-tool-connections","title":"Meet ContextForge MCP Gateway: Simplify AI Tool Connections","text":"<p>Building AI agents should be easy-but each tool speaks a different dialect.</p> <p>ContextForge MCP Gateway is a universal hub: one secure endpoint that discovers your tools and works seamlessly with Copilot, CrewAI, LangChain, and more.</p> <p>\"What should be simple often becomes a debugging nightmare. The ContextForge MCP Gateway solves that.\" - Mihai Criveti</p> <p>Try it in 60 seconds: <pre><code>docker run -d --name mcpgateway \\\n  -p 4444:4444 \\\n  -e JWT_SECRET_KEY=YOUR_KEY \\\n  ghcr.io/ibm/mcp-context-forge:latest\n</code></pre></p> <p>Please \u2b50 the project on GitHub if you find this useful, it helps us grow!</p>"},{"location":"media/kit/#introducing-contextforge-mcp-gateway-the-missing-proxy-for-ai-agents-and-tools","title":"Introducing ContextForge MCP Gateway: The Missing Proxy for AI Agents and Tools","text":"<p>ContextForge MCP Gateway normalizes STDIO, SSE, REST, and HTTP MCP servers into one HTTPS + JSON-RPC interface with full MCP support.</p> <p>It includes schema-validated retries, JWT auth, and a built-in catalog UI.</p> <p>Docker: <pre><code>docker run -d --name mcpgateway \\\n  -p 4444:4444 \\\n  -e JWT_SECRET_KEY=YOUR_KEY \\\n  ghcr.io/ibm/mcp-context-forge:latest\n</code></pre></p> <p>PyPI: <pre><code>pip install mcp-gateway\nmcpgateway --host 0.0.0.0 --port 4444\n</code></pre></p> <p>Please \u2b50 the project on GitHub if you find this useful, it helps us grow!</p>"},{"location":"media/kit/#connect-your-cline-extension-to-mcp-gateway","title":"Connect your Cline extension to MCP Gateway","text":"<p>ContextForge MCP Gateway offers a unified HTTPS + JSON-RPC endpoint for AI tools, making integration seamless-including with Cline, a VS Code extension that supports MCP.</p> <p>Start the Gateway (Docker): <pre><code>docker run -d --name mcpgateway \\\n  -p 4444:4444 \\\n  -e JWT_SECRET_KEY=YOUR_KEY \\\n  ghcr.io/ibm/mcp-context-forge:latest\n</code></pre></p> <p>Or install via PyPI:</p> <pre><code>pip install mcp-gateway\nmcpgateway --host 0.0.0.0 --port 4444\n</code></pre> <p>\u2b50 Enjoying this? Leave a star on GitHub!</p>"},{"location":"media/kit/#what-is-cline","title":"\ud83d\udd0d What is Cline?","text":"<p>Cline is a powerful AI coding assistant for VS Code. It supports MCP, allowing it to discover and use tools provided through MCP Gateway.</p>"},{"location":"media/kit/#set-up-jwt-authentication","title":"\ud83d\udd10 Set up JWT Authentication","text":"<p>In your Cline settings, add an MCP server:</p> <pre><code>{\n  \"name\": \"MCP Gateway\",\n  \"url\": \"http://localhost:4444\",\n  \"auth\": {\n    \"type\": \"bearer\",\n    \"token\": \"&lt;YOUR_JWT_TOKEN&gt;\"\n  }\n}\n</code></pre> <p>Enable the server in Cline-you should see a green \"connected\" indicator when authentication succeeds.</p>"},{"location":"media/kit/#using-mcp-tools-in-cline","title":"\ud83d\ude80 Using MCP Tools in Cline","text":"<p>With the connection live, Cline can:</p> <ul> <li>Automatically list tools exposed by the Gateway</li> <li>Use simple prompts to invoke tools, e.g.:</li> </ul> <p><pre><code>Run the `list_files` tool with path: \"./src\"\n</code></pre> * Display results and JSON output directly within the VS Code interface</p> <p>Try it yourself-and don't forget to \u2b50 the project at ContextForge MCP Gateway!</p>"},{"location":"media/kit/#logo-images","title":"\ud83d\uddbc\ufe0f Logo &amp; Images","text":"Asset URL Transparent PNG logo <code>https://ibm.github.io/mcp-context-forge/logo.png</code> Hero demo GIF <code>https://ibm.github.io/mcp-context-forge/images/mcpgateway.gif</code> Architecture overview SVG"},{"location":"media/kit/#social-snippets","title":"\ud83d\udce3 Social Snippets","text":"<p>Tweet / X</p> <p>Twitter / X</p> <p>\ud83d\ude80 ContextForge MCP Gateway is now open source! One endpoint to unify &amp; secure AI-tool connections (STDIO, SSE, REST). Give it a spin and drop a \u2b50 \u2192 IBM/mcp-context-forge #mcp #ai #tools</p> <p>LinkedIn</p> <p>Example</p> <p>Thrilled to share ContextForge MCP Gateway-an open-source hub that turns fragmented AI-tool integrations into a single secure interface with discovery, observability, and a live catalog UI. Check it out on GitHub and leave us a star \u2b50! <code>#mcp #ai #tools</code></p> <p>Tip</p> <p>See Social for example articles and social media posts - and add your own there once published!</p>"},{"location":"media/press/","title":"Press Highlights","text":"<p>Coverage from industry publications, press, and news media about MCP Gateway, ACP, and IBM's agentic AI initiatives.</p>"},{"location":"media/press/#articles","title":"Articles","text":"<p>Watsonx.ai Agent to MCP Gateway (ruslanmv.com)</p> <p>Author: Ruslan Magana Vsevolodovna | Publication: ruslanmv.com | Date: July 4, 2025 Read the article</p> <p>Quote</p> <p>This detailed, end-to-end tutorial provides a practical blueprint for developers. It walks through the entire process of building a watsonx.ai-powered agent, registering it with the MCP Gateway using SSE, and connecting it to a custom FastAPI frontend. The post serves as a hands-on guide for creating fully-functional, multi-component AI applications.</p> <p>Getting Started with ContextForge MCP Gateway on macOS (aiarchplaybook.substack.com)</p> <p>Author: Shaikh Quader | Publication: AI Architect's Playbook | Date: June 26, 2025 Read the article</p> <p>Quote</p> <p>ContextForge MCP Gateway is an open-source IBM middleware that connects AI agents to multiple MCP servers through a single endpoint with centralized login and built-in observability.</p> <p>IBM's MCP Gateway: A Unified FastAPI-Based Model Context Protocol Gateway for Next-Gen AI Toolchains (MarkTechPost)</p> <p>Author: Nikhil | Publication: MarkTechPost | Date: June 21, 2025 Read the article</p> <p>Quote</p> <p>IBM's MCP Gateway offers a robust orchestration layer for agentic and GenAI applications, enabling API wrapping, multi-protocol support, centralized schema management, and real-time observability through a modern admin UI. It serves as a scalable foundation for unifying diverse AI tools and resources under the Model Context Protocol.</p> <p>IBM MCP Gateway: Revolutionizing GenAI Integration for Startups and Enterprises (Pitangent)</p> <p>Author: Miltan Chaudhury | Publication: Pitangent | Date: June 11, 2025 Read the article</p> <p>Quote</p> <p>\"IBM's MCP Gateway is more than a bridge-it's a platform for accelerating GenAI transformation with agility and confidence. For startups and enterprises navigating the complex AI tool landscape, this innovation brings a modular, future-proof path to build smarter, scalable, and context-aware applications.\"</p> <p>The article breaks down the technical benefits of the MCP Gateway and positions it as a game-changer for reducing integration overhead, improving developer productivity, and democratizing AI access for early-stage companies.</p> <p>IBM Introduces MCP Gateway to Simplify GenAI Tool Integration (Analytics India Magazine)</p> <p>Author: Ankush Das | Publication: Analytics India Magazine | Date: June 10, 2025 Read the article</p> <p>Quote</p> <p>\"IBM has launched MCP Gateway, a FastAPI-based component designed to streamline the integration and orchestration of generative AI tools and services. It is an open-source project made available under the Apache 2.0 license\u2026 Armand Ruiz, VP of AI Platform at IBM, stated on LinkedIn, 'I think this is a great step forward for those building agentic systems, orchestrating tools, or deploying complex GenAI apps.'\"</p> <p>The article also notes IBM's draft Agent Communication Protocol (ACP) as a complementary innovation to MCP, aimed at enabling standardized AI agent interaction as part of the BeeAI initiative.</p> <p>IBM Launches MCP Gateway to Merge and Manage AI Tools (Geekflare)</p> <p>Author: Keval Vachharajani | Publication: Geekflare | Date: June 10, 2025 Read the article</p> <p>Quote</p> <p>\"Built on FastAPI, the MCP Gateway is designed to act as a unified entry point for the Model Context Protocol (MCP)\u2026 According to Ruiz, this launch is particularly relevant for teams working on agent-based systems or orchestrating multiple AI tools within enterprise environments.\"</p> <p>The article highlights MCP Gateway's support for JSON-Schema validation, transport layer management, and its production-ready admin UI. It also mentions IBM Consulting's influence in shaping the tool and situates the launch within IBM's broader innovation efforts, including the new Watsonx AI Labs.</p>"},{"location":"media/social/","title":"Social Highlights","text":"<p>Check out these social media highlights, and write your own!</p>"},{"location":"media/social/#linkedin-posts","title":"LinkedIn Posts:","text":"<p>MCP Context Forge Collaboration &amp; Open-Source Release (LinkedIn)</p> <p>Manav Gupta - Vice President &amp; CTO, IBM Canada @ IBM | June 24, 2025</p> <p>\"I have been lucky to collaborate and contribute to mcp-context-forge. It serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP). I think this will be way to build AI Agents of the future.\"</p> <p>IBM's Armand Ruiz on MCP Gateway &amp; ACP (LinkedIn)</p> <p>Author: Analytics India Magazine | Date: June 10, 2025 View on LinkedIn</p> <p>Quote</p> <p>\"Armand Ruiz, IBM's VP of AI Platform, hails the open-source MCP Gateway as 'a great step forward for those building agentic systems, orchestrating tools, or deploying complex GenAI apps.' \u2026 With MCP Gateway streamlining tool orchestration and ACP redefining agent interactions, IBM is pushing to standardize AI infrastructure. As Ruiz emphasizes, this dual approach reduces deployment friction, empowering developers to scale GenAI applications efficiently.\"</p> <p>MCP Gateway Overview Post (LinkedIn)</p> <p>Author: Armand Ruiz - VP of AI Platform @ IBM | Date: June 9, 2025 View on LinkedIn</p> <p>Quote</p> <p>\"Introducing MCP Gateway, a powerful, FastAPI-based gateway for the Model Context Protocol, designed to unify and scale your AI toolchain\u2026 It does a lot\u2026 I think this is a great step forward for those building agentic systems, orchestrating tools, or deploying complex GenAI apps.\"</p> <p>MCP Gateway Launch Announcement (LinkedIn)</p> <p>Author: Mihai Criveti - Distinguished Engineer, Agentic AI @ IBM | Date: June 5, 2025 View on LinkedIn</p> <p>Quote</p> <p>\"Just open-sourced something I've been building - the MCP Gateway: turn any REST API into an MCP server, connect multiple MCP servers, combine tools into virtual servers, swap them on the fly, and adds observability and security - all in one container that can be deployed anywhere.\"</p>"},{"location":"media/social/#articles","title":"Articles","text":"<p>MCP Gateway: The Missing Proxy for AI Tools (Medium)</p> <p>Author: Mihai Criveti - Distinguished Engineer, Agentic AI @ IBM | Date: June 8, 2025 | 6 min read Read on Medium</p> <p>Quote</p> <p>\"AI agents and tool integration are exciting - until you actually try to connect them. Different authentication systems (or none), fragmented documentation, and incompatible protocols quickly turn what should be simple integrations into debugging nightmares. MCP Gateway solves this.\"</p> <p>Model Context Protocol (MCP) Gateway - a middleware meant to productionize MCP for an enterprise</p> <p>Author: Manoj Jahgirdar - AI Engineer, Agentic AI @ IBM | Date: June 13, 2025 | 6 min read Read on Medium</p> <p>Quote</p> <p>\"Learn how ContextForge MCP Gateway works - a secure, unified middleware for scaling agentic AI integrations in the enterprise.\"</p>"},{"location":"media/testimonials/","title":"Testimonials","text":""},{"location":"media/testimonials/#platforms","title":"Platforms","text":"<ul> <li>IBM Consulting Advantage IBM Consulting Advantage - AI-tooling platform, equipping 160,000 expert consultants with role, industry and business domain-specific AI assistants, agents, and applications.</li> </ul>"},{"location":"overview/","title":"Overview","text":"<p>Welcome to the MCP Gateway documentation.</p> <p>This section introduces what the Gateway is, how it fits into the MCP ecosystem, and what core features and capabilities it offers out of the box.</p>"},{"location":"overview/#what-is-mcp-gateway","title":"What is MCP Gateway?","text":"<p>MCP Gateway is an orchestration and federation layer for the Model Context Protocol (MCP). It provides:</p> <ul> <li>A unified entrypoint for tools, resources, prompts, and agents</li> <li>Federation of multiple MCP servers into one composable catalog</li> <li>Protocol enforcement, health monitoring, and registry centralization</li> <li>A visual Admin UI to manage everything in real time</li> <li>Comprehensive doctest coverage ensuring all code examples are tested and verified</li> </ul> <p>Whether you're integrating REST APIs, local functions, or full LLM agents, MCP Gateway standardizes access and transport - over HTTP, WebSockets, SSE, StreamableHttp or stdio.</p>"},{"location":"overview/#whats-in-this-section","title":"What's in This Section","text":"Page Description Features Breakdown of supported features including federation, transports, and tool wrapping Admin UI Screenshots and explanation of the interactive web dashboard Quick Start Quick Installation and Start up"},{"location":"overview/features/","title":"\u2728 Features Overview","text":"<p>MCP Gateway is a gateway + registry + proxy purpose-built for the Model Context Protocol (MCP). It unifies REST, MCP, and stdio worlds while adding auth, caching, federation, and an HTMX-powered Admin UI.</p>"},{"location":"overview/features/#multi-transport-core","title":"\ud83c\udf10 Multi-Transport Core","text":"Supported Transports Transport Description Typical Use-case HTTP / JSON-RPC Low-latency request-response, default for most REST clients Simple tool invocations WebSocket Bi-directional, full-duplex Streaming chat or incremental tool results Server-Sent Events (SSE) Uni-directional server \u2192 client stream LLM completions or real-time updates STDIO Local process pipes via <code>mcpgateway-wrapper</code> Editor plugins, headless CLI clients Try it: SSE from curl <pre><code>curl -N -H \"Accept: text/event-stream\" \\\n     -H \"Authorization: Bearer $TOKEN\" \\\n     http://localhost:4444/servers/UUID_OF_SERVER_1/sse\n</code></pre>"},{"location":"overview/features/#federation-discovery","title":"\ud83c\udf0d Federation &amp; Discovery","text":"Features <ul> <li>Auto-discovery - DNS-SD (<code>_mcp._tcp.local.</code>) or static peer list</li> <li>Health checks - fail-over + removal of unhealthy gateways</li> <li>Capability sync - merges remote tool catalogs into the local DB</li> <li>Request forwarding - automatic routing to the correct gateway</li> </ul> Architecture <pre><code>graph TD\n  subgraph Local_Gateway\n    A[MCP Gateway Core]\n  end\n  subgraph Remote_Gateway_1\n    B[Peer 1]\n  end\n  subgraph Remote_Gateway_2\n    C[Peer 2]\n  end\n  A &lt;-- ping / register --&gt; B\n  A &lt;-- ping / register --&gt; C</code></pre> Configuration <p>Enable or tweak discovery via <code>.env</code>:</p> <pre><code>FEDERATION_ENABLED=true\nFEDERATION_DISCOVERY=true\nFEDERATION_PEERS=https://remote.example.com\nHEALTH_CHECK_INTERVAL=30\n</code></pre>"},{"location":"overview/features/#security","title":"\ud83d\udd10 Security","text":"Auth mechanisms <ul> <li>JWT bearer (default, signed with <code>JWT_SECRET_KEY</code>)</li> <li>HTTP Basic for the Admin UI</li> <li>Custom headers (e.g., API keys) per tool or gateway</li> </ul> Rate limiting <p>Set <code>MAX_TOOL_CALLS_PER_MINUTE</code> to throttle abusive clients. Exceeding the limit returns HTTP 429 with a <code>Retry-After</code> header.</p> Generate a 24 h token <pre><code>python3 -m mcpgateway.utils.create_jwt_token \\\n  --username alice --exp 1440 --secret \"$JWT_SECRET_KEY\"\n</code></pre>"},{"location":"overview/features/#tool-server-registry","title":"\ud83d\udee0 Tool &amp; Server Registry","text":"What you can register Registry Entities Notes Tools Native MCP tools or wrapped REST / CLI functions JSON Schema input validation Resources URIs for blobs, text, images Optional SSE change notifications Prompts Jinja2 templates + multimodal content Versioning &amp; rollback Servers Virtual collections of tools/prompts/resources Exposed as full MCP servers REST tool example <pre><code>curl -X POST -H \"Authorization: Bearer $TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n           \"name\": \"joke_api\",\n           \"url\": \"https://icanhazdadjoke.com/\",\n           \"requestType\": \"GET\",\n           \"integrationType\": \"REST\",\n           \"headers\": {\"Accept\":\"application/json\"}\n         }' \\\n     http://localhost:4444/tools\n</code></pre>"},{"location":"overview/features/#admin-ui","title":"\ud83d\udda5 Admin UI","text":"Built with <ul> <li>FastAPI + Jinja2 + HTMX + Alpine.js</li> <li>Tailwind CSS for styling</li> </ul>"},{"location":"overview/features/#persistence-caching-observability","title":"\ud83d\uddc4 Persistence, Caching &amp; Observability","text":"Storage options <ul> <li>SQLite (default dev)</li> <li>PostgreSQL, MySQL/MariaDB, MongoDB - via <code>DATABASE_URL</code></li> </ul> Redis cache <pre><code>CACHE_TYPE=redis\nREDIS_URL=redis://localhost:6379/0\n</code></pre> Observability <ul> <li>Structured JSON logs (tap with <code>jq</code>)</li> <li><code>/metrics</code> - Prometheus-friendly counters (<code>tool_calls_total</code>, <code>gateway_up</code>)</li> <li><code>/health</code> - readiness + dependency checks</li> </ul>"},{"location":"overview/features/#dev-extensibility","title":"\ud83e\udde9 Dev &amp; Extensibility","text":"Highlights <ul> <li>Makefile targets - <code>make dev</code>, <code>make test</code>, <code>make lint</code></li> <li>400+ unit tests - Pytest + HTTPX TestClient</li> <li>VS Code Dev Container - Python 3.11 + Docker/Podman CLI</li> <li>Plug-in friendly - drop-in FastAPI routers or Pydantic models</li> </ul>"},{"location":"overview/features/#next-steps","title":"Next Steps","text":"<ul> <li>Hands-on Walk-through \u2192 Quick Start</li> <li>Deployment Guides \u2192 Compose, K8s &amp; Cloud</li> <li>Admin UI deep dive \u2192 UI Guide</li> </ul> <p>Ready to explore</p> <p>With transports, federation, and security handled for you, focus on building great MCP tools, prompts, and agents-the gateway has your back.</p>"},{"location":"overview/quick_start/","title":"\ud83d\ude80 Quick Start","text":"<p>MCP Gateway can be running on your laptop or server in &lt; 5 minutes. Pick an install method below, generate an auth token, then walk through a real tool + server demo.</p>"},{"location":"overview/quick_start/#installing-and-starting-mcp-gateway","title":"Installing and starting MCP Gateway","text":"PyPI / virtual-envDocker / PodmanDocker Compose"},{"location":"overview/quick_start/#local-install-via-pypi","title":"Local install via PyPI","text":"<p>Note</p> <p>Prereqs: Python \u2265 3.10, plus <code>curl</code> &amp; <code>jq</code> for the smoke test.</p> <ol> <li> <p>Create an isolated environment and upgrade pip if required</p> <pre><code>mkdir mcpgateway &amp;&amp; cd mcpgateway\npython3 -m venv .venv &amp;&amp; source .venv/bin/activate\npython3 -m pip install --upgrade pip\n</code></pre> </li> <li> <p>Install the gateway from pypi</p> <pre><code>pip install mcp-contextforge-gateway\nmcpgateway --version\n</code></pre> </li> <li> <p>Launch it, listening on all interfaces</p> <pre><code>export BASIC_AUTH_PASSWORD=changeme\nexport JWT_SECRET_KEY=my-test-key\nmcpgateway --host 0.0.0.0 --port 4444\n</code></pre> <p>The terminal shows startup logs; keep it running.</p> </li> <li> <p>Generate a bearer token with an expiration time of 10080 seconds (1 week)</p> <pre><code>export MCP_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token \\\n    --username admin --exp 10080 --secret my-test-key)\n</code></pre> <p>Use <code>--exp 0</code> for tokens that don't expire</p> </li> <li> <p>Smoke-test health + version</p> <pre><code>curl -s http://localhost:4444/health | jq\ncurl -s -H \"Authorization: Bearer $MCP_BEARER_TOKEN\" http://localhost:4444/version | jq\n</code></pre> </li> </ol>"},{"location":"overview/quick_start/#dockerpodman-container-install","title":"Docker/Podman Container install","text":"<p>Note</p> <p>Substitute <code>docker</code> with <code>podman</code> if preferred.</p> <ol> <li> <p>Run the image</p> <pre><code>docker run -d --name mcpgateway \\\n  -p 4444:4444 \\\n  -e HOST=0.0.0.0 \\\n  -e JWT_SECRET_KEY=my-test-key \\\n  -e BASIC_AUTH_USER=admin \\\n  -e BASIC_AUTH_PASSWORD=changeme \\\n  ghcr.io/ibm/mcp-context-forge:0.3.0\n</code></pre> </li> <li> <p>(Optional) persist the DB</p> <pre><code>mkdir -p $(pwd)/data\ndocker run -d --name mcpgateway \\\n  -p 4444:4444 \\\n  -v $(pwd)/data:/data \\\n  -e DATABASE_URL=sqlite:////data/mcp.db \\\n  -e JWT_SECRET_KEY=my-test-key \\\n  -e BASIC_AUTH_USER=admin \\\n  -e BASIC_AUTH_PASSWORD=changeme \\\n  ghcr.io/ibm/mcp-context-forge:0.3.0\n</code></pre> </li> <li> <p>Generate a token inside the container</p> <pre><code>docker exec mcpgateway python3 -m mcpgateway.utils.create_jwt_token \\\n  --username admin --exp 10080 --secret my-test-key\n</code></pre> </li> <li> <p>Smoke-test</p> <pre><code>export MCP_BEARER_TOKEN=&lt;paste_from_previous_step&gt;\ncurl -s http://localhost:4444/health | jq\ncurl -s -H \"Authorization: Bearer $MCP_BEARER_TOKEN\" http://localhost:4444/version | jq\n</code></pre> </li> </ol>"},{"location":"overview/quick_start/#run-the-full-stack-with-compose","title":"Run the full stack with Compose","text":"<p>Typical Compose file includes Gateway + Postgres + Redis and optional PgAdmin / Redis Commander. See the complete sample and advanced scenarios in Deployment \u203a Compose.</p> <ol> <li> <p>Install Compose v2 (if needed)</p> <pre><code># Ubuntu example\nsudo apt install docker-buildx docker-compose-v2\n# Tell the Makefile / docs which command to use\nexport COMPOSE_CMD=\"docker compose\"\n</code></pre> </li> <li> <p>Pull the published image</p> <pre><code>docker pull ghcr.io/ibm/mcp-context-forge:0.3.0\n</code></pre> </li> <li> <p>Start the stack</p> <pre><code># Uses podman or docker automatically\nmake compose-up\n# -or- raw CLI\ndocker compose -f podman-compose.yml up -d\n</code></pre> </li> <li> <p>Verify</p> <pre><code>curl -s http://localhost:4444/health | jq\n</code></pre> </li> </ol> <p>Tip : The sample Compose file has multiple database blocks (Postgres, MariaDB, MySQL, MongoDB) and admin tools. Uncomment one and align <code>DATABASE_URL</code> for your preferred backend.</p>"},{"location":"overview/quick_start/#registering-mcp-tools-creating-a-virtual-server","title":"Registering MCP tools &amp; creating a virtual server","text":"<pre><code># Spin up a sample MCP time server (SSE, port 8002)\npip install uv\nnpx -y supergateway --stdio \"uvx mcp_server_time -- --local-timezone=Europe/Dublin\" --port 8002 &amp;\n</code></pre> <pre><code># Register that server with your gateway\ncurl -s -X POST -H \"Authorization: Bearer $MCP_BEARER_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"name\":\"local_time\",\"url\":\"http://localhost:8002/sse\"}' \\\n     http://localhost:4444/gateways | jq\n</code></pre> <pre><code># Bundle the imported tool(s) into a virtual MCP server\ncurl -s -X POST -H \"Authorization: Bearer $MCP_BEARER_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"name\":\"demo_server\",\"description\":\"Time tools\",\"associatedTools\":[\"1\"]}' \\\n     http://localhost:4444/servers | jq\n</code></pre> <pre><code># Verify catalog entries\ncurl -s -H \"Authorization: Bearer $MCP_BEARER_TOKEN\" http://localhost:4444/tools   | jq\ncurl -s -H \"Authorization: Bearer $MCP_BEARER_TOKEN\" http://localhost:4444/servers | jq\n</code></pre> <pre><code># Optional: Connect interactively via MCP Inspector\nnpx -y @modelcontextprotocol/inspector\n# Transport SSE \u2192 URL http://localhost:4444/servers/UUID_OF_SERVER_1/sse\n# Header Authorization \u2192 Bearer $MCP_BEARER_TOKEN\n</code></pre>"},{"location":"overview/quick_start/#connect-via-mcpgateway-wrapper-stdio","title":"Connect via <code>mcpgateway-wrapper</code> (stdio)","text":"<pre><code>export MCP_AUTH_TOKEN=$MCP_BEARER_TOKEN\nexport MCP_SERVER_CATALOG_URLS=http://localhost:4444/servers/UUID_OF_SERVER_1\npython3 -m mcpgateway.wrapper   # behaves as a local MCP stdio server - run from MCP client\n</code></pre> <p>Use this in GUI clients (Claude Desktop, Continue, etc.) that prefer stdio. Example:</p> <pre><code>{\n  \"mcpServers\": {\n    \"mcpgateway-wrapper\": {\n      \"command\": \"python3\",\n      \"args\": [\"-m\", \"mcpgateway.wrapper\"],\n      \"env\": {\n        \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444/servers/UUID_OF_SERVER_1\",\n        \"MCP_AUTH_TOKEN\": \"&lt;YOUR_JWT_TOKEN&gt;\",\n        \"MCP_TOOL_CALL_TIMEOUT\": \"120\"\n      }\n    }\n  }\n}\n</code></pre> <p>For more information see MCP Clients</p>"},{"location":"overview/quick_start/#4-useful-urls","title":"4 - Useful URLs","text":"URL Description <code>http://localhost:4444/admin</code> Admin UI (Basic Auth: <code>admin</code> / <code>changeme</code>) <code>http://localhost:4444/tools</code> Tool registry (GET) <code>http://localhost:4444/servers</code> Virtual servers (GET) <code>/servers/&lt;id&gt;/sse</code> SSE endpoint for that server <code>/docs</code>, <code>/redoc</code> Swagger / ReDoc (JWT-protected)"},{"location":"overview/quick_start/#5-next-steps","title":"5 - Next Steps","text":"<ul> <li>Features Overview - deep dive on transports, federation, caching</li> <li>Admin UI Guide</li> <li>Deployment to K8s / AWS / GCP / Azure</li> <li>Wrap any client via <code>mcpgateway-wrapper</code></li> <li>Tweak <code>.env</code> - see example</li> </ul> <p>Gateway is ready!</p> <p>You now have an authenticated MCP Gateway proxying a live tool, exposed via SSE and stdio. Jump into the Admin UI or start wiring it into your agents and clients!</p>"},{"location":"overview/ui-concepts/","title":"Admin Console Concepts","text":"<p>This guide introduces each major section of the Gateway Admin UI and how it connects to the Model Context Protocol (MCP).</p>"},{"location":"overview/ui-concepts/#setting-up-a-new-mcp-server-to-federate-to-the-gateway","title":"\ud83c\udd95 Setting up a new MCP Server to federate to the gateway","text":"\ud83d\udd0c How do I expose an MCP server over SSE? <p>To federate a new MCP Server to your gateway, it must run over Server-Sent Events (SSE) so the gateway can communicate with it.</p> <p>You can use <code>supergateway</code> to wrap any <code>stdio</code>-only MCP server and expose it over SSE. Here are example commands:</p> <pre><code>npx -y supergateway --stdio \"uvx mcp-server-git\" --port 8001\nnpx -y supergateway --stdio \"uvx mcp_server_time -- --local-timezone=Europe/Dublin\"\n</code></pre> <p>\u2705 Important: The gateway must be able to reach the MCP server's network address.</p> <p>If you're running services inside Docker (or other containerized environments), ensure networking is configured properly: - Use <code>host</code> networking when needed. - Expose ports to the host machine. - Make sure internal container IPs are reachable from the gateway.</p>"},{"location":"overview/ui-concepts/#virtual-servers","title":"\ud83d\udce6 Virtual Servers","text":"<p>A virtual server is a logical wrapper that combines selected tools, resources, and prompts under one context-specific endpoint.</p> \ud83d\udd17 What are Virtual Servers? <ul> <li>A Virtual Server defines a project-specific toolset.</li> <li>Each one is backed by a real SSE or STDIO interface.</li> <li>You can activate/deactivate, view metrics, and invoke tools from this server.</li> </ul>"},{"location":"overview/ui-concepts/#global-tools","title":"\ud83d\udee0 Global Tools","text":"<p>Tools are remote functions that an LLM can invoke, either via MCP or REST. Think of them like typed APIs with schemas and optional auth.</p> \u2699\ufe0f What do Tools represent? <ul> <li>Integration Types: <code>MCP</code>, <code>REST</code></li> <li>Request Types: <code>STDIO</code>, <code>SSE</code>, <code>GET</code>, <code>POST</code>, etc.</li> <li>Input Schema: JSON Schema defines valid input.</li> <li>Supports Basic Auth, Bearer, or Custom headers.</li> </ul>"},{"location":"overview/ui-concepts/#global-resources","title":"\ud83d\udcc1 Global Resources","text":"<p>Resources expose read-only data like files, database rows, logs, or screenshots. LLMs can read this content through a URI.</p> \ud83d\udcd6 How do Resources work? <ul> <li>Text and Binary data supported.</li> <li>Exposed via unique URI (<code>file:///</code>, <code>db://</code>, etc.).</li> <li>Resources can be listed, templated, or subscribed to.</li> </ul>"},{"location":"overview/ui-concepts/#global-prompts","title":"\ud83e\uddfe Global Prompts","text":"<p>Prompts are reusable message templates with arguments. They define system prompts, user instructions, or chainable inputs.</p> \ud83d\uddd2 What's in a Prompt? <ul> <li>Each prompt has a name, template, and arguments.</li> <li>Arguments are defined with name, description, and required status.</li> <li>Used to enforce consistency across tool use or system messaging.</li> </ul>"},{"location":"overview/ui-concepts/#gateways-mcp-servers","title":"\ud83c\udf10 Gateways (MCP Servers)","text":"<p>Gateways are other MCP-compatible servers. When registered, their tools/resources/prompts become usable locally.</p> \ud83c\udf09 What is a federated Gateway? <ul> <li>Syncs public tools from a remote MCP server.</li> <li>Peer tools show up in your catalog with <code>gateway_id</code>.</li> <li>Can be toggled active/inactive.</li> </ul>"},{"location":"overview/ui-concepts/#roots","title":"\ud83d\udcc2 Roots","text":"<p>Roots define base folders for file-based resources. They control what files MCP clients can access from your local system.</p> \ud83d\udcc1 What are Roots used for? <ul> <li>Restrict access to specific folders (<code>file:///workspace</code>)</li> <li>Prevent tools from referencing outside their sandbox.</li> <li>Deleting a root invalidates its associated resources.</li> </ul>"},{"location":"overview/ui-concepts/#metrics","title":"\ud83d\udcc8 Metrics","text":"<p>Track tool calls, resource reads, prompt renders, and overall usage in one place.</p> \ud83d\udcca What does the Metrics tab show? <ul> <li>Overall executions by server/tool/prompt.</li> <li>Latency, failure rate, and hot paths.</li> <li>Top tools, resources, prompts, and servers.</li> </ul>"},{"location":"overview/ui-concepts/#version-diagnostics","title":"\ud83e\uddea Version &amp; Diagnostics","text":"<p>The <code>/version</code> endpoint returns structured JSON diagnostics including system info, DB/Redis health, and Git SHA.</p> \ud83e\ude7a What does the Version panel include? <ul> <li>MCP protocol version and server metadata.</li> <li>Live system metrics (CPU, memory).</li> <li>Environment checks and service readiness.</li> </ul>"},{"location":"overview/ui-concepts/#learn-more","title":"\ud83d\udcda Learn More","text":"<ul> <li>\ud83d\udd17 MCP Specification</li> </ul>"},{"location":"overview/ui/","title":"Admin UI","text":"<p>MCP Gateway includes a built-in Admin UI for managing all entities in real time via a web browser.</p>"},{"location":"overview/ui/#accessing-the-ui","title":"\ud83d\udda5\ufe0f Accessing the UI","text":"<p>After launching the gateway (<code>make serve</code> or <code>make podman-run</code>), open your browser and go to:</p> <p>http://localhost:4444/admin - or the corresponding URL / port / protocol (ex: https when launching with <code>make podman-run-ssl</code>)</p> <p>Login using the <code>BASIC_AUTH_USER</code> and <code>BASIC_AUTH_PASSWORD</code> set in your <code>.env</code>.</p>"},{"location":"overview/ui/#ui-overview","title":"\ud83e\udded UI Overview","text":"<p>The Admin UI is built with HTMX, Alpine.js, and Tailwind CSS, offering a dynamic, SPA-like experience without JavaScript bloat.</p> <p>It provides tabbed access to:</p> <ul> <li>Servers Catalog: Define or edit MCP servers (real or virtual)</li> <li>Tools: Register REST or native tools, configure auth/rate limits, test responses</li> <li>Resources: Add templated or static resources, set MIME types, enable caching</li> <li>Prompts: Define Jinja2 prompt templates with argument schemas and preview rendering</li> <li>Gateways: View and manage federated peers, toggle activity status</li> <li>Roots: Register root URIs for agent or resource scoping</li> <li>Metrics: Real-time usage and performance metrics for all entities</li> </ul>"},{"location":"overview/ui/#common-actions","title":"\u270d\ufe0f Common Actions","text":"Action How Register a tool Use the Tools tab \u2192 Add Tool form View prompt output Go to Prompts \u2192 click View Toggle server activity Use the \"Activate/Deactivate\" buttons in Servers tab Delete a resource Navigate to Resources \u2192 click Delete (after confirming) <p>All actions are reflected in the live API via <code>/tools</code>, <code>/prompts</code>, etc.</p>"},{"location":"overview/ui/#auth-jwt-from-ui","title":"\ud83d\udd10 Auth + JWT from UI","text":"<p>Upon successful login, the UI automatically sets a secure JWT token as an HTTP-only cookie (<code>jwt_token</code>).</p> <p>This token is reused for all Admin API calls from within the UI.</p>"},{"location":"overview/ui/#live-reloading-dev-only","title":"\ud83d\udd04 Live Reloading (Dev Only)","text":"<p>If running in development mode (<code>DEV_MODE=true</code> or <code>make run</code>), changes to templates and routes reload automatically.</p>"},{"location":"testing/","title":"\ud83e\uddea Testing MCP Gateway","text":"<p>This section contains guides for testing your MCP Gateway deployment.</p>"},{"location":"testing/#basic-smoke-test","title":"\ud83d\udd39 Basic Smoke Test","text":"<p>Use the Basic Smoke Test to verify:</p> <ul> <li>JWT token generation and authentication</li> <li>Gateway registration</li> <li>Tool registration</li> <li>Server creation and event streaming</li> <li>Tool invocation via JSON-RPC</li> </ul> <p>This test is ideal for validating local development environments or freshly deployed test instances.</p> <p>For additional scenarios (e.g., completion APIs, multi-hop toolchains), expand the test suite as needed.</p>"},{"location":"testing/basic/","title":"MCP Gateway - Basic","text":"<p>Test script for MCP Gateway development environments. Verifies API readiness, JWT auth, Gateway/Tool/Server lifecycle, and RPC invocation.</p>"},{"location":"testing/basic/#environment-setup","title":"\ud83d\udd27 Environment Setup","text":""},{"location":"testing/basic/#0-bootstrap-env","title":"0. Bootstrap <code>.env</code>","text":"<pre><code>cp .env.example .env\n</code></pre>"},{"location":"testing/basic/#1-start-the-gateway","title":"1. Start the Gateway","text":"<pre><code>make podman podman-run-ssl\n# or\nmake venv install serve-ssl\n</code></pre> <p>Gateway will listen on:</p> <ul> <li>Admin UI \u2192 https://localhost:4444/admin</li> <li>Swagger   \u2192 https://localhost:4444/docs</li> <li>ReDoc     \u2192 https://localhost:4444/redoc</li> </ul>"},{"location":"testing/basic/#authentication","title":"\ud83d\udd11 Authentication","text":""},{"location":"testing/basic/#2-generate-and-export-tokens","title":"2. Generate and export tokens","text":""},{"location":"testing/basic/#gateway-jwt-for-local-api-access","title":"Gateway JWT (for local API access)","text":"<pre><code>export MCPGATEWAY_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token -u admin)\ncurl -s -k -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" https://localhost:4444/health\n</code></pre> <p>Expected: <code>{\"status\":\"ok\"}</code></p>"},{"location":"testing/basic/#remote-gateway-token-peer","title":"Remote gateway token (peer)","text":"<pre><code>export MY_MCP_TOKEN=\"sse-bearer-token-here...\"\n</code></pre>"},{"location":"testing/basic/#optional-local-test-server-token-github-mcp-server","title":"Optional: local test server token (GitHub MCP server)","text":"<pre><code>export LOCAL_MCP_URL=\"http://localhost:8000/sse\"\nexport LOCAL_MCP_TOOL_URL=\"http://localhost:9000/rpc\"\n</code></pre>"},{"location":"testing/basic/#3-set-convenience-variables","title":"3. Set convenience variables","text":"<pre><code>export BASE_URL=\"https://localhost:4444\"\nexport AUTH_HEADER=\"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\"\nexport JSON=\"Content-Type: application/json\"\n</code></pre>"},{"location":"testing/basic/#smoke-tests","title":"\ud83e\uddea Smoke Tests","text":""},{"location":"testing/basic/#4-ping-json-rpc-system","title":"4. Ping JSON-RPC system","text":"<pre><code>curl -s -k -X POST $BASE_URL/protocol/ping \\\n  -H \"$AUTH_HEADER\" -H \"$JSON\" \\\n  -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"ping\"}'\n</code></pre> <p>Expected:</p> <pre><code>{\"jsonrpc\":\"2.0\",\"id\":1,\"result\":{}}\n</code></pre>"},{"location":"testing/basic/#5-add-a-peer-gateway","title":"5. Add a Peer Gateway","text":"<pre><code>curl -s -k -X POST $BASE_URL/gateways \\\n  -H \"$AUTH_HEADER\" -H \"$JSON\" \\\n  -d '{\n        \"name\": \"my-mcp\",\n        \"url\": \"https://link-to-remote-mcp-server/sse\",\n        \"description\": \"My MCP Servers\",\n        \"auth_type\": \"bearer\",\n        \"auth_token\": \"'\"$MY_MCP_TOKEN\"'\"\n      }'\n</code></pre> <p>List gateways:</p> <pre><code>curl -s -k -H \"$AUTH_HEADER\" $BASE_URL/gateways\n</code></pre>"},{"location":"testing/basic/#6-add-a-tool","title":"6. Add a Tool","text":"<pre><code>curl -s -k -X POST $BASE_URL/tools \\\n  -H \"$AUTH_HEADER\" -H \"$JSON\" \\\n  -d '{\n        \"name\": \"clock_tool\",\n        \"url\": \"'\"$LOCAL_MCP_TOOL_URL\"'\",\n        \"description\": \"Returns current time\",\n        \"request_type\": \"POST\",\n        \"integration_type\": \"MCP\",\n        \"input_schema\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"timezone\": { \"type\": \"string\" }\n          }\n        }\n      }'\n</code></pre>"},{"location":"testing/basic/#7-create-a-virtual-server","title":"7. Create a Virtual Server","text":"<pre><code>curl -s -k -X POST $BASE_URL/servers/ \\\n  -H \"$AUTH_HEADER\" -H \"$JSON\" -H 'accept: application/json' \\\n  -d '{\n        \"name\": \"demo-server\",\n        \"description\": \"Smoke-test virtual server\",\n        \"icon\": \"https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png\",\n        \"associatedTools\": [\"1\"],\n        \"associatedResources\": [],\n        \"associatedPrompts\": []\n      }'\n</code></pre> <p>Expected:</p> <pre><code>{\n  \"id\": 2,\n  \"name\": \"demo-server\",\n  \"description\": \"Smoke-test virtual server\",\n  \"icon\": \"https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png\",\n  \"createdAt\": \"2025-05-28T04:28:38.554558\",\n  \"updatedAt\": \"2025-05-28T04:28:38.554564\",\n  \"isActive\": true,\n  \"associatedTools\": [\n    1\n  ],\n  \"associatedResources\": [],\n  \"associatedPrompts\": [],\n  \"metrics\": {\n    \"totalExecutions\": 0,\n    \"successfulExecutions\": 0,\n    \"failedExecutions\": 0,\n    \"failureRate\": 0,\n    \"minResponseTime\": null,\n    \"maxResponseTime\": null,\n    \"avgResponseTime\": null,\n    \"lastExecutionTime\": null\n  }\n}\n</code></pre> <p>Check:</p> <pre><code>curl -s -k -H \"$AUTH_HEADER\" $BASE_URL/servers | jq\n</code></pre>"},{"location":"testing/basic/#8-open-an-sse-stream","title":"8. Open an SSE stream","text":"<pre><code>curl -s -k -N -H \"$AUTH_HEADER\" $BASE_URL/servers/UUID_OF_SERVER_1/sse\n</code></pre> <p>Leave running - real-time events appear here.</p>"},{"location":"testing/basic/#9-invoke-the-tool-via-rpc","title":"9. Invoke the Tool via RPC","text":"<pre><code>curl -s -k -X POST $BASE_URL/rpc \\\n  -H \"$AUTH_HEADER\" -H \"$JSON\" \\\n  -d '{\n        \"jsonrpc\": \"2.0\",\n        \"id\": 99,\n        \"method\": \"get_system_time\",\n        \"params\": {\n          \"timezone\": \"Europe/Dublin\"\n        }\n      }'\n</code></pre> <p>Expected:</p> <pre><code>{\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": \"{\\n  \\\"timezone\\\": \\\"Europe/Dublin\\\",\\n  \\\"datetime\\\": \\\"2025-05-28T05:24:13+01:00\\\",\\n  \\\"is_dst\\\": true\\n}\"\n    }\n  ],\n  \"is_error\": false\n}\n</code></pre>"},{"location":"testing/basic/#10-connect-to-github-mcp-tools-via-supergateway","title":"10. Connect to GitHub MCP Tools via SuperGateway","text":"<p>You can test the Gateway against GitHub's official <code>mcp-server-git</code> tool using <code>supergateway</code>.</p> <p>Start a temporary SSE wrapper around the GitHub MCP server:</p> <pre><code>npx -y supergateway --stdio \"uvx mcp-server-git\"\n</code></pre> <p>This starts:</p> <ul> <li>SSE endpoint: <code>http://localhost:8000/sse</code></li> <li>Message POST: <code>http://localhost:8000/message</code></li> </ul> <p>To register it with the MCP Gateway:</p> <pre><code>export MY_MCP_TOKEN=\"optional-auth-header-if-needed\"\n\ncurl -s -k -X POST $BASE_URL/gateways \\\n  -H \"$AUTH_HEADER\" -H \"$JSON\" \\\n  -d '{\n        \"name\": \"github-mcp\",\n        \"url\": \"http://localhost:8000/sse\",\n        \"description\": \"GitHub MCP Tools via SuperGateway\",\n        \"auth_type\": \"none\"\n      }'\n</code></pre> <p>This gives you access to GitHub's MCP tools like <code>get_repo_issues</code>, <code>get_pull_requests</code>, etc.</p>"},{"location":"testing/basic/#11-development-testing-with-mcp-inspector","title":"11. Development Testing with MCP Inspector","text":"<p>Launch a visual inspector to interactively test your Gateway:</p> <pre><code>npx @modelcontextprotocol/inspector\n</code></pre> <p>Once launched at http://localhost:5173:</p> <ol> <li>Click \"Add Server\"</li> <li>Use the URL for your virtual server's SSE stream:</li> </ol> <pre><code>http://localhost:4444/servers/UUID_OF_SERVER_1/sse\n</code></pre> <ol> <li>Add this header:</li> </ol> <pre><code>{\n  \"Authorization\": \"Bearer &lt;your-jwt-token&gt;\"\n}\n</code></pre> <ol> <li>Save and test tool invocations by selecting a tool and sending sample input:</li> </ol> <pre><code>{ \"timezone\": \"Europe/Dublin\" }\n</code></pre>"},{"location":"testing/basic/#cleanup","title":"\ud83e\uddf9 Cleanup","text":"<pre><code>curl -s -k -X DELETE -H \"$AUTH_HEADER\" $BASE_URL/servers/UUID_OF_SERVER_1\ncurl -s -k -X DELETE -H \"$AUTH_HEADER\" $BASE_URL/tools/1\ncurl -s -k -X DELETE -H \"$AUTH_HEADER\" $BASE_URL/gateways/1\n</code></pre>"},{"location":"testing/basic/#summary","title":"\u2705 Summary","text":"<p>This smoke test validates:</p> <ul> <li>\u2705 Gateway JWT auth</li> <li>\u2705 Peer Gateway registration with remote bearer</li> <li>\u2705 Tool registration and RPC wiring</li> <li>\u2705 Virtual server creation</li> <li>\u2705 SSE subscription and live messaging</li> <li>\u2705 JSON-RPC invocation flow</li> <li>\u2705 Connecting MCP Inspector to the MCP Gateway</li> <li>\u2705 Connecting the official GitHub MCP server to the Gateway</li> </ul>"},{"location":"testing/performance/","title":"Performance Testing","text":"<p>Use this guide to benchmark MCP Gateway under load, validate performance improvements, and identify bottlenecks before production deployment.</p>"},{"location":"testing/performance/#tooling-hey","title":"\u2699\ufe0f Tooling: <code>hey</code>","text":"<p><code>hey</code> is a CLI-based HTTP load generator. Install it with:</p> <pre><code>brew install hey            # macOS\nsudo apt install hey        # Debian/Ubuntu\ngo install github.com/rakyll/hey@latest  # From source\n</code></pre>"},{"location":"testing/performance/#establishing-a-baseline","title":"\ud83c\udfaf Establishing a Baseline","text":"<p>Before benchmarking the full MCP Gateway stack, run tests against the MCP server directly (if applicable) to establish baseline latency and throughput. This helps isolate issues related to gateway overhead, authentication, or network I/O.</p> <p>If your backend service exposes a direct HTTP interface or gRPC gateway, target it with <code>hey</code> using the same payload and concurrency settings.</p> <pre><code>hey -n 5000 -c 100 \\\n  -m POST \\\n  -T application/json \\\n  -D tests/hey/payload.json \\\n  http://localhost:5000/your-backend-endpoint\n</code></pre> <p>Compare the 95/99<sup>th</sup> percentile latencies and error rates with and without the gateway in front. Any significant increase can guide you toward:</p> <ul> <li>Bottlenecks in auth middleware</li> <li>Overhead from JSON-RPC wrapping/unwrapping</li> <li>Improper worker/thread config in Gunicorn</li> </ul>"},{"location":"testing/performance/#scripted-load-tests-testsheyheysh","title":"\ud83d\ude80 Scripted Load Tests: <code>tests/hey/hey.sh</code>","text":"<p>A wrapper script exists at:</p> <pre><code>tests/hey/hey.sh\n</code></pre> <p>This script provides:</p> <ul> <li>Strict error handling (<code>set -euo pipefail</code>)</li> <li>Helpful CLI interface (<code>-n</code>, <code>-c</code>, <code>-d</code>, etc.)</li> <li>Required dependency checks</li> <li>Optional dry-run mode</li> <li>Timestamped logging</li> </ul> <p>Example usage:</p> <pre><code>./hey.sh -n 10000 -c 200 \\\n  -X POST \\\n  -T application/json \\\n  -H \"Authorization: Bearer $JWT\" \\\n  -d payload.json \\\n  -u http://localhost:4444/rpc\n</code></pre> <p>The <code>payload.json</code> file is expected to be a valid JSON-RPC request payload.</p> <p>Sample payload (<code>tests/hey/payload.json</code>):</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"convert_time\",\n  \"params\": {\n    \"source_timezone\": \"Europe/Berlin\",\n    \"target_timezone\": \"Europe/Dublin\",\n    \"time\": \"09:00\"\n  }\n}\n</code></pre> <p>Logs are saved automatically (e.g. <code>hey-20250610_120000.log</code>).</p>"},{"location":"testing/performance/#interpreting-results","title":"\ud83d\udcca Interpreting Results","text":"<p>When the test completes, look at:</p> Metric Interpretation Requests/sec (RPS) Raw throughput capability 95/99<sup>th</sup> percentile Tail latency - tune <code>timeout</code>, workers, or DB pooling Non-2xx responses Failures under load - common with CPU/memory starvation"},{"location":"testing/performance/#tips-best-practices","title":"\ud83e\uddea Tips &amp; Best Practices","text":"<ul> <li>Always test against a realistic endpoint (e.g. <code>POST /rpc</code> with auth and payload).</li> <li>Use the same JWT and payload structure your clients would.</li> <li>Run from a dedicated machine to avoid local CPU skewing results.</li> <li>Use <code>make run</code> or <code>make serve</code> to launch the app for local testing.</li> </ul> <p>For runtime tuning details, see Gateway Tuning Guide.</p>"},{"location":"using/","title":"Using MCP Gateway","text":"<p>This section focuses on how to use MCP Gateway effectively as a developer, integrator, or end user.</p>"},{"location":"using/#typical-use-cases","title":"\ud83d\udc68\ud83d\udcbb Typical Use Cases","text":"<ul> <li>You want to expose tools, prompts, or resources via MCP.</li> <li>You want to use <code>mcpgateway-wrapper</code> to connect to any MCP Gateway service using <code>stdio</code>, while still supporting authentication to the gateway.</li> <li>You're building a client or agent framework that speaks the MCP protocol.</li> <li>You want to consume Gateway APIs from an LLM agent, browser app, or CLI tool.</li> </ul>"},{"location":"using/#what-youll-find-in-this-section","title":"\ud83d\udcda What You'll Find in This Section","text":"Page Description mcpgateway-wrapper Wrap CLI tools or subprocesses to expose them via SSE/stdio Clients Compatible UIs and developer tools Agents LangChain, LangGraph, CrewAI, and other frameworks"},{"location":"using/#authentication-reminder","title":"\ud83d\udd11 Authentication Reminder","text":"<p>All Gateway usage requires authentication unless <code>AUTH_REQUIRED=false</code>. Refer to:</p> <pre><code>curl -H \"Authorization: Bearer $TOKEN\" http://localhost:4444/tools\n</code></pre> <p>Or use Basic Auth for the Admin UI and <code>/admin</code> routes.</p>"},{"location":"using/mcpgateway-translate/","title":"MCP Gateway StdIO to SSE Bridge (<code>mcpgateway.translate</code>)","text":"<p><code>mcpgateway.translate</code> is a lightweight bridge that connects a JSON-RPC server running over StdIO to an HTTP/SSE interface, or consumes a remote SSE stream and forwards messages to a local StdIO process.</p> <p>Supported modes:</p> <ol> <li>StdIO to SSE - serve a local subprocess over HTTP with SSE output</li> <li>SSE to StdIO - subscribe to a remote SSE stream and forward messages to a local process</li> </ol>"},{"location":"using/mcpgateway-translate/#features","title":"Features","text":"Feature Description Bidirectional bridging Supports both StdIO to SSE and SSE to StdIO Keep-alive frames Emits <code>keepalive</code> events every 30 seconds Endpoint bootstrapping Sends a unique message POST endpoint per client session CORS support Configure allowed origins via <code>--cors</code> OAuth2 support Use <code>--oauth2Bearer</code> to authorize remote SSE connections Health check Provides a <code>/healthz</code> endpoint for liveness probes Logging control Adjustable log verbosity with <code>--logLevel</code> Graceful shutdown Cleans up subprocess and server on termination signals"},{"location":"using/mcpgateway-translate/#quick-start","title":"Quick Start","text":""},{"location":"using/mcpgateway-translate/#expose-a-local-stdio-server-over-sse","title":"Expose a local StdIO server over SSE","text":"<pre><code>python3 -m mcpgateway.translate \\\n  --stdio \"uvx mcp-server-git\" \\\n  --port 9000\n</code></pre> <p>Access the SSE stream at:</p> <pre><code>http://localhost:9000/sse\n</code></pre>"},{"location":"using/mcpgateway-translate/#bridge-a-remote-sse-endpoint-to-a-local-process","title":"Bridge a remote SSE endpoint to a local process","text":"<pre><code>python3 -m mcpgateway.translate \\\n  --sse \"https://corp.example.com/mcp\" \\\n  --oauth2Bearer \"your-token\"\n</code></pre>"},{"location":"using/mcpgateway-translate/#command-line-options","title":"Command-Line Options","text":"<pre><code>python3 -m mcpgateway.translate [--stdio CMD | --sse URL | --streamableHttp URL] [options]\n</code></pre>"},{"location":"using/mcpgateway-translate/#required-one-of","title":"Required (one of)","text":"<ul> <li> <p><code>--stdio &lt;command&gt;</code>   Start a local process whose stdout will be streamed as SSE and stdin will receive backchannel messages.</p> </li> <li> <p><code>--sse &lt;url&gt;</code>   Connect to a remote SSE stream and forward messages to a local subprocess.</p> </li> <li> <p><code>--streamableHttp &lt;url&gt;</code>   Not implemented in this build. Raises an error.</p> </li> </ul>"},{"location":"using/mcpgateway-translate/#optional","title":"Optional","text":"<ul> <li> <p><code>--port &lt;number&gt;</code>   HTTP server port when using \u2013stdio mode (default: 8000)</p> </li> <li> <p><code>--cors &lt;origins&gt;</code>   One or more allowed origins for CORS (space-separated)</p> </li> <li> <p><code>--oauth2Bearer &lt;token&gt;</code>   Bearer token to include in Authorization header when connecting to remote SSE</p> </li> <li> <p><code>--logLevel &lt;level&gt;</code>   Logging level (default: info). Options: debug, info, warning, error, critical</p> </li> </ul>"},{"location":"using/mcpgateway-translate/#http-api-when-using-stdio","title":"HTTP API (when using \u2013stdio)","text":""},{"location":"using/mcpgateway-translate/#get-sse","title":"GET /sse","text":"<p>Streams JSON-RPC responses as SSE. Each connection receives:</p> <ul> <li><code>event: endpoint</code> - the URL for backchannel POST</li> <li><code>event: keepalive</code> - periodic keepalive signal</li> <li><code>event: message</code> - forwarded output from subprocess</li> </ul>"},{"location":"using/mcpgateway-translate/#post-message","title":"POST /message","text":"<p>Send a JSON-RPC message to the subprocess. Returns HTTP 202 on success, or 400 for invalid JSON.</p>"},{"location":"using/mcpgateway-translate/#get-healthz","title":"GET /healthz","text":"<p>Health check endpoint. Always responds with <code>ok</code>.</p>"},{"location":"using/mcpgateway-translate/#example-use-cases","title":"Example Use Cases","text":""},{"location":"using/mcpgateway-translate/#1-browser-integration","title":"1. Browser integration","text":"<pre><code>python3 -m mcpgateway.translate \\\n  --stdio \"uvx mcp-server-git\" \\\n  --port 9000 \\\n  --cors \"https://myapp.com\"\n</code></pre> <p>Then connect the frontend to:</p> <pre><code>http://localhost:9000/sse\n</code></pre>"},{"location":"using/mcpgateway-translate/#2-connect-remote-server-to-local-cli-tools","title":"2. Connect remote server to local CLI tools","text":"<pre><code>python3 -m mcpgateway.translate \\\n  --sse \"https://corp.example.com/mcp\" \\\n  --oauth2Bearer \"$TOKEN\" \\\n  --logLevel debug\n</code></pre>"},{"location":"using/mcpgateway-translate/#notes","title":"Notes","text":"<ul> <li>Only StdIO to SSE and SSE to StdIO bridging are implemented.</li> <li>Any use of <code>--streamableHttp</code> will raise a NotImplementedError.</li> </ul>"},{"location":"using/mcpgateway-wrapper/","title":"\ud83d\udee0 STDIO Wrapper (<code>mcpgateway.wrapper</code>)","text":"<p><code>mcpgateway.wrapper</code> ships inside the main PyPI package and re-publishes your Gateway's tools / prompts / resources over <code>stdin \u2194 stdout</code>, while connecting securely to the gateway using <code>SSE</code> + <code>JWT</code>.</p> <p>Perfect for clients that can't open SSE streams or attach JWT headers (e.g. Claude Desktop, Cline, Continue, custom CLI scripts).</p>"},{"location":"using/mcpgateway-wrapper/#key-highlights","title":"\ud83d\udd11 Key Highlights","text":"<ul> <li>Dynamic catalog - auto-syncs from one or more <code>.../servers/{id}</code> Virtual Server endpoints</li> <li>Full MCP protocol - <code>initialize</code>, <code>ping</code>, <code>tools/call</code>, streaming content, resources and prompts/template rendering</li> <li>Transparent proxy - stdio \u2192 Gateway \u2192 tool, results stream back to stdout</li> <li>Secure - wrapper keeps using your JWT to talk to the Gateway</li> </ul>"},{"location":"using/mcpgateway-wrapper/#launch-options","title":"\ud83d\ude80 Launch Options","text":"<p>Ensure you have a valid JWT tokens:</p> <pre><code>export MCP_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token \\\n      --username admin --exp 10080 --secret my-test-key)\n</code></pre> <p>Configure the wrapper via ENV variables:</p> <pre><code>export MCP_AUTH_TOKEN=${MCPGATEWAY_BEARER_TOKEN}\nexport MCP_SERVER_CATALOG_URLS='http://localhost:4444/servers/UUID_OF_SERVER_1'  # select a virtual server\nexport MCP_TOOL_CALL_TIMEOUT=120          # tool call timeout in seconds (optional - default 90)\nexport MCP_WRAPPER_LOG_LEVEL=INFO         # DEBUG | INFO | OFF\n</code></pre> <p>Configure via Pip or Docker. Note that lauching the wrapper should be done from an MCP Client (ex: via the JSON configuration).</p> <p>Launching it in your terminal (ex: <code>python3 -m mcpgateway.wrapper</code>) is useful for testing.</p> Local shell (venv)Docker / Podmanpipx (one-liner)uv / uvx (ultra-fast) <pre><code>pip install mcp-contextforge-gateway\npython3 -m mcpgateway.wrapper\n</code></pre> <pre><code>docker run -i --rm --network=host \\\n  -e MCP_SERVER_CATALOG_URLS=$MCP_SERVER_CATALOG_URLS \\\n  -e MCP_AUTH_TOKEN=$MCP_AUTH_TOKEN \\\n  ghcr.io/ibm/mcp-context-forge:latest \\\n  python3 -m mcpgateway.wrapper\n</code></pre> <pre><code>pipx install --include-deps mcp-contextforge-gateway\nMCP_AUTH_TOKEN=$MCP_AUTH_TOKEN \\\nMCP_SERVER_CATALOG_URLS=$MCP_SERVER_CATALOG_URLS \\\npython3 -m mcpgateway.wrapper\n</code></pre> <pre><code>curl -Ls https://astral.sh/uv/install.sh | sh\nuv venv ~/.venv/mcpgw &amp;&amp; source ~/.venv/mcpgw/bin/activate\nuv pip install mcp-contextforge-gateway\nuv python3 -m mcpgateway.wrapper\n</code></pre> <p>The wrapper now waits for JSON-RPC on stdin and emits replies on stdout.</p>"},{"location":"using/mcpgateway-wrapper/#environment-variables","title":"\u2705 Environment Variables","text":"Variable Purpose Default <code>MCP_SERVER_CATALOG_URLS</code> Comma-sep list of <code>/servers/{id}</code> endpoints - <code>MCP_AUTH_TOKEN</code> Bearer token the wrapper forwards to Gateway - <code>MCP_TOOL_CALL_TIMEOUT</code> Per-tool timeout (seconds) <code>90</code> <code>MCP_WRAPPER_LOG_LEVEL</code> <code>OFF</code>, <code>INFO</code>, <code>DEBUG</code>, \u2026 <code>INFO</code>"},{"location":"using/mcpgateway-wrapper/#gui-client-config-json-snippets","title":"\ud83d\udda5 GUI Client Config JSON Snippets","text":"<p>You can run <code>mcpgateway.wrapper</code> from any MCP client, using either <code>python3</code>, <code>uv</code>, <code>uvx</code>, <code>uvx</code>, <code>pipx</code>, <code>docker</code>, or <code>podman</code> entrypoints.</p> <p>The MCP Client calls the entrypoint, which needs to have the <code>mcp-contextforge-gateway</code> module installed, able to call <code>mcpgateway.wrapper</code> and the right <code>env</code> settings exported (<code>MCP_SERVER_CATALOG_URLS</code> and <code>MCP_AUTH_TOKEN</code> at a minimum).</p> Claude Desktop (venv)Claude Desktop (uvx)Continue (python3)Cline (uv) <pre><code>{\n  \"mcpServers\": {\n    \"mcpgateway-wrapper\": {\n      \"command\": \"python3\",\n      \"args\": [\"-m\", \"mcpgateway.wrapper\"],\n      \"env\": {\n        \"MCP_AUTH_TOKEN\": \"&lt;paste-token&gt;\",\n        \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444/servers/UUID_OF_SERVER_1\"\n      }\n    }\n  }\n}\n</code></pre> <p>Use your venv's Python</p> <p>Replace <code>/path/to/python</code> with the exact interpreter in your venv (e.g. <code>$HOME/.venv/mcpgateway/bin/python3</code>) - where the <code>mcp-contextforge-gateway</code> module is installed.</p> <pre><code>{\n  \"mcpServers\": {\n    \"mcpgateway-wrapper\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"run\",\n        \"--\",\n        \"python\",\n        \"-m\",\n        \"mcpgateway.wrapper\"\n      ],\n      \"env\": {\n        \"MCP_AUTH_TOKEN\": \"&lt;paste-token&gt;\",\n        \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444/servers/UUID_OF_SERVER_1\"\n      }\n    }\n  }\n}\n</code></pre> <p>Add to Settings \u2192 Continue: MCP Servers:</p> <pre><code>{\n  \"mcpgateway-wrapper\": {\n    \"command\": \"/path/to/python\",\n    \"args\": [\"-m\", \"mcpgateway.wrapper\"],\n    \"env\": {\n      \"MCP_AUTH_TOKEN\": \"&lt;token&gt;\",\n      \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444/servers/UUID_OF_SERVER_1\"\n    }\n  }\n}\n</code></pre> <p>(Replace <code>/path/to/python</code> with your venv interpreter.)</p> <pre><code>{\n  \"mcpServers\": {\n    \"mcpgateway-wrapper\": {\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"type\": \"stdio\",\n      \"command\": \"uv\",\n      \"args\": [\n        \"run\",\n        \"--directory\",\n        \"REPLACE_WITH_PATH_TO_REPO\",\n        \"-m\",\n        \"mcpgateway.wrapper\"\n      ],\n      \"env\": {\n        \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444/servers/UUID_OF_SERVER_1\",\n        \"MCP_AUTH_TOKEN\": \"REPLACE_WITH_MCPGATEWAY_BEARER_TOKEN\",\n        \"MCP_WRAPPER_LOG_LEVEL\": \"OFF\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"using/mcpgateway-wrapper/#local-development","title":"\ud83d\udc0d Local Development","text":"<pre><code># Hot-reload wrapper code while hacking\nuv --dev run python3 -m mcpgateway.wrapper\n</code></pre>"},{"location":"using/mcpgateway-wrapper/#mcp-inspector","title":"\ud83d\udd0e MCP Inspector","text":"<pre><code>npx @modelcontextprotocol/inspector \\\n     python3 -m mcpgateway.wrapper -- \\\n     --log-level DEBUG\n</code></pre>"},{"location":"using/mcpgateway-wrapper/#example-call-flow","title":"\ud83d\udcdd Example call flow","text":"<pre><code>{\n  \"method\": \"get_system_time\",\n  \"params\": { \"timezone\": \"Europe/Dublin\" }\n}\n</code></pre> <ol> <li>Wrapper maps <code>get_system_time</code> \u2192 tool ID 123 in the catalog.</li> <li>Sends RPC to the Gateway with your JWT token.</li> <li>Gateway executes the tool and returns JSON \u2192 wrapper \u2192 stdout.</li> </ol>"},{"location":"using/mcpgateway-wrapper/#manual-json-rpc-smoke-test","title":"\ud83e\uddea Manual JSON-RPC Smoke-test","text":"<p>The wrapper speaks plain JSON-RPC over stdin/stdout, so you can exercise it from any terminal-no GUI required. Open two shells or use a tool like <code>jq -c | nc -U</code> to pipe messages in and view replies.</p> Step-by-step request sequence <pre><code># 1\ufe0f\u20e3 Initialize session\n{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"initialize\",\"params\":{\"protocolVersion\":\"2025-03-26\",\"capabilities\":{},\n  \"clientInfo\":{\"name\":\"demo\",\"version\":\"0.0.1\"}\n}}\n\n# 2\ufe0f\u20e3 Ack initialisation (required by MCP)\n{\"jsonrpc\":\"2.0\",\"method\":\"notifications/initialized\",\"params\":{}}\n\n# 3\ufe0f\u20e3 Prompts\n{\"jsonrpc\":\"2.0\",\"id\":4,\"method\":\"prompts/list\"}\n{\"jsonrpc\":\"2.0\",\"id\":5,\"method\":\"prompts/get\",\n \"params\":{\"name\":\"greeting\",\"arguments\":{\"user\":\"Bob\"}}}\n\n# 4\ufe0f\u20e3 Resources\n{\"jsonrpc\":\"2.0\",\"id\":6,\"method\":\"resources/list\"}\n{\"jsonrpc\":\"2.0\",\"id\":7,\"method\":\"resources/read\",\n \"params\":{\"uri\":\"https://example.com/some.txt\"}}\n\n# 5\ufe0f\u20e3 Tools (list / call)\n{\"jsonrpc\":\"2.0\",\"id\":2,\"method\":\"tools/list\"}\n{\"jsonrpc\":\"2.0\",\"id\":3,\"method\":\"tools/call\",\n \"params\":{\"name\":\"get_system_time\",\"arguments\":{\"timezone\":\"Europe/Dublin\"}}}\n</code></pre> Sample responses you should see <pre><code># Initialise\n{\"jsonrpc\":\"2.0\",\"id\":1,\"result\":{\n  \"protocolVersion\":\"2025-03-26\",\n  \"capabilities\":{\n    \"experimental\":{},\n    \"prompts\":{\"listChanged\":false},\n    \"resources\":{\"subscribe\":false,\"listChanged\":false},\n    \"tools\":{\"listChanged\":false}\n  },\n  \"serverInfo\":{\"name\":\"mcpgateway-wrapper\",\"version\":\"0.3.0\"}\n}}\n\n# Empty tool list\n{\"jsonrpc\":\"2.0\",\"id\":2,\"result\":{\"tools\":[]}}\n\n# ...after adding tools (example)\n{\"jsonrpc\":\"2.0\",\"id\":2,\"result\":{\n  \"tools\":[\n    {\n      \"name\":\"get_system_time\",\n      \"description\":\"Get current time in a specific timezone\",\n      \"inputSchema\":{\n        \"type\":\"object\",\n        \"properties\":{\n          \"timezone\":{\n            \"type\":\"string\",\n            \"description\":\"IANA timezone name (e.g. 'Europe/London').\"\n          }\n        },\n        \"required\":[\"timezone\"]\n      }\n    }\n  ]\n}}\n\n# Tool invocation\n{\"jsonrpc\":\"2.0\",\"id\":3,\"result\":{\n  \"content\":[\n    {\n      \"type\":\"text\",\n      \"text\":\"{ \\\"timezone\\\": \\\"Europe/Dublin\\\", \\\"datetime\\\": \\\"2025-06-08T21:47:07+01:00\\\", \\\"is_dst\\\": true }\"\n    }\n  ],\n  \"isError\":false\n}}\n</code></pre>"},{"location":"using/agents/","title":"Agent Integrations","text":"<p>This section provides guidance on integrating various AI agent frameworks with the Model Context Protocol (MCP) Gateway. MCP enables agents to dynamically discover and utilize tools across multiple servers, enhancing their capabilities and flexibility.</p>"},{"location":"using/agents/#supported-agent-frameworks","title":"\ud83e\udde0 Supported Agent Frameworks","text":"<ul> <li>LangChain: Utilize MCP tools within LangChain agents using the <code>langchain-mcp-adapters</code> package.</li> <li>LangGraph: Integrate MCP tools into LangGraph agents for advanced workflow orchestration.</li> <li>CrewAI: Connect CrewAI agents to MCP servers using the <code>crewai-tools</code> library.</li> <li>Bee Agent Framework: Leverage MCP tools within the Bee Agent Framework for scalable agent deployments.</li> <li>AutoGen: Integrate MCP tools with AutoGen agents using the <code>autogen-ext-mcp</code> package.</li> <li>LlamaIndex: Incorporate MCP tools into LlamaIndex workflows for enhanced data retrieval and question answering.</li> <li>OpenAI Agents SDK: Utilize MCP tools within OpenAI's Agents SDK for building AI agents with standardized tool access.</li> <li>Semantic Kernel: Connect Semantic Kernel agents to MCP servers for enriched context and tool integration.</li> </ul>"},{"location":"using/agents/#overview","title":"\ud83d\udd0d Overview","text":"<p>Each integration guide includes:</p> <ul> <li>Installation Instructions: Step-by-step setup for the respective agent framework.</li> <li>Configuration Details: How to connect the agent to the MCP Gateway, including authentication and transport options.</li> <li>Usage Examples: Sample code demonstrating how to invoke MCP tools within the agent's workflow.</li> <li>Additional Resources: Links to official documentation and repositories for further reference.</li> </ul>"},{"location":"using/agents/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>Model Context Protocol Overview</li> <li>MCP Gateway Documentation</li> </ul>"},{"location":"using/agents/autogen/","title":"AutoGen Integration with MCP Gateway","text":"<p>AutoGen is an open-source framework from Microsoft for building multi-agent systems. It supports tool calling and dynamic agent coordination.</p>"},{"location":"using/agents/autogen/#mcp-support","title":"\ud83d\udd27 MCP Support","text":"<p>Experimental support for MCP integration is available via custom <code>ToolAgent</code> wrappers that call MCP tools via HTTP or <code>mcpgateway-wrapper</code>.</p> <p>A full guide is coming soon. For now, you can use <code>requests</code> or <code>httpx</code> to call MCP Gateway endpoints from AutoGen agents.</p>"},{"location":"using/agents/autogen/#resources","title":"\ud83d\udd17 Resources","text":"<ul> <li>AutoGen GitHub</li> <li>AutoGen Docs</li> </ul>"},{"location":"using/agents/bee/","title":"Bee Agent Framework Integration with MCP Gateway","text":"<p>The Bee Agent Framework is an open-source platform developed by IBM for building, deploying, and managing AI agents at scale. Integrating Bee with the Model Context Protocol (MCP) allows agents to dynamically discover and utilize tools hosted on MCP servers, enhancing their capabilities and flexibility.</p>"},{"location":"using/agents/bee/#key-features","title":"\ud83e\uddf0 Key Features","text":"<ul> <li>Dynamic Tool Discovery: Agents can fetch available tools from MCP servers in real-time.</li> <li>Standardized Communication: Utilizes the open MCP standard for consistent tool integration.</li> <li>Multi-Server Support: Interact with tools defined on multiple MCP servers simultaneously.</li> <li>Human-in-the-Loop: Incorporate human feedback into agent workflows for improved decision-making.</li> </ul>"},{"location":"using/agents/bee/#installation","title":"\ud83d\udee0 Installation","text":"<p>To use MCP tools in the Bee Agent Framework, follow these steps:</p> <ol> <li>Clone the Bee Agent Framework Repository:</li> </ol> <p><code>bash    git clone https://github.com/i-am-bee/bee-agent-framework.git    cd bee-agent-framework</code></p> <ol> <li>Install Dependencies:</li> </ol> <pre><code>yarn install\n</code></pre> <ol> <li>Set Up the Environment:</li> </ol> <p>Ensure you have Node.js and Yarn installed. You may also need to set environment variables for your MCP server:</p> <pre><code>export MCP_GATEWAY_BASE_URL=http://localhost:4444\nexport MCP_AUTH_TOKEN=\"your_bearer_token\"\n</code></pre>"},{"location":"using/agents/bee/#connecting-to-mcp-gateway","title":"\ud83d\udd17 Connecting to MCP Gateway","text":"<p>Bee provides a native <code>MCPTool</code> class to simplify integration with MCP servers. Here's how to set it up:</p> <ol> <li>Import the MCPTool Class:</li> </ol> <pre><code>import { MCPTool } from 'bee-agent-framework/tools/mcp';\n</code></pre> <ol> <li>Configure the MCPTool:</li> </ol> <pre><code>const mcpTool = new MCPTool({\n  baseUrl: process.env.MCP_GATEWAY_BASE_URL,\n  auth: {\n    username: process.env.MCP_AUTH_USER,\n    password: process.env.MCP_AUTH_PASS,\n  },\n});\n</code></pre> <ol> <li>Register the Tool with Your Agent:</li> </ol> <pre><code>agent.registerTool(mcpTool);\n</code></pre> <p>This setup allows your Bee agent to discover and invoke tools from the specified MCP server dynamically.</p>"},{"location":"using/agents/bee/#creating-an-agent","title":"\ud83e\udd16 Creating an Agent","text":"<p>After setting up the MCPTool, you can create a Bee agent:</p> <pre><code>import { Agent } from 'bee-agent-framework';\n\nconst agent = new Agent({\n  name: 'Data Analyst',\n  tools: [mcpTool],\n});\n</code></pre>"},{"location":"using/agents/bee/#using-the-agent","title":"\ud83e\uddea Using the Agent","text":"<p>Once the agent is created, you can assign tasks and execute them:</p> <pre><code>agent.runTask('Generate a sales report for Q1 2025');\n</code></pre> <p>The agent will utilize tools from the MCP server to accomplish the task.</p>"},{"location":"using/agents/bee/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>Bee Agent Framework Documentation</li> <li>Bee Agent Framework GitHub Repository</li> <li>Model Context Protocol Overview</li> </ul>"},{"location":"using/agents/crewai/","title":"CrewAI Integration with MCP Gateway","text":"<p>CrewAI is a multi-agent orchestration framework that enables AI agents to collaborate on complex tasks. Integrating CrewAI with the Model Context Protocol (MCP) allows agents to dynamically discover and utilize tools hosted on MCP servers, enhancing their capabilities and flexibility.</p>"},{"location":"using/agents/crewai/#key-features","title":"\ud83e\uddf0 Key Features","text":"<ul> <li>Dynamic Tool Discovery: Agents can fetch available tools from MCP servers in real-time.</li> <li>Standardized Communication: Utilizes the open MCP standard for consistent tool integration.</li> <li>Multi-Server Support: Interact with tools defined on multiple MCP servers simultaneously.</li> </ul>"},{"location":"using/agents/crewai/#installation","title":"\ud83d\udee0 Installation","text":"<p>To use MCP tools in CrewAI, install the <code>crewai-tools</code> package with MCP support:</p> <pre><code>pip install \"crewai-tools[mcp]\"\n</code></pre>"},{"location":"using/agents/langchain/","title":"LangChain Integration with MCP Gateway","text":"<p>LangChain is a framework for developing applications powered by language models. Integrating LangChain with the Model Context Protocol (MCP) allows agents to utilize tools defined across one or more MCP servers, enabling seamless interaction with external data sources and services.</p>"},{"location":"using/agents/langchain/#key-features","title":"\ud83e\uddf0 Key Features","text":"<ul> <li>Dynamic Tool Access: Connects to MCP servers to fetch available tools in real time.</li> <li>Multi-Server Support: Interact with tools defined on multiple MCP servers simultaneously.</li> <li>Standardized Communication: Utilizes the open MCP standard for consistent tool integration.</li> </ul>"},{"location":"using/agents/langchain/#installation","title":"\ud83d\udee0 Installation","text":"<p>To use MCP tools in LangChain, install the <code>langchain-mcp-adapters</code> package:</p> <pre><code>pip install langchain-mcp-adapters\n</code></pre>"},{"location":"using/agents/langchain/#connecting-to-mcp-gateway","title":"\ud83d\udd17 Connecting to MCP Gateway","text":"<p>Here's how to set up a connection to your MCP Gateway:</p> <pre><code>from langchain_mcp_adapters.client import MultiServerMCPClient\nfrom langgraph.prebuilt import create_react_agent\n\nclient = MultiServerMCPClient(\n    {\n        \"gateway\": {\n            \"url\": \"http://localhost:4444/mcp\",\n            \"transport\": \"streamable_http\",\n        }\n    }\n)\n</code></pre> <p>Replace <code>\"http://localhost:4444/mcp\"</code> with the URL of your MCP Gateway.</p>"},{"location":"using/agents/langchain/#creating-an-agent","title":"\ud83e\udd16 Creating an Agent","text":"<p>After setting up the client, you can create a LangChain agent:</p> <pre><code>agent = create_react_agent(\n    tools=client.get_tools(),\n    llm=your_language_model,\n)\n</code></pre> <p>Replace <code>your_language_model</code> with your configured language model instance.</p>"},{"location":"using/agents/langchain/#using-the-agent","title":"\ud83e\uddea Using the Agent","text":"<p>Once the agent is created, you can use it to perform tasks:</p> <pre><code>response = agent.run(\"Use the 'weather' tool to get the forecast for Dublin.\")\nprint(response)\n</code></pre>"},{"location":"using/agents/langchain/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>LangChain MCP Adapters Documentation</li> <li>LangChain GitHub Repository</li> <li>Model Context Protocol Overview</li> </ul>"},{"location":"using/agents/langgraph/","title":"LangGraph Integration with MCP Gateway","text":"<p>LangGraph is a framework for developing applications powered by language models. Integrating LangGraph with the Model Context Protocol (MCP) allows agents to utilize tools defined across one or more MCP servers, enabling seamless interaction with external data sources and services.</p>"},{"location":"using/agents/langgraph/#key-features","title":"\ud83e\uddf0 Key Features","text":"<ul> <li>Dynamic Tool Access: Connects to MCP servers to fetch available tools in real time.</li> <li>Multi-Server Support: Interact with tools defined on multiple MCP servers simultaneously.</li> <li>Standardized Communication: Utilizes the open MCP standard for consistent tool integration.</li> </ul>"},{"location":"using/agents/langgraph/#installation","title":"\ud83d\udee0 Installation","text":"<p>To use MCP tools in LangGraph, install the <code>langchain-mcp-adapters</code> package:</p> <pre><code>pip install langchain-mcp-adapters\n</code></pre>"},{"location":"using/agents/langgraph/#connecting-to-mcp-gateway","title":"\ud83d\udd17 Connecting to MCP Gateway","text":"<p>Here's how to set up a connection to your MCP Gateway:</p> <pre><code>from langchain_mcp_adapters.client import MultiServerMCPClient\nfrom langgraph.prebuilt import create_react_agent\n\nclient = MultiServerMCPClient(\n    {\n        \"gateway\": {\n            \"url\": \"http://localhost:4444/mcp\",\n            \"transport\": \"streamable_http\",\n        }\n    }\n)\n</code></pre> <p>Replace <code>\"http://localhost:4444/mcp\"</code> with the URL of your MCP Gateway.</p>"},{"location":"using/agents/langgraph/#creating-an-agent","title":"\ud83e\udd16 Creating an Agent","text":"<p>After setting up the client, you can create a LangGraph agent:</p> <pre><code>agent = create_react_agent(\n    tools=client.get_tools(),\n    llm=your_language_model,\n)\n</code></pre> <p>Replace <code>your_language_model</code> with your configured language model instance.</p>"},{"location":"using/agents/langgraph/#using-the-agent","title":"\ud83e\uddea Using the Agent","text":"<p>Once the agent is created, you can use it to perform tasks:</p> <pre><code>response = agent.run(\"Use the 'weather' tool to get the forecast for Dublin.\")\nprint(response)\n</code></pre>"},{"location":"using/agents/langgraph/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>LangGraph MCP Integration Documentation</li> <li>LangChain MCP Adapters GitHub Repository</li> <li>Model Context Protocol Overview</li> </ul>"},{"location":"using/agents/llamaindex/","title":"LlamaIndex Integration with MCP Gateway","text":"<p>LlamaIndex is a framework for building retrieval-augmented generation (RAG) pipelines.</p>"},{"location":"using/agents/llamaindex/#mcp-support","title":"\ud83d\udd27 MCP Support","text":"<p>You can wrap tool calls from MCP Gateway as query engines, retrievers, or tool nodes inside LlamaIndex.</p> <p>A dedicated <code>ToolRetriever</code> adapter is under development to support direct MCP tool discovery.</p>"},{"location":"using/agents/openai-sdk/","title":"OpenAI Agents SDK + MCP Gateway","text":"<p>OpenAI's Agents SDK supports structured tool use and multi-modal workflows. MCP Gateway can serve as a unified tool registry for OpenAI agents.</p>"},{"location":"using/agents/openai-sdk/#integration","title":"\ud83d\udd27 Integration","text":"<p>OpenAI SDK has native support for MCP.</p>"},{"location":"using/agents/openai-sdk/#resources","title":"\ud83d\udd17 Resources","text":"<ul> <li>OpenAI Agents SDK</li> <li>MCP Tool Protocol</li> </ul>"},{"location":"using/agents/semantic-kernel/","title":"Semantic Kernel Integration with MCP Gateway","text":"<p>Semantic Kernel is a Microsoft OSS framework for building AI-first apps.</p>"},{"location":"using/agents/semantic-kernel/#mcp-integration","title":"\ud83d\udd27 MCP Integration","text":"<p>Support for external tools via REST allows you to call MCP tools from SK plugins using <code>HttpFunction</code>.</p> <p>Define a plugin that points to MCP Gateway's <code>/tools/invoke</code> and pass arguments as JSON.</p>"},{"location":"using/agents/semantic-kernel/#resources","title":"\ud83d\udd17 Resources","text":"<ul> <li>Semantic Kernel GitHub</li> <li>Using REST APIs in SK</li> </ul>"},{"location":"using/clients/","title":"MCP Clients","text":"<p>MCP Gateway is compatible with any client that speaks the Model Context Protocol (MCP). This section documents tested clients, their configuration, and any integration tips.</p>"},{"location":"using/clients/#client-types","title":"\ud83d\udd0c Client Types","text":"<p>There are two ways clients typically connect:</p> <ul> <li>Direct to Gateway (HTTP/SSE/WS)</li> <li>Via <code>mcpgateway-wrapper</code> (stdio transport, especially for LLM apps)</li> </ul>"},{"location":"using/clients/#compatible-clients","title":"\u2705 Compatible Clients","text":"Client Type Notes Claude Desktop UI Configure to launch <code>mcpgateway.wrapper</code> via JSON Cline CLI Supports stdio or direct MCP over HTTP Continue VSCode plugin MCP plugin support MCP Inspector Web debugger Great for manual testing and exploring protocol features <p>Each of these tools can consume the MCP protocol and dynamically detect tools from the Gateway.</p>"},{"location":"using/clients/#whats-in-this-section","title":"\ud83d\udcc1 What's in This Section","text":"Page Description Claude Desktop How to connect Claude to MCP Gateway via wrapper Cline Using the CLI tool for invoking tools or prompts Continue Integrating with the VSCode plugin MCP Inspector Launch and test the Gateway or wrapper via a web debugger"},{"location":"using/clients/claude-desktop/","title":"Claude Desktop \u00d7 MCP Gateway","text":"<p>Claude Desktop can launch a local stdio process for every chat \"backend\". By pointing it at <code>mcpgateway.wrapper</code> you give Claude instant access to every tool, prompt and resource registered in your Gateway.</p>"},{"location":"using/clients/claude-desktop/#where-to-edit-the-config","title":"\ud83d\udcc2 Where to edit the config","text":"OS Path macOS <code>~/Library/Application Support/Claude/claude_desktop_config.json</code> Windows <code>%APPDATA%\\Claude\\claude_desktop_config.json</code> Linux (Flatpak / AppImage) <code>$HOME/.config/Claude/claude_desktop_config.json</code>"},{"location":"using/clients/claude-desktop/#minimal-json-block","title":"\u2699\ufe0f Minimal JSON block","text":"<pre><code>{\n  \"mcpServers\": {\n    \"mcpgateway-wrapper\": {\n      \"command\": \"python3\",\n      \"args\": [\"-m\", \"mcpgateway.wrapper\"],\n      \"env\": {\n        \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444/servers/UUID_OF_SERVER_1\",\n        \"MCP_AUTH_TOKEN\": \"&lt;YOUR_JWT_TOKEN&gt;\",\n        \"MCP_TOOL_CALL_TIMEOUT\": \"120\"\n      }\n    }\n  }\n}\n</code></pre> <p>Use the real server ID instead of <code>1</code> and paste your bearer token.</p>"},{"location":"using/clients/claude-desktop/#docker-alternative","title":"\ud83d\udc33 Docker alternative","text":"<pre><code>{\n  \"command\": \"docker\",\n  \"args\": [\n    \"run\", \"--rm\", \"--network=host\", \"-i\",\n    \"-e\", \"MCP_SERVER_CATALOG_URLS=http://localhost:4444/servers/UUID_OF_SERVER_1\",\n    \"-e\", \"MCP_AUTH_TOKEN=&lt;YOUR_JWT_TOKEN&gt;\",\n    \"ghcr.io/ibm/mcp-context-forge:latest\",\n    \"python3\", \"-m\", \"mcpgateway.wrapper\"\n  ]\n}\n</code></pre> <p>(Mac / Windows users should replace <code>localhost</code> with <code>host.docker.internal</code>.)</p>"},{"location":"using/clients/claude-desktop/#pipx-uvx-one-liner-wrapper-already-installed","title":"\u26a1 pipx / uvx one-liner (wrapper already installed)","text":"<p>If you installed the package globally:</p> <pre><code>{\n  \"command\": \"pipx\",\n  \"args\": [\"run\", \"python3\", \"-m\", \"mcpgateway.wrapper\"],\n  \"env\": {\n    \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444/servers/UUID_OF_SERVER_1\",\n    \"MCP_AUTH_TOKEN\": \"&lt;YOUR_JWT_TOKEN&gt;\"\n  }\n}\n</code></pre>"},{"location":"using/clients/claude-desktop/#smoke-test-inside-claude","title":"\ud83e\uddea Smoke-test inside Claude","text":"<ol> <li>Restart Claude Desktop (quit from system-tray).</li> <li>Select \"mcpgateway-wrapper\" in the chat dropdown.</li> <li>Type:</li> </ol> <p><pre><code>#get_system_time { \"timezone\": \"Europe/Dublin\" }\n</code></pre> 4. The wrapper should proxy the call \u2192 Gateway \u2192 tool \u2192 chat reply.</p> <p>If tools don't appear, open File \u25b8 Settings \u25b8 Developer \u25b8 View Logs to see wrapper output.</p>"},{"location":"using/clients/claude-desktop/#environment-variables-recap","title":"\ud83d\udd11 Environment variables recap","text":"Var Purpose <code>MCP_SERVER_CATALOG_URLS</code> One or more <code>/servers/{id}</code> endpoints (comma-sep) <code>MCP_AUTH_TOKEN</code> JWT bearer for Gateway auth <code>MCP_TOOL_CALL_TIMEOUT</code> Per-tool timeout (seconds, optional) <code>MCP_WRAPPER_LOG_LEVEL</code> <code>DEBUG</code>, <code>INFO</code>, <code>OFF</code> (optional) <p>You can place them:</p> <ul> <li>under <code>\"env\"</code> in the mcpServers block (preferred)</li> <li>in your user/environment shell before launching Claude.</li> </ul>"},{"location":"using/clients/cline/","title":"Cline (VS Code Extension)","text":"<p>Cline is a Visual Studio Code extension that brings AI-powered coding assistance directly into your editor. It supports the Model Context Protocol (MCP), enabling seamless integration with MCP-compatible servers like MCP Gateway.</p>"},{"location":"using/clients/cline/#key-features","title":"\ud83e\uddf0 Key Features","text":"<ul> <li>AI-Powered Coding: Leverages advanced AI models (e.g., Claude 3.5 Sonnet, DeepSeek Chat) for code generation, editing, and debugging.</li> <li>MCP Integration: Connects to MCP servers to discover and utilize tools dynamically.</li> <li>Terminal and Browser Access: Executes terminal commands and performs browser operations with user permission.</li> <li>Custom Tools: Supports adding custom tools via MCP for extended functionality.</li> </ul>"},{"location":"using/clients/cline/#installation","title":"\ud83d\udee0 Installation","text":"<ol> <li>Install Cline Extension:</li> <li>Open VS Code.</li> <li>Navigate to the Extensions view (<code>Ctrl+Shift+X</code> or <code>Cmd+Shift+X</code>).</li> <li> <p>Search for \"Cline\" and click \"Install\".</p> </li> <li> <p>Sign In to Cline:</p> </li> <li>Click the Cline icon in the Activity Bar.</li> <li>Follow the prompts to sign in or create a new account at app.cline.bot.</li> <li>New users receive free credits; no credit card required.</li> </ol>"},{"location":"using/clients/cline/#connecting-to-mcp-gateway","title":"\ud83d\udd17 Connecting to MCP Gateway","text":"<p>To integrate Cline with your MCP Gateway:</p> <ol> <li>Configure MCP Server:</li> <li>Open the Cline settings in VS Code.</li> <li>Navigate to the MCP Servers section.</li> <li> <p>Add a new MCP server with the following configuration under mcpServers as shown below:</p> <pre><code>\"mcpServers\": {\n    \"mcpgateway-wrapper\": {\n       \"disabled\": true,\n       \"timeout\": 60,\n       \"type\": \"stdio\",\n       \"command\": \"uv\",\n       \"args\": [\n       \"run\",\n       \"--directory\",\n       \"REPLACE_WITH_PATH_TO_REPO\",\n       \"-m\",\n       \"mcpgateway.wrapper\"\n       ],\n       \"env\": {\n          \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444\",\n          \"MCP_AUTH_TOKEN\": \"REPLACE_WITH_MCPGATEWAY_BEARER_TOKEN\",\n          \"MCP_WRAPPER_LOG_LEVEL\": \"OFF\"\n       }\n    }\n }\n</code></pre> </li> <li> <p>Enable the MCP Server:</p> </li> <li> <p>Ensure the newly added MCP server is enabled in the Cline settings.</p> </li> <li> <p>Verify Connection:</p> </li> <li>In the Cline interface, navigate to the MCP Servers section.</li> <li>Confirm that the MCP Gateway server is listed and shows a green status indicator.</li> </ol>"},{"location":"using/clients/cline/#using-mcp-tools-in-cline","title":"\ud83e\uddea Using MCP Tools in Cline","text":"<p>Once connected:</p> <ul> <li>Discover Tools: Cline will automatically fetch and list available tools from the MCP Gateway.</li> <li>Invoke Tools: Use natural language prompts in Cline to invoke tools. For example:</li> <li>\"Run the <code>hello_world</code> tool with the argument <code>name: Alice</code>.\"</li> <li>Monitor Responses: Cline will display the tool's output directly within the chat interface.</li> </ul>"},{"location":"using/clients/cline/#tips-for-effective-use","title":"\ud83d\udcdd Tips for Effective Use","text":"<ul> <li>.clinerules File: Create a <code>.clinerules</code> file in your project root to define project-specific behaviors and instructions for Cline.</li> <li>Custom Instructions: Utilize Cline's Custom Instructions feature to tailor its behavior across all projects.</li> <li>Model Selection: Choose the AI model that best fits your project's needs within the Cline settings.</li> </ul>"},{"location":"using/clients/cline/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>Cline Official Website</li> <li>Cline Documentation</li> </ul>"},{"location":"using/clients/continue/","title":"Continue (VS Code Extension)","text":"<p>Continue is an open-source AI code assistant for Visual Studio Code. Because it speaks the Model Context Protocol (MCP), Continue can discover and call the tools you publish through MCP Gateway - no plug-in code required.</p>"},{"location":"using/clients/continue/#key-features","title":"\ud83e\uddf0 Key Features","text":"<ul> <li>\u2728 AI-powered completions, edits &amp; chat</li> <li>\ud83d\udd0c MCP integration - dynamic tool list pulled from your gateway</li> <li>\ud83c\udfd7 Bring-your-own model - local Ollama, OpenAI, Anthropic, etc.</li> <li>\ud83e\udde0 Context-aware - reads your workspace to craft better replies</li> </ul>"},{"location":"using/clients/continue/#installation","title":"\ud83d\udee0 Installation","text":"<ol> <li>Install \"Continue\": <code>Ctrl \u21e7 X</code> \u2192 search Continue \u2192 Install</li> <li>Open config: <code>Ctrl \u21e7 P</code> \u2192 \"Continue: Open Config\"    \u2192 edits <code>~/.continue/config.json</code></li> </ol>"},{"location":"using/clients/continue/#connecting-continue-to-mcp-gateway","title":"\ud83d\udd17 Connecting Continue to MCP Gateway","text":"<p>There are two ways to attach Continue to a gateway:</p> Transport When to use Snippet SSE (HTTP) Remote / SSL / no local process <code>&lt;-- see Option A&gt;</code> Stdio wrapper Local dev, no SSE, or auth-header issues <code>&lt;-- see Option B&gt;</code> <p>For both options you still need a JWT or Basic auth if the gateway is protected.</p>"},{"location":"using/clients/continue/#option-a-direct-sse","title":"Option A - Direct SSE","text":"<pre><code>// ~/.continue/config.json\n{\n  \"experimental\": {\n    \"modelContextProtocolServer\": {\n      \"transport\": {\n        \"type\": \"sse\",\n        \"url\": \"http://localhost:4444/servers/UUID_OF_SERVER_1/sse\",\n        \"headers\": {\n          \"Authorization\": \"Bearer ${env:MCP_AUTH_TOKEN}\"\n        }\n      }\n    }\n  }\n}\n</code></pre> <p>Generate a token:</p> <pre><code>export MCP_AUTH_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token -u admin --secret my-test-key)\n</code></pre>"},{"location":"using/clients/continue/#option-b-local-stdio-bridge-mcpgatewaywrapper","title":"Option B - Local stdio bridge (<code>mcpgateway.wrapper</code>)","text":"<ol> <li>Install the wrapper (pipx keeps it isolated):</li> </ol> <pre><code>pipx install --include-deps mcp-contextforge-gateway\n</code></pre> <ol> <li>Config in Continue:</li> </ol> <pre><code>{\n  \"experimental\": {\n    \"modelContextProtocolServer\": {\n      \"transport\": {\n        \"type\": \"stdio\",\n        \"command\": \"python3\",\n        \"args\": [\"-m\", \"mcpgateway.wrapper\"],\n        \"env\": {\n          \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444/servers/UUID_OF_SERVER_1\",\n          \"MCP_AUTH_TOKEN\": \"${env:MCP_AUTH_TOKEN}\",\n          \"MCP_TOOL_CALL_TIMEOUT\": \"120\"\n        }\n      }\n    }\n  }\n}\n</code></pre> <p>If you prefer Docker: replace <code>\"command\": \"python3\"</code> with <code>\"command\": \"docker\"</code> and use the same container arguments shown in the Copilot docs.</p>"},{"location":"using/clients/continue/#using-gateway-tools","title":"\ud83e\uddea Using Gateway Tools","text":"<p>Once VS Code restarts:</p> <ol> <li>Open Continue Chat (<code>\u2325 C</code> on macOS / <code>Alt C</code> on Windows/Linux)</li> <li>Click Tools - your gateway's tools should appear</li> <li>Chat naturally:</li> </ol> <pre><code>Run hello_world with name = \"Alice\"\n</code></pre> <p>The wrapper/Gateway executes and streams the JSON result back to Continue.</p>"},{"location":"using/clients/continue/#tips","title":"\ud83d\udcdd Tips","text":"<ul> <li>SSE vs stdio - SSE is simpler in prod, stdio is great for offline or   header-free environments.</li> <li>Multiple servers - add more blocks under <code>\"servers\"</code> if you run staging vs prod.</li> <li>Custom instructions - Continue's Custom Instructions pane lets you steer tool use.</li> </ul>"},{"location":"using/clients/continue/#resources","title":"\ud83d\udcda Resources","text":"<ul> <li>\ud83c\udf10 Continue docs</li> <li>\ud83d\udcd6 MCP Spec</li> <li>\ud83d\udee0 MCP Gateway GitHub</li> </ul>"},{"location":"using/clients/copilot/","title":"\ud83e\udde0 GitHub Copilot + MCP Gateway","text":"<p>Super-charge Copilot (or any VS Code chat agent that speaks MCP) with tools, prompts and resources from your own MCP Gateway.</p> <p>With Copilot \u2192 MCP you can:</p> <ul> <li>\ud83d\udd27 call custom / enterprise tools from chat</li> <li>\ud83d\udcc2 pull live resources (configs, docs, snippets)</li> <li>\ud83e\udde9 render prompts or templates directly inside the IDE</li> </ul> <p>Copilot supports SSE streams out-of-the-box; for environments that forbid long-lived HTTP or require local stdio, you can insert the bundled <code>mcpgateway.wrapper</code> bridge.</p>"},{"location":"using/clients/copilot/#prerequisites","title":"\ud83d\udee0 Prerequisites","text":"<ul> <li>VS Code \u2265 1.99</li> <li><code>\"chat.mcp.enabled\": true</code> in your settings.json</li> <li>An MCP Gateway running (<code>make serve</code>, Docker, or container image)</li> <li>A JWT or Basic credentials (<code>admin</code> / <code>changeme</code> in dev)</li> </ul>"},{"location":"using/clients/copilot/#option-1-direct-sse-best-for-prod-remote","title":"\ud83d\udd17 Option 1 - Direct SSE (best for prod / remote)","text":""},{"location":"using/clients/copilot/#1-create-vscodemcpjson","title":"1 - Create <code>.vscode/mcp.json</code>","text":"<pre><code>{\n  \"servers\": {\n    \"mcp-gateway\": {\n      \"type\": \"sse\",\n      \"url\": \"https://mcpgateway.example.com/servers/UUID_OF_SERVER_1/sse\",\n      \"headers\": {\n        \"Authorization\": \"Bearer &lt;YOUR_JWT_TOKEN&gt;\"\n      }\n    }\n  }\n}\n</code></pre> <p>Tip - generate a token</p> <pre><code>python3 -m mcpgateway.utils.create_jwt_token -u admin --exp 10080 --secret my-test-key\n</code></pre>"},{"location":"using/clients/copilot/#option-2-streamable-http-best-for-prod-remote","title":"\ud83d\udd17 Option 2 - Streamable HTTP (best for prod / remote)","text":""},{"location":"using/clients/copilot/#2-create-vscodemcpjson","title":"2 - Create <code>.vscode/mcp.json</code>","text":"<pre><code>{\n  \"servers\": {\n    \"mcp-gateway\": {\n      \"type\": \"http\",\n      \"url\": \"https://mcpgateway.example.com/servers/UUID_OF_SERVER_1/mcp/\",\n      \"headers\": {\n        \"Authorization\": \"Bearer &lt;YOUR_JWT_TOKEN&gt;\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"using/clients/copilot/#option-3-local-stdio-bridge-mcpgatewaywrapper","title":"\ud83d\udd17 Option 3 - Local stdio bridge (<code>mcpgateway.wrapper</code>)","text":"<p>Perfect when:</p> <ul> <li>the IDE cannot add HTTP headers, or</li> <li>you're offline / behind a corp proxy.</li> </ul>"},{"location":"using/clients/copilot/#1-install-the-wrapper-one-liner","title":"1 - Install the wrapper (one-liner)","text":"<pre><code>pipx install --include-deps mcp-contextforge-gateway          # isolates in ~/.local/pipx/venvs\n#   - or -\nuv pip install mcp-contextforge-gateway                       # inside any uv/venv you like\n</code></pre>"},{"location":"using/clients/copilot/#2-create-vscodemcpjson_1","title":"2 - Create <code>.vscode/mcp.json</code>","text":"<pre><code>{\n  \"servers\": {\n    \"mcp-wrapper\": {\n      \"type\": \"stdio\",\n      \"command\": \"python3\",\n      \"args\": [\"-m\", \"mcpgateway.wrapper\"],\n      \"env\": {\n        \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444/servers/UUID_OF_SERVER_1\",\n        \"MCP_AUTH_TOKEN\": \"&lt;YOUR_JWT_TOKEN&gt;\",\n        \"MCP_TOOL_CALL_TIMEOUT\": \"120\"\n      }\n    }\n  }\n}\n</code></pre> <p>That's it - VS Code spawns the stdio process, pipes JSON-RPC, and you're ready to roll.</p> \ud83d\udc33 Docker alternative <pre><code>{\n  \"command\": \"docker\",\n  \"args\": [\n    \"run\", \"--rm\", \"--network=host\", \"-i\",\n    \"-e\", \"MCP_SERVER_CATALOG_URLS=http://localhost:4444/servers/UUID_OF_SERVER_1\",\n    \"-e\", \"MCP_AUTH_TOKEN=&lt;YOUR_JWT_TOKEN&gt;\",\n    \"ghcr.io/ibm/mcp-context-forge:latest\",\n    \"python3\", \"-m\", \"mcpgateway.wrapper\"\n  ]\n}\n</code></pre>"},{"location":"using/clients/copilot/#verify-inside-copilot","title":"\ud83e\uddea Verify inside Copilot","text":"<ol> <li>Open Copilot Chat \u2192 switch to Agent mode.</li> <li>Click Tools - your Gateway tools should list.</li> <li>Try:</li> </ol> <pre><code>#echo { \"message\": \"Hello from VS Code\" }\n</code></pre> <p>Copilot routes the call \u2192 Gateway \u2192 tool, and prints the reply.</p>"},{"location":"using/clients/copilot/#good-to-know","title":"\ud83d\udcdd Good to know","text":"<ul> <li>Use SSE for production, stdio for local/offline.</li> <li>You can manage servers, tools and prompts from the Gateway Admin UI (<code>/admin</code>).</li> <li>Need a bearer quickly?   <code>export MCP_AUTH_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token -u admin --secret my-test-key)</code></li> </ul>"},{"location":"using/clients/copilot/#further-reading","title":"\ud83d\udcda Further Reading","text":"<ul> <li>Gateway GitHub \u2192 ibm/mcp-context-forge</li> <li>MCP Spec \u2192 https://modelcontextprotocol.io/</li> <li>Copilot docs \u2192 features/copilot</li> </ul>"},{"location":"using/clients/mcp-cli/","title":"\ud83d\udda5\ufe0f MCP CLI + MCP Context Forge Gateway","text":"<p>A powerful, feature-rich command-line interface for interacting with Model Context Protocol servers through IBM's MCP Context Forge Gateway. The mcp-cli provides multiple operational modes including chat, interactive shell, and scriptable automation, with support for multiple LLM providers.</p> <p>With mcp-cli \u2192 MCP Context Forge Gateway you can:</p> <ul> <li>\ud83d\udd27 Auto-discover tools from your MCP Context Forge Gateway and use them seamlessly</li> <li>\ud83d\udd04 Switch between providers (OpenAI, Anthropic, Ollama) during sessions</li> <li>\ud83d\udcca Export conversation history to JSON for analysis and debugging</li> <li>\ud83e\udd16 Chat with LLMs that automatically invoke Gateway tools and resources</li> <li>\ud83d\udcdc Automate workflows with scriptable command-line operations</li> <li>\ud83d\udee0\ufe0f Compare modes - chat vs. interactive vs. command-line automation</li> </ul> <p>The mcp-cli supports stdio connections out-of-the-box through the bundled <code>mcpgateway.wrapper</code> bridge, with optional direct SSE access for production environments.</p>"},{"location":"using/clients/mcp-cli/#prerequisites","title":"\ud83d\udee0 Prerequisites","text":"<ul> <li>Python \u2265 3.11</li> <li>uv (recommended) or pip for dependency management</li> <li>MCP Context Forge Gateway running locally or remotely (default: http://localhost:4444)</li> <li>JWT or Basic Auth credentials for Gateway access</li> <li>LLM Provider API keys (optional, for chat mode):</li> <li>OpenAI: <code>OPENAI_API_KEY</code> environment variable</li> <li>Anthropic: <code>ANTHROPIC_API_KEY</code> environment variable</li> <li>Ollama: Local Ollama installation with function-calling capable models</li> </ul>"},{"location":"using/clients/mcp-cli/#installation","title":"\ud83d\ude80 Installation","text":""},{"location":"using/clients/mcp-cli/#install-mcp-cli","title":"Install MCP CLI","text":"<pre><code>git clone https://github.com/chrishayuk/mcp-cli\ncd mcp-cli\npip install -e \".[cli,dev]\"\n</code></pre>"},{"location":"using/clients/mcp-cli/#using-uv-recommended","title":"Using UV (Recommended)","text":"<pre><code># Install UV if not already installed\npip install uv\n\n# Clone and install\ngit clone https://github.com/chrishayuk/mcp-cli\ncd mcp-cli\nuv sync --reinstall\n\n# Run using UV\nuv run mcp-cli --help\n</code></pre>"},{"location":"using/clients/mcp-cli/#install-mcp-context-forge-gateway","title":"Install MCP Context Forge Gateway","text":"<pre><code># Clone the MCP Context Forge repository\ngit clone https://github.com/IBM/mcp-context-forge\ncd mcp-context-forge\n\n# Install and start the gateway\nmake venv install serve\n# Gateway will be available at http://localhost:4444\n</code></pre>"},{"location":"using/clients/mcp-cli/#configuring-your-server","title":"\u2699\ufe0f Configuring Your Server","text":"<p>Create a <code>server_config.json</code> file to define your MCP Context Forge Gateway connection:</p>"},{"location":"using/clients/mcp-cli/#basic-configuration-local-development","title":"Basic Configuration (Local Development)","text":"<pre><code>{\n  \"mcpServers\": {\n    \"mcpgateway-wrapper\": {\n      \"command\": \"/path/to/mcp-context-forge/.venv/bin/python\",\n      \"args\": [\"-m\", \"mcpgateway.wrapper\"],\n      \"env\": {\n        \"MCP_AUTH_TOKEN\": \"&lt;YOUR_AUTH_TOKEN_HERE&gt;\",\n        \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444\",\n        \"MCP_TOOL_CALL_TIMEOUT\": \"120\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"using/clients/mcp-cli/#docker-based-configuration-production","title":"Docker-based Configuration (Production)","text":"<pre><code>{\n  \"mcpServers\": {\n    \"mcpgateway-wrapper\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"-e\",\n        \"MCP_SERVER_CATALOG_URLS=http://host.docker.internal:4444\",\n        \"-e\",\n        \"MCP_AUTH_TOKEN=${MCPGATEWAY_BEARER_TOKEN}\",\n        \"--entrypoint\",\n        \"uv\",\n        \"ghcr.io/ibm/mcp-context-forge:latest\",\n        \"run\",\n        \"--directory\",\n        \"mcpgateway-wrapper\",\n        \"mcpgateway-wrapper\"\n      ],\n      \"env\": {\n        \"MCPGATEWAY_BEARER_TOKEN\": \"your-jwt-token-here\"\n      }\n    }\n  }\n}\n</code></pre> <p>\ud83d\udca1 Generate a JWT token for your Gateway</p> <pre><code># From your mcp-context-forge directory\npython3 -m mcpgateway.utils.create_jwt_token -u admin --exp 10080 --secret my-test-key\n</code></pre> <p>\u26a0\ufe0f Important Notes - Use the full path to your virtual environment's Python to avoid import errors - Make sure your MCP Context Forge Gateway is running on the correct port (default: 4444) - The wrapper requires <code>MCP_SERVER_CATALOG_URLS</code> environment variable</p>"},{"location":"using/clients/mcp-cli/#available-modes","title":"\ud83c\udf10 Available Modes","text":""},{"location":"using/clients/mcp-cli/#1-chat-mode-default","title":"1. Chat Mode (Default)","text":"<p>Natural language interface where LLMs automatically use available tools:</p> <pre><code># Default chat mode with OpenAI\nexport OPENAI_API_KEY=\"your-api-key\"\nmcp-cli chat --server mcpgateway-wrapper\n\n# Using Ollama (recommended to avoid OpenAI tool name length limits)\nmcp-cli chat --server mcpgateway-wrapper --provider ollama --model mistral-nemo:latest\n\n# Using Anthropic\nexport ANTHROPIC_API_KEY=\"your-api-key\"\nmcp-cli chat --server mcpgateway-wrapper --provider anthropic --model claude-sonnet-4-20250514\n</code></pre>"},{"location":"using/clients/mcp-cli/#2-interactive-mode","title":"2. Interactive Mode","text":"<p>Command-driven shell interface for direct server operations:</p> <pre><code>mcp-cli interactive --server mcpgateway-wrapper\n</code></pre>"},{"location":"using/clients/mcp-cli/#3-command-mode","title":"3. Command Mode","text":"<p>Unix-friendly interface for automation and pipeline integration:</p> <pre><code># Process content with LLM\nmcp-cli cmd --server mcpgateway-wrapper --input document.md --prompt \"Summarize: {{input}}\"\n\n# Direct tool invocation\nmcp-cli cmd --server mcpgateway-wrapper --tool github-server-list-notifications --raw\n\n# Search for GitHub issues\nmcp-cli cmd --server mcpgateway-wrapper --tool github-server-search-issues --tool-args '{\"q\":\"assignee:@me\"}' --raw\n</code></pre>"},{"location":"using/clients/mcp-cli/#4-direct-commands","title":"4. Direct Commands","text":"<p>Run individual commands without entering interactive mode:</p> <pre><code># List available tools\nmcp-cli tools list --server mcpgateway-wrapper\n\n# Ping the gateway\nmcp-cli ping --server mcpgateway-wrapper\n\n# List available prompts\nmcp-cli prompts list --server mcpgateway-wrapper\n\n# List available resources\nmcp-cli resources list --server mcpgateway-wrapper\n</code></pre>"},{"location":"using/clients/mcp-cli/#verify-tool-discovery","title":"\ud83e\uddea Verify Tool Discovery","text":"<p>Once connected to your MCP Context Forge Gateway, mcp-cli automatically discovers all available tools:</p> <ol> <li>Test connection: <code>mcp-cli ping --server mcpgateway-wrapper</code></li> <li>List tools: <code>mcp-cli tools list --server mcpgateway-wrapper</code></li> <li>Start Chat Mode: <code>mcp-cli chat --server mcpgateway-wrapper --provider ollama --model mistral-nemo:latest</code></li> <li>Type <code>/tools</code> - your Gateway tools should list automatically</li> <li>Try asking: <code>\"What tools are available?\"</code> and the LLM will show discovered tools</li> <li>Test GitHub integration: <code>\"What issues have been assigned to me?\"</code></li> </ol> <p>The CLI auto-discovers tools from your Gateway and makes them available across all modes.</p>"},{"location":"using/clients/mcp-cli/#llm-provider-setup","title":"\ud83d\udd27 LLM Provider Setup","text":""},{"location":"using/clients/mcp-cli/#openai-has-64-character-tool-name-limitation","title":"OpenAI (Has 64-character tool name limitation)","text":"<pre><code>export OPENAI_API_KEY=\"sk-your-api-key-here\"\nmcp-cli chat --server mcpgateway-wrapper --provider openai --model gpt-4o-mini\n</code></pre> <p>\u26a0\ufe0f Known Issue: OpenAI has a 64-character limit for tool names, but some MCP Context Forge tools exceed this limit (e.g., <code>github-server-add-pull-request-review-comment-to-pending-review</code> is 69 characters).</p>"},{"location":"using/clients/mcp-cli/#ollama-recommended-no-tool-name-limitations","title":"Ollama (Recommended - No tool name limitations)","text":"<pre><code># Install Ollama\ncurl -fsSL https://ollama.ai/install.sh | sh\n\n# Pull a function-calling capable model\nollama pull mistral-nemo:latest\n# or\nollama pull llama3.2:latest\n\n# Use with mcp-cli\nmcp-cli chat --server mcpgateway-wrapper --provider ollama --model mistral-nemo:latest\n</code></pre>"},{"location":"using/clients/mcp-cli/#anthropic-claude","title":"Anthropic Claude","text":"<pre><code>export ANTHROPIC_API_KEY=\"sk-ant-your-api-key-here\"\nmcp-cli chat --server mcpgateway-wrapper --provider anthropic --model claude-3-sonnet\n</code></pre>"},{"location":"using/clients/mcp-cli/#basic-usage","title":"\ud83e\uddea Basic Usage","text":""},{"location":"using/clients/mcp-cli/#chat-mode-commands","title":"Chat Mode Commands","text":"<p>In chat mode, use these slash commands for enhanced functionality:</p>"},{"location":"using/clients/mcp-cli/#general-commands","title":"General Commands","text":"<ul> <li><code>/help</code> - Show available commands</li> <li><code>/quickhelp</code> or <code>/qh</code> - Quick reference guide</li> <li><code>exit</code> or <code>quit</code> - Exit chat mode</li> </ul>"},{"location":"using/clients/mcp-cli/#provider-model-management","title":"Provider &amp; Model Management","text":"<ul> <li><code>/provider</code> - Show current provider and model</li> <li><code>/provider list</code> - List all configured providers</li> <li><code>/provider &lt;name&gt;</code> - Switch to different provider</li> <li><code>/model &lt;name&gt;</code> - Switch to different model</li> </ul>"},{"location":"using/clients/mcp-cli/#tool-management","title":"Tool Management","text":"<ul> <li><code>/tools</code> - Display all available tools from your Gateway</li> <li><code>/tools --all</code> - Show detailed tool information</li> <li><code>/toolhistory</code> or <code>/th</code> - Show tool call history</li> </ul>"},{"location":"using/clients/mcp-cli/#conversation-management","title":"Conversation Management","text":"<ul> <li><code>/conversation</code> or <code>/ch</code> - Show conversation history</li> <li><code>/save &lt;filename&gt;</code> - Save conversation to JSON file</li> <li><code>/compact</code> - Condense conversation history</li> </ul>"},{"location":"using/clients/mcp-cli/#example-chat-interactions","title":"Example Chat Interactions","text":"<pre><code>&gt; what issues have been assigned to me?\n[Tool Call: github-server-get-me]\n[Tool Call: github-server-search-issues with q=\"assignee:username\"]\n\n&gt; what files are in my Downloads folder?\n[Tool Call: filesystem-downloads-list-directory]\n\n&gt; create a memory about this conversation\n[Tool Call: memory-server-store-memory]\n\n&gt; what time is it in London?\n[Tool Call: time-server-get-system-time with timezone=\"Europe/London\"]\n</code></pre>"},{"location":"using/clients/mcp-cli/#interactive-mode-commands","title":"Interactive Mode Commands","text":"<p>In interactive mode, use these commands:</p> <ul> <li><code>/help</code> - Show available commands</li> <li><code>/tools</code> or <code>/t</code> - List/call tools interactively</li> <li><code>/resources</code> or <code>/res</code> - List available resources</li> <li><code>/prompts</code> or <code>/p</code> - List available prompts</li> <li><code>/servers</code> or <code>/srv</code> - List connected servers</li> <li><code>/ping</code> - Ping connected servers</li> </ul>"},{"location":"using/clients/mcp-cli/#command-mode-options","title":"Command Mode Options","text":"<ul> <li><code>--input</code> - Input file path (use <code>-</code> for stdin)</li> <li><code>--output</code> - Output file path (use <code>-</code> for stdout)</li> <li><code>--prompt</code> - Prompt template with <code>{{input}}</code> placeholder</li> <li><code>--tool</code> - Directly call a specific tool</li> <li><code>--tool-args</code> - JSON arguments for tool call</li> <li><code>--provider</code> - Specify LLM provider</li> <li><code>--model</code> - Specify model to use</li> <li><code>--raw</code> - Output raw response without formatting</li> </ul>"},{"location":"using/clients/mcp-cli/#advanced-configuration","title":"\ud83d\udd27 Advanced Configuration","text":""},{"location":"using/clients/mcp-cli/#environment-variables","title":"Environment Variables","text":"<pre><code># MCP Context Forge Gateway connection\nexport MCP_AUTH_TOKEN=\"your-jwt-token\"\nexport MCP_SERVER_CATALOG_URLS=\"http://localhost:4444\"\n\n# LLM Provider API keys\nexport OPENAI_API_KEY=\"sk-your-openai-key\"\nexport ANTHROPIC_API_KEY=\"sk-ant-your-anthropic-key\"\n\n# Default provider settings\nexport LLM_PROVIDER=\"ollama\"\nexport LLM_MODEL=\"mistral-nemo:latest\"\n</code></pre>"},{"location":"using/clients/mcp-cli/#troubleshooting-common-issues","title":"Troubleshooting Common Issues","text":""},{"location":"using/clients/mcp-cli/#modulenotfounderror-no-module-named-mcpgateway","title":"\"ModuleNotFoundError: No module named 'mcpgateway'\"","text":"<p>Solution: Use the full path to your virtual environment's Python:</p> <pre><code>{\n  \"mcpServers\": {\n    \"mcpgateway-wrapper\": {\n      \"command\": \"/Users/username/path/to/mcp-context-forge/.venv/bin/python\",\n      \"args\": [\"-m\", \"mcpgateway.wrapper\"],\n      \"env\": { ... }\n    }\n  }\n}\n</code></pre>"},{"location":"using/clients/mcp-cli/#mcp_server_catalog_urls-environment-variable-is-required","title":"\"MCP_SERVER_CATALOG_URLS environment variable is required\"","text":"<p>Solution: Ensure your <code>server_config.json</code> includes the required environment variables in the <code>env</code> section.</p>"},{"location":"using/clients/mcp-cli/#openai-tool-name-length-error","title":"OpenAI Tool Name Length Error","text":"<p>Error: <code>string too long. Expected a string with maximum length 64</code></p> <p>Solution: Use Ollama or Anthropic instead:</p> <pre><code>mcp-cli chat --server mcpgateway-wrapper --provider ollama --model mistral-nemo:latest\n</code></pre>"},{"location":"using/clients/mcp-cli/#model-doesnt-support-tools","title":"Model doesn't support tools","text":"<p>Error: <code>does not support tools (status code: 400)</code></p> <p>Solution: Use a function-calling capable model:</p> <pre><code># Pull compatible models\nollama pull mistral-nemo:latest\nollama pull llama3.2:latest\n\n# Use in mcp-cli\nmcp-cli chat --server mcpgateway-wrapper --provider ollama --model mistral-nemo:latest\n</code></pre>"},{"location":"using/clients/mcp-cli/#advanced-usage-examples","title":"\ud83d\udcc8 Advanced Usage Examples","text":""},{"location":"using/clients/mcp-cli/#github-integration","title":"GitHub Integration","text":"<pre><code># Get your GitHub profile\nmcp-cli cmd --server mcpgateway-wrapper --tool github-server-get-me --raw\n\n# List notifications\nmcp-cli cmd --server mcpgateway-wrapper --tool github-server-list-notifications --raw\n\n# Search for issues assigned to you\nmcp-cli cmd --server mcpgateway-wrapper --tool github-server-search-issues \\\n  --tool-args '{\"q\":\"assignee:@me is:open\"}' --raw\n\n# Create a new issue\nmcp-cli cmd --server mcpgateway-wrapper --tool github-server-create-issue \\\n  --tool-args '{\"owner\":\"username\",\"repo\":\"repository\",\"title\":\"New Issue\",\"body\":\"Issue description\"}' --raw\n</code></pre>"},{"location":"using/clients/mcp-cli/#file-system-operations","title":"File System Operations","text":"<pre><code># List allowed directories\nmcp-cli cmd --server mcpgateway-wrapper --tool filesystem-downloads-list-allowed-directories --raw\n\n# Read a file\nmcp-cli cmd --server mcpgateway-wrapper --tool filesystem-downloads-read-file \\\n  --tool-args '{\"path\":\"/path/to/file.txt\"}' --raw\n\n# Search for files\nmcp-cli cmd --server mcpgateway-wrapper --tool filesystem-downloads-search-files \\\n  --tool-args '{\"path\":\"/Users/username/Downloads\",\"pattern\":\"*.pdf\"}' --raw\n</code></pre>"},{"location":"using/clients/mcp-cli/#memory-management","title":"Memory Management","text":"<pre><code># Store a memory\nmcp-cli cmd --server mcpgateway-wrapper --tool memory-server-store-memory \\\n  --tool-args '{\"content\":\"Important project note\",\"bucket\":\"work\"}' --raw\n\n# Get memories\nmcp-cli cmd --server mcpgateway-wrapper --tool memory-server-get-memories \\\n  --tool-args '{\"bucket\":\"work\"}' --raw\n</code></pre>"},{"location":"using/clients/mcp-cli/#time-operations","title":"Time Operations","text":"<pre><code># Get current time\nmcp-cli cmd --server mcpgateway-wrapper --tool time-server-get-system-time --raw\n\n# Convert time zones\nmcp-cli cmd --server mcpgateway-wrapper --tool time-server-convert-time \\\n  --tool-args '{\"from_timezone\":\"UTC\",\"to_timezone\":\"America/New_York\",\"time\":\"2025-01-01T12:00:00Z\"}' --raw\n</code></pre>"},{"location":"using/clients/mcp-cli/#integration-with-mcp-context-forge-gateway","title":"\ud83d\udd17 Integration with MCP Context Forge Gateway","text":"<p>The mcp-cli integrates with MCP Context Forge Gateway through multiple connection methods:</p>"},{"location":"using/clients/mcp-cli/#local-development-setup","title":"Local Development Setup","text":"<ol> <li> <p>Start the Gateway: <pre><code>cd mcp-context-forge\nmake serve  # Starts on http://localhost:4444\n</code></pre></p> </li> <li> <p>Configure mcp-cli: <pre><code>{\n  \"mcpServers\": {\n    \"mcpgateway-wrapper\": {\n      \"command\": \"/path/to/mcp-context-forge/.venv/bin/python\",\n      \"args\": [\"-m\", \"mcpgateway.wrapper\"],\n      \"env\": {\n        \"MCP_AUTH_TOKEN\": \"your-jwt-token\",\n        \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444\"\n      }\n    }\n  }\n}\n</code></pre></p> </li> <li> <p>Test the connection: <pre><code>mcp-cli ping --server mcpgateway-wrapper\n</code></pre></p> </li> </ol>"},{"location":"using/clients/mcp-cli/#production-docker-setup","title":"Production Docker Setup","text":"<p>Use the official Docker image for production environments:</p> <pre><code># Start the gateway\ndocker run -d --name mcpgateway \\\n  -p 4444:4444 \\\n  -e HOST=0.0.0.0 \\\n  -e JWT_SECRET_KEY=my-secret-key \\\n  -e BASIC_AUTH_USER=admin \\\n  -e BASIC_AUTH_PASSWORD=changeme \\\n  ghcr.io/ibm/mcp-context-forge:latest\n\n# Generate token\nexport MCPGATEWAY_BEARER_TOKEN=$(docker exec mcpgateway python3 -m mcpgateway.utils.create_jwt_token --username admin --exp 10080 --secret my-secret-key)\n\n# Test connection\ncurl -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" http://localhost:4444/tools\n</code></pre>"},{"location":"using/clients/mcp-cli/#available-tool-categories","title":"\ud83d\udcdd Available Tool Categories","text":"<p>Your MCP Context Forge Gateway provides these tool categories:</p>"},{"location":"using/clients/mcp-cli/#filesystem-tools","title":"\ud83d\uddc2\ufe0f Filesystem Tools","text":"<ul> <li>Downloads &amp; Documents: Read, write, edit, search files</li> <li>Directory Operations: List, create, move files and directories</li> <li>File Management: Get file info, create directory trees</li> </ul>"},{"location":"using/clients/mcp-cli/#github-integration_1","title":"\ud83d\udc19 GitHub Integration","text":"<ul> <li>Issue Management: Create, update, list, search issues</li> <li>Pull Requests: Create, review, merge, comment on PRs</li> <li>Repository Operations: Fork, create, manage repositories</li> <li>Notifications: List, manage, dismiss notifications</li> <li>Code Analysis: Search code, get commits, manage branches</li> </ul>"},{"location":"using/clients/mcp-cli/#memory-server","title":"\ud83e\udde0 Memory Server","text":"<ul> <li>Memory Storage: Store and retrieve contextual memories</li> <li>Bucket Management: Organize memories in buckets</li> <li>Memory Querying: Search and filter stored memories</li> </ul>"},{"location":"using/clients/mcp-cli/#time-operations_1","title":"\u23f0 Time Operations","text":"<ul> <li>System Time: Get current time in any timezone</li> <li>Time Conversion: Convert between different timezones</li> </ul>"},{"location":"using/clients/mcp-cli/#features-comparison","title":"\ud83d\udcca Features Comparison","text":"Feature Chat Mode Interactive Mode Command Mode Natural language interface \u2705 \u274c \u274c Automatic tool usage \u2705 \u274c \u274c Direct tool invocation \u274c \u2705 \u2705 Scriptable automation \u274c \u274c \u2705 Conversation history \u2705 \u274c \u274c Provider switching \u2705 \u2705 \u2705 Batch processing \u274c \u274c \u2705 Pipeline integration \u274c \u274c \u2705 GitHub integration \u2705 \u2705 \u2705 File system access \u2705 \u2705 \u2705"},{"location":"using/clients/mcp-cli/#further-reading","title":"\ud83d\udcda Further Reading","text":"<ul> <li>mcp-cli GitHub \u2192 chrishayuk/mcp-cli</li> <li>CHUK-MCP Protocol \u2192 chrishayuk/chuk-mcp</li> <li>MCP Context Forge Gateway \u2192 IBM/mcp-context-forge</li> <li>MCP Specification \u2192 https://modelcontextprotocol.io/</li> </ul>"},{"location":"using/clients/mcp-cli/#quick-start-checklist","title":"\ud83c\udfaf Quick Start Checklist","text":"<ul> <li> Install mcp-cli: <code>pip install -e \".[cli,dev]\"</code></li> <li> Install MCP Context Forge Gateway</li> <li> Start gateway: <code>make serve</code> (runs on localhost:4444)</li> <li> Create <code>server_config.json</code> with correct Python path</li> <li> Generate JWT token for authentication</li> <li> Test connection: <code>mcp-cli ping --server mcpgateway-wrapper</code></li> <li> Install Ollama and pull a compatible model (recommended)</li> <li> Start chat: <code>mcp-cli chat --server mcpgateway-wrapper --provider ollama --model mistral-nemo:latest</code></li> <li> Try asking: \"What tools are available?\" or \"What issues have been assigned to me?\"</li> </ul>"},{"location":"using/clients/mcp-inspector/","title":"MCP Inspector","text":"<p>MCP Inspector is a visual debugging GUI for the Model Context Protocol. Point it at any MCP-compliant endpoint \u2014 a live Gateway SSE stream or a local <code>mcpgateway.wrapper</code> stdio server \u2014 and you can:</p> <ul> <li>\ud83d\udd0d Browse tools, prompts and resources in real time</li> <li>\ud83d\udee0 Invoke tools with JSON params and inspect raw results</li> <li>\ud83d\udcdc Watch the full bidirectional JSON-RPC / MCP traffic live</li> <li>\ud83d\udd04 Replay or edit previous requests</li> <li>\ud83d\udcac Stream sampling messages (where supported)</li> </ul>"},{"location":"using/clients/mcp-inspector/#quick-launch-recipes","title":"\ud83d\ude80 Quick launch recipes","text":"<p>All commands use npx (bundled with Node \u2265 14). Feel free to <code>npm install -g @modelcontextprotocol/inspector</code> for a global binary.</p> Use-case One-liner What happens 1. Connect to Gateway (SSE) <code>bash&lt;br/&gt;npx @modelcontextprotocol/inspector \\\\&lt;br/&gt;  --url http://localhost:4444/servers/UUID_OF_SERVER_1/sse \\\\&lt;br/&gt;  --header \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\"&lt;br/&gt;</code> Inspector opens <code>http://localhost:5173</code> and attaches directly to the gateway stream. 2. Connect to Gateway (Streamable HTTP) <code>bash&lt;br/&gt;npx @modelcontextprotocol/inspector \\\\&lt;br/&gt;  --url http://localhost:4444/servers/UUID_OF_SERVER_1/mcp/ \\\\&lt;br/&gt;  --header \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\"&lt;br/&gt;</code> Inspector opens <code>http://localhost:5173</code> and attaches directly to the gateway stream. 3 - Spin up the stdio wrapper in-process <code>bash&lt;br/&gt;export MCP_AUTH_TOKEN=$MCPGATEWAY_BEARER_TOKEN&lt;br/&gt;export MCP_SERVER_CATALOG_URLS=http://localhost:4444/servers/UUID_OF_SERVER_1&lt;br/&gt;&lt;br/&gt;npx @modelcontextprotocol/inspector \\\\&lt;br/&gt;  python3 -m mcpgateway.wrapper&lt;br/&gt;</code> Inspector forks <code>python3 -m mcpgateway.wrapper</code>, then connects to its stdio port automatically. 4 - Same, but via uv / uvx <code>bash&lt;br/&gt;npx @modelcontextprotocol/inspector \\\\&lt;br/&gt;  uvx python3 -m mcpgateway.wrapper&lt;br/&gt;</code> Uses the super-fast uv virtual-env if you prefer. 5 - Wrapper already running Launch the wrapper in another shell, then:<code>bash&lt;br/&gt;npx @modelcontextprotocol/inspector --stdio&lt;br/&gt;</code> Inspector only opens the GUI and binds to the running stdio server on stdin/stdout."},{"location":"using/clients/mcp-inspector/#environment-variables","title":"\ud83d\udd10 Environment variables","text":"<p>Most wrappers / servers will need at least:</p> <pre><code>export MCP_SERVER_CATALOG_URLS=http://localhost:4444/servers/UUID_OF_SERVER_1   # one or many\nexport MCP_AUTH_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token -u admin --secret my-test-key)\n</code></pre> <p>If you point Inspector directly at a Gateway SSE stream, pass the header:</p> <pre><code>--header \"Authorization: Bearer $MCP_AUTH_TOKEN\"\n</code></pre>"},{"location":"using/clients/mcp-inspector/#inspector-highlights","title":"\ud83d\udd27 Inspector Highlights","text":"<ul> <li>Real-time catalogue - tools/prompts/resources update as soon as the Gateway sends <code>*Changed</code> notifications.</li> <li>Request builder - JSON editor with schema hints (if the tool exposes an <code>inputSchema</code>).</li> <li>Traffic console - colour-coded view of every request &amp; reply; copy as cURL.</li> <li>Replay &amp; edit - click any previous call, tweak parameters, re-send.</li> <li>Streaming - see <code>sampling/createMessage</code> chunks scroll by live (MCP 2025-03-26 spec).</li> </ul>"},{"location":"using/clients/mcp-inspector/#connecting-through-supergateway-stdio-sse-bridge","title":"\ud83d\udef0 Connecting through SuperGateway (stdio \u2192 SSE bridge)","text":"<p>Want to test a stdio-only MCP server inside Inspector?</p> <pre><code># Example: expose mcp-server-git over SSE on :8000\nnpx -y supergateway --stdio \"uvx mcp-server-git\"\n#   SSE stream:  http://localhost:8000/sse\n#   POST back-channel: http://localhost:8000/message\n</code></pre> <p>Then simply start Inspector:</p> <pre><code>npx @modelcontextprotocol/inspector \\\n  --url http://localhost:8000/sse\n</code></pre> <p>SuperGateway handles the bridging; Inspector thinks it is speaking native SSE.</p>"},{"location":"using/clients/openwebui/","title":"OpenWebUI Integration with MCP Gateway","text":"<p>OpenWebUI is a self-hosted, extensible interface for interacting with large language models (LLMs). Integrating OpenWebUI with the Model Context Protocol (MCP) allows you to enhance your AI workflows by leveraging tools and resources provided by MCP servers.</p>"},{"location":"using/clients/openwebui/#integration-overview","title":"\ud83d\udd0c Integration Overview","text":"<p>OpenWebUI supports integration with external tools via OpenAPI specifications. MCP Gateway exposes its tools through OpenAPI-compatible endpoints, enabling seamless integration with OpenWebUI.</p>"},{"location":"using/clients/openwebui/#prerequisites","title":"\ud83d\udee0\ufe0f Prerequisites","text":"<ul> <li>OpenWebUI: Ensure you have OpenWebUI installed and running. Refer to the OpenWebUI documentation for installation instructions.</li> <li>MCP Gateway: Set up and run the MCP Gateway. Detailed setup instructions can be found in the MCP Gateway documentation.</li> </ul>"},{"location":"using/clients/openwebui/#connecting-mcp-tools-to-openwebui","title":"\ud83d\udd17 Connecting MCP Tools to OpenWebUI","text":""},{"location":"using/clients/openwebui/#1-launch-mcp-gateway","title":"1. Launch MCP Gateway","text":"<p>Start the MCP Gateway to expose its tools via OpenAPI endpoints. For example:</p> <pre><code>uv run mcpgateway\n</code></pre> <p>Ensure that the MCP Gateway is accessible at a known URL, such as <code>http://localhost:4444</code>.</p>"},{"location":"using/clients/openwebui/#2-identify-mcp-tool-endpoints","title":"2. Identify MCP Tool Endpoints","text":"<p>Determine the specific tool endpoints provided by the MCP Gateway. These endpoints follow the OpenAPI specification and are typically accessible at URLs like:</p> <pre><code>http://localhost:4444/tools/&lt;tool-name&gt;\n</code></pre> <p>Replace <code>&lt;tool-name&gt;</code> with the actual name of the tool you wish to integrate.</p>"},{"location":"using/clients/openwebui/#3-add-mcp-tools-to-openwebui","title":"3. Add MCP Tools to OpenWebUI","text":""},{"location":"using/clients/openwebui/#a-access-openwebui-settings","title":"a. Access OpenWebUI Settings","text":"<ul> <li>Navigate to the OpenWebUI interface in your browser.</li> <li>Click on the \u2699\ufe0f Settings icon.</li> </ul>"},{"location":"using/clients/openwebui/#b-add-a-new-tool-server","title":"b. Add a New Tool Server","text":"<ul> <li>In the Settings menu, locate the Tools section.</li> <li>Click on the \u2795 Add Tool Server button.</li> <li>Enter the URL of the MCP tool endpoint (e.g., <code>http://localhost:4444/tools/&lt;tool-name&gt;</code>).</li> <li>Click Save to register the tool.</li> </ul> <p>Repeat this process for each MCP tool you wish to integrate.</p>"},{"location":"using/clients/openwebui/#using-mcp-tools-in-openwebui","title":"\ud83e\uddea Using MCP Tools in OpenWebUI","text":"<p>Once the MCP tools are registered:</p> <ul> <li>Enable Tools in Chat: In the chat interface, click on the \u2795 icon to view available tools. Toggle the desired MCP tools to enable them for the current session.</li> <li>Invoke Tools: Interact with the AI model as usual. When appropriate, the model will utilize the enabled MCP tools to fulfill your requests.</li> </ul>"},{"location":"using/clients/openwebui/#advanced-configuration","title":"\u2699\ufe0f Advanced Configuration","text":""},{"location":"using/clients/openwebui/#global-tool-servers","title":"Global Tool Servers","text":"<p>To make MCP tools available to all users:</p> <ul> <li>Navigate to Admin Settings &gt; Tools.</li> <li>Add the MCP tool endpoints as described above.</li> <li>These tools will now be accessible to all users, subject to individual activation in their chat sessions.</li> </ul>"},{"location":"using/clients/openwebui/#native-function-calling","title":"Native Function Calling","text":"<p>OpenWebUI supports native function calling for tools:</p> <ul> <li>In the chat interface, go to Chat Controls &gt; Advanced Params.</li> <li>Set the Function Calling parameter to <code>Native</code>.</li> <li>This enables more structured interactions between the AI model and the tools.</li> </ul>"},{"location":"using/clients/openwebui/#additional-resources","title":"\ud83e\uddf0 Additional Resources","text":"<ul> <li>OpenWebUI Documentation</li> <li>MCP Gateway Documentation</li> <li>OpenWebUI GitHub Repository</li> <li>MCP Gateway GitHub Repository</li> </ul> <p>By integrating MCP tools into OpenWebUI, you can enhance your AI assistant's capabilities, enabling it to perform a wider range of tasks by leveraging the diverse tools provided by the MCP ecosystem.</p>"},{"location":"using/servers/","title":"\ud83c\udfaf Sample MCP Servers","text":"<p>The MCP Context Forge Gateway includes a collection of high-performance sample MCP servers built in different programming languages. These servers serve multiple purposes: demonstrating best practices for MCP implementation, providing ready-to-use tools for testing and development, and showcasing the performance characteristics of different language ecosystems.</p> <p>Perfect for testing, learning, and production use - each server is optimized for speed, reliability, and demonstrates language-specific MCP patterns.</p>"},{"location":"using/servers/#available-servers","title":"\ud83c\udf1f Available Servers","text":""},{"location":"using/servers/#fast-time-server-go","title":"\ud83e\uddab Fast Time Server (Go)","text":"<p><code>mcp-servers/go/fast-time-server</code> - Ultra-fast timezone and time conversion tools</p> <ul> <li>Language: Go 1.21+</li> <li>Performance: Sub-millisecond response times</li> <li>Transport: stdio, HTTP, SSE, dual-mode</li> <li>Tools: <code>get_system_time</code>, timezone conversions with DST support</li> <li>Container: <code>ghcr.io/ibm/fast-time-server:latest</code></li> </ul> <p>\ud83d\udcd6 Full Documentation \u2192</p>"},{"location":"using/servers/#quick-start","title":"Quick Start","text":"<pre><code># Docker (recommended)\ndocker run --rm -it -p 8888:8080 \\\n  ghcr.io/ibm/fast-time-server:latest \\\n  -transport=dual -log-level=debug\n\n# From source\ncd mcp-servers/go/fast-time-server\nmake build &amp;&amp; make run\n</code></pre>"},{"location":"using/servers/#coming-soon","title":"\ud83d\ude80 Coming Soon","text":""},{"location":"using/servers/#python-samples","title":"\ud83d\udc0d Python Samples","text":"<ul> <li>Fast Calculator Server - Mathematical operations and conversions</li> <li>System Info Server - OS and hardware information tools</li> <li>File Operations Server - Safe file system operations</li> </ul>"},{"location":"using/servers/#javascripttypescript-samples","title":"\ud83d\udfe8 JavaScript/TypeScript Samples","text":"<ul> <li>Web Scraper Server - URL content extraction and parsing</li> <li>JSON Transformer Server - Data transformation and validation</li> <li>API Client Server - REST API interaction tools</li> </ul>"},{"location":"using/servers/#rust-samples","title":"\ud83e\udd80 Rust Samples","text":"<ul> <li>High-Performance Parser Server - Ultra-fast text and data parsing</li> <li>Crypto Utils Server - Cryptographic operations and hashing</li> <li>Network Tools Server - Network diagnostics and utilities</li> </ul>"},{"location":"using/servers/#java-samples","title":"\u2615 Java Samples","text":"<ul> <li>Enterprise Integration Server - Database and messaging operations</li> <li>Document Processor Server - PDF and office document handling</li> <li>Monitoring Server - Application metrics and health checks</li> </ul>"},{"location":"using/servers/#use-cases","title":"\ud83c\udfaf Use Cases","text":""},{"location":"using/servers/#testing-development","title":"\ud83e\uddea Testing &amp; Development","text":"<ul> <li>Protocol Testing - Validate MCP client implementations</li> <li>Performance Benchmarking - Compare language runtime characteristics</li> <li>Integration Testing - Test gateway federation and tool routing</li> </ul>"},{"location":"using/servers/#learning-reference","title":"\ud83d\udcda Learning &amp; Reference","text":"<ul> <li>Best Practices - Language-specific MCP implementation patterns</li> <li>Architecture Examples - Different transport and authentication approaches</li> <li>Performance Optimization - Learn optimization techniques per language</li> </ul>"},{"location":"using/servers/#production-ready","title":"\ud83c\udfed Production Ready","text":"<ul> <li>Horizontal Scaling - All servers support container orchestration</li> <li>Monitoring Integration - Built-in health checks and metrics</li> <li>Security Hardened - Authentication, input validation, and safe defaults</li> </ul>"},{"location":"using/servers/#gateway-integration","title":"\ud83c\udf10 Gateway Integration","text":"<p>All sample servers are designed to integrate seamlessly with the MCP Gateway:</p>"},{"location":"using/servers/#direct-registration","title":"Direct Registration","text":"<pre><code># Register any sample server with the gateway\ncurl -X POST -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"name\":\"sample_server\",\"url\":\"http://localhost:8080/sse\"}' \\\n     http://localhost:4444/gateways\n</code></pre>"},{"location":"using/servers/#via-supergateway-bridge","title":"Via Supergateway Bridge","text":"<pre><code># Expose stdio servers over SSE\nnpx -y supergateway --stdio \"path/to/sample-server\" --port 8002\n</code></pre>"},{"location":"using/servers/#testing-with-wrapper","title":"Testing with Wrapper","text":"<pre><code># Test through mcpgateway.wrapper\nexport MCP_AUTH_TOKEN=$MCPGATEWAY_BEARER_TOKEN\nexport MCP_SERVER_CATALOG_URLS='http://localhost:4444/servers/UUID_OF_SERVER_1'\npython3 -m mcpgateway.wrapper\n</code></pre>"},{"location":"using/servers/#development-guidelines","title":"\ud83d\udee0 Development Guidelines","text":""},{"location":"using/servers/#adding-new-sample-servers","title":"Adding New Sample Servers","text":"<p>Each sample server should follow these conventions:</p>"},{"location":"using/servers/#directory-structure","title":"Directory Structure","text":"<pre><code>mcp-servers/\n\u251c\u2500\u2500 go/\n\u2502   \u2514\u2500\u2500 your-server/\n\u2502       \u251c\u2500\u2500 main.go\n\u2502       \u251c\u2500\u2500 Makefile\n\u2502       \u251c\u2500\u2500 Dockerfile\n\u2502       \u2514\u2500\u2500 README.md\n\u251c\u2500\u2500 python/\n\u2502   \u2514\u2500\u2500 your-server/\n\u2502       \u251c\u2500\u2500 main.py\n\u2502       \u251c\u2500\u2500 pyproject.toml\n\u2502       \u251c\u2500\u2500 Dockerfile\n\u2502       \u2514\u2500\u2500 README.md\n\u2514\u2500\u2500 typescript/\n    \u2514\u2500\u2500 your-server/\n        \u251c\u2500\u2500 src/index.ts\n        \u251c\u2500\u2500 package.json\n        \u251c\u2500\u2500 Dockerfile\n        \u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"using/servers/#required-features","title":"Required Features","text":"<ul> <li>\u2705 Multiple transports - stdio, SSE, HTTP support</li> <li>\u2705 Container ready - Dockerfile with multi-stage builds</li> <li>\u2705 Health checks - <code>/health</code> endpoint for monitoring</li> <li>\u2705 Authentication - Bearer token support for web transports</li> <li>\u2705 Logging - Configurable log levels</li> <li>\u2705 Documentation - Complete usage examples and API docs</li> </ul>"},{"location":"using/servers/#performance-targets","title":"Performance Targets","text":"<ul> <li>Response Time: &lt; 10ms for simple operations</li> <li>Memory Usage: &lt; 50MB baseline memory footprint</li> <li>Startup Time: &lt; 1 second cold start</li> <li>Throughput: &gt; 1000 requests/second under load</li> </ul>"},{"location":"using/servers/#performance-comparison","title":"\ud83d\udcca Performance Comparison","text":"Server Language Response Time Memory Binary Size Cold Start fast-time-server Go 0.5ms 8MB 12MB 100ms coming soon Python ~2ms 25MB N/A 300ms coming soon TypeScript ~3ms 35MB N/A 400ms coming soon Rust 0.3ms 4MB 8MB 50ms coming soon Java ~5ms 45MB 25MB 800ms <p>Benchmarks measured on standard GitHub Actions runners</p>"},{"location":"using/servers/#contributing","title":"\ud83e\udd1d Contributing","text":"<p>We welcome contributions of new sample servers!</p>"},{"location":"using/servers/#contribution-process","title":"Contribution Process","text":"<ol> <li>Choose a language and create the directory structure</li> <li>Implement core MCP functionality following our guidelines</li> <li>Add comprehensive tests and performance benchmarks</li> <li>Create documentation following the fast-time-server example</li> <li>Submit a pull request with your implementation</li> </ol>"},{"location":"using/servers/#language-priorities","title":"Language Priorities","text":"<p>We're particularly interested in: - Python - Most popular for AI/ML tooling - TypeScript - Web-native integration - Rust - Maximum performance critical applications - Java - Enterprise integration scenarios</p>"},{"location":"using/servers/#resources","title":"\ud83d\udcda Resources","text":""},{"location":"using/servers/#mcp-specification","title":"MCP Specification","text":"<ul> <li>Model Context Protocol</li> <li>JSON-RPC 2.0 Specification</li> </ul>"},{"location":"using/servers/#gateway-documentation","title":"Gateway Documentation","text":"<ul> <li>MCP Context Forge Gateway</li> <li>mcpgateway.wrapper Usage</li> <li>mcpgateway.translate Bridge</li> </ul>"},{"location":"using/servers/#development-tools","title":"Development Tools","text":"<ul> <li>MCP Inspector - Interactive protocol debugging</li> <li>Supergateway - stdio to SSE bridge</li> <li>UV - Fast Python package management</li> </ul>"},{"location":"using/servers/#quick-links","title":"\ud83d\udd17 Quick Links","text":"<ul> <li>\ud83e\uddab Fast Time Server (Go) \u2192</li> </ul> <p>Want to add a new sample server? Open an issue or submit a pull request!</p>"},{"location":"using/servers/go-fast-time-server/","title":"\ud83e\uddab Fast Time Server","text":"<p><code>fast-time-server</code> is a lightweight, high-performance Go service that provides current time lookup across different timezones via multiple transport protocols. Built specifically for MCP (Model Context Protocol) integration, it supports stdio, HTTP, SSE, and dual transport modes.</p> <p>Perfect for time-sensitive applications requiring fast, reliable timezone conversions with sub-millisecond response times and multiple client interface options.</p>"},{"location":"using/servers/go-fast-time-server/#docker-gateway-integration","title":"Docker Gateway Integration","text":""},{"location":"using/servers/go-fast-time-server/#running-fast-time-server-for-gateway-registration","title":"Running fast-time-server for Gateway Registration","text":"<pre><code># 1\ufe0f\u20e3 Start fast-time-server in SSE mode for direct gateway registration\ndocker run --rm -d --name fast-time-server \\\n  -p 8888:8080 \\\n  ghcr.io/ibm/fast-time-server:latest \\\n  -transport=sse -listen=0.0.0.0 -port=8080 -log-level=debug\n\n# 2\ufe0f\u20e3 Register with gateway (gateway running on host)\ncurl -X POST -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"name\":\"docker_fast_time\",\"url\":\"http://host.docker.internal:8888/sse\"}' \\\n     http://localhost:4444/gateways\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#docker-compose-setup","title":"Docker Compose Setup","text":"<p>Create <code>docker-compose.yml</code> for integrated testing:</p> <pre><code>version: '3.8'\nservices:\n  mcpgateway:\n    image: ghcr.io/ibm/mcp-context-forge:latest\n    ports:\n      - \"4444:4444\"\n    environment:\n      BASIC_AUTH_PASSWORD: pass\n      JWT_SECRET_KEY: my-test-key\n    command: mcpgateway --host 0.0.0.0 --port 4444\n\n  fast-time-server:\n    image: ghcr.io/ibm/fast-time-server:latest\n    ports:\n      - \"8888:8080\"\n    command: [\"-transport=sse\", \"-listen=0.0.0.0\", \"-port=8080\", \"-log-level=debug\"]\n    depends_on:\n      - mcpgateway\n\n  wrapper-test:\n    image: ghcr.io/ibm/mcp-context-forge:latest\n    environment:\n      MCP_AUTH_TOKEN: \"${MCPGATEWAY_BEARER_TOKEN}\"\n      MCP_SERVER_CATALOG_URLS: \"http://mcpgateway:4444/servers/UUID_OF_SERVER_1\"\n      MCP_WRAPPER_LOG_LEVEL: DEBUG\n    command: python3 -m mcpgateway.wrapper\n    depends_on:\n      - mcpgateway\n      - fast-time-server\n    stdin_open: true\n    tty: true\n</code></pre> <p>Run the complete stack:</p> <pre><code># Generate token\nexport MCPGATEWAY_BEARER_TOKEN=$(docker run --rm ghcr.io/ibm/mcp-context-forge:latest \\\n  python3 -m mcpgateway.utils.create_jwt_token --username admin --exp 10080 --secret my-test-key)\n\n# Start services\ndocker-compose up -d mcpgateway fast-time-server\n\n# Register fast-time-server\ncurl -X POST -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"name\":\"docker_time\",\"url\":\"http://fast-time-server:8080/sse\"}' \\\n     http://localhost:4444/gateways\n\n# Test wrapper\ndocker-compose run wrapper-test\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#container-networking-notes","title":"Container Networking Notes","text":"<p>Docker Networking</p> <ul> <li>Use <code>host.docker.internal</code> when gateway runs on host and server in container</li> <li>Use service names when both run in same Docker Compose network</li> <li>Map ports consistently: <code>-p 8888:8080</code> maps host port 8888 to container port 8080</li> </ul>"},{"location":"using/servers/go-fast-time-server/#key-features","title":"\ud83d\udd11 Key Features","text":"<ul> <li>\u26a1 Ultra-fast - Written in Go for minimal latency and high throughput</li> <li>\ud83c\udf0d Timezone-aware - IANA timezone support with DST handling</li> <li>\ud83d\ude80 Multiple transports - stdio, HTTP, SSE, and dual-mode support</li> <li>\ud83d\udd10 Secure - Bearer token authentication for SSE endpoints</li> <li>\ud83d\udcca Production-ready - Built-in benchmarking, logging, and health checks</li> <li>\ud83d\udc33 Docker-native - Pre-built container images available</li> </ul>"},{"location":"using/servers/go-fast-time-server/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"using/servers/go-fast-time-server/#docker-recommended","title":"Docker (Recommended)","text":"<p>Run with dual transport mode (HTTP + SSE on port 8080):</p> <pre><code>docker run --rm -it -p 8888:8080 \\\n  ghcr.io/ibm/fast-time-server:latest \\\n  -transport=dual -log-level=debug\n</code></pre> <p>Port Mapping</p> <p>The example maps host port <code>8888</code> to container port <code>8080</code>. Adjust as needed for your environment.</p>"},{"location":"using/servers/go-fast-time-server/#alternative-transport-modes","title":"Alternative Transport Modes","text":"HTTP OnlySSE OnlySSE with AuthSTDIO (MCP Default) <pre><code>docker run --rm -p 8080:8080 \\\n  ghcr.io/ibm/fast-time-server:latest \\\n  -transport=http -addr=0.0.0.0:8080\n</code></pre> <pre><code>docker run --rm -p 8080:8080 \\\n  ghcr.io/ibm/fast-time-server:latest \\\n  -transport=sse -listen=0.0.0.0 -port=8080\n</code></pre> <pre><code>docker run --rm -p 8080:8080 \\\n  -e AUTH_TOKEN=your-secret-token \\\n  ghcr.io/ibm/fast-time-server:latest \\\n  -transport=sse -listen=0.0.0.0 -port=8080 -auth-token=your-secret-token\n</code></pre> <pre><code>docker run --rm -i \\\n  ghcr.io/ibm/fast-time-server:latest \\\n  -transport=stdio\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#building-from-source","title":"\ud83d\udee0 Building from Source","text":""},{"location":"using/servers/go-fast-time-server/#prerequisites","title":"Prerequisites","text":"<ul> <li>Go 1.21+ installed</li> <li>Git for cloning the repository</li> <li>Make for build automation</li> </ul>"},{"location":"using/servers/go-fast-time-server/#clone-and-build","title":"Clone and Build","text":"<pre><code># Clone the MCP servers repository\ngit clone https://github.com/IBM/mcp-context-forge\ncd mcp-servers/go/fast-time-server\n\n# Install dependencies and build\nmake tidy\nmake build\n\n# Binary will be in ./dist/fast-time-server\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#development-commands","title":"Development Commands","text":"Build &amp; TestCode QualityCross-Compilation <pre><code>make build          # Build binary into ./dist\nmake test           # Run unit tests with race detection\nmake coverage       # Generate HTML coverage report\nmake install        # Install to GOPATH/bin\n</code></pre> <pre><code>make fmt            # Format code (gofmt + goimports)\nmake vet            # Run go vet\nmake lint           # Run golangci-lint\nmake staticcheck    # Run staticcheck\nmake pre-commit     # Run all pre-commit hooks\n</code></pre> <pre><code># Build for different platforms\nGOOS=linux GOARCH=amd64 make release\nGOOS=darwin GOARCH=arm64 make release\nGOOS=windows GOARCH=amd64 make release\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#running-locally","title":"\ud83c\udfc3 Running Locally","text":""},{"location":"using/servers/go-fast-time-server/#local-development","title":"Local Development","text":"<pre><code># Quick run with stdio transport\nmake run\n\n# Run specific transport modes\nmake run-http    # HTTP on :8080\nmake run-sse     # SSE on :8080\nmake run-dual    # Both HTTP &amp; SSE on :8080\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#manual-execution","title":"Manual Execution","text":"<pre><code># After building with make build\n./dist/fast-time-server -transport=dual -port=8080 -log-level=info\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#docker-development","title":"\ud83d\udc33 Docker Development","text":""},{"location":"using/servers/go-fast-time-server/#build-your-own-image","title":"Build Your Own Image","text":"<pre><code>make docker-build\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#development-containers","title":"Development Containers","text":"HTTP DevelopmentSSE DevelopmentAuthenticated SSE <pre><code>make docker-run\n# Runs HTTP transport on localhost:8080\n</code></pre> <pre><code>make docker-run-sse\n# Runs SSE transport on localhost:8080\n</code></pre> <pre><code>make docker-run-sse-auth TOKEN=my-dev-token\n# Runs SSE with Bearer token authentication\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#configuration-options","title":"\u2699\ufe0f Configuration Options","text":"Flag Description Default Example <code>-transport</code> Transport mode: <code>stdio</code>, <code>http</code>, <code>sse</code>, <code>dual</code> <code>stdio</code> <code>-transport=dual</code> <code>-addr</code> HTTP bind address <code>:8080</code> <code>-addr=0.0.0.0:8080</code> <code>-listen</code> SSE listen address <code>localhost</code> <code>-listen=0.0.0.0</code> <code>-port</code> Port for SSE/dual mode <code>8080</code> <code>-port=9000</code> <code>-auth-token</code> Bearer token for SSE authentication - <code>-auth-token=secret123</code> <code>-log-level</code> Logging level: <code>debug</code>, <code>info</code>, <code>warn</code>, <code>error</code> <code>info</code> <code>-log-level=debug</code>"},{"location":"using/servers/go-fast-time-server/#api-endpoints","title":"\ud83d\udce1 API Endpoints","text":""},{"location":"using/servers/go-fast-time-server/#http-transport-transporthttp-or-transportdual","title":"HTTP Transport (<code>-transport=http</code> or <code>-transport=dual</code>)","text":"<p>POST <code>/http</code> - JSON-RPC endpoint</p> <pre><code>curl -X POST http://localhost:8080/http \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"jsonrpc\": \"2.0\",\n    \"id\": 1,\n    \"method\": \"get_system_time\",\n    \"params\": {\n      \"timezone\": \"Europe/Dublin\"\n    }\n  }'\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#sse-transport-transportsse-or-transportdual","title":"SSE Transport (<code>-transport=sse</code> or <code>-transport=dual</code>)","text":"<p>GET <code>/sse</code> - Server-Sent Events stream POST <code>/messages</code> - Send JSON-RPC messages</p> <pre><code># Connect to SSE stream\ncurl -N http://localhost:8080/sse\n\n# Send message (in another terminal)\ncurl -X POST http://localhost:8080/messages \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"method\":\"get_system_time\",\"params\":{\"timezone\":\"UTC\"}}'\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#stdio-transport-transportstdio","title":"STDIO Transport (<code>-transport=stdio</code>)","text":"<p>Standard MCP JSON-RPC over stdin/stdout:</p> <pre><code>{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"get_system_time\",\"params\":{\"timezone\":\"America/New_York\"}}\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#testing-benchmarking","title":"\ud83e\uddea Testing &amp; Benchmarking","text":""},{"location":"using/servers/go-fast-time-server/#unit-tests","title":"Unit Tests","text":"<pre><code>make test           # Run all tests\nmake coverage       # Generate coverage report\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#load-testing","title":"Load Testing","text":"<p>Start the server in dual mode:</p> <pre><code>make run-dual\n</code></pre> <p>Run benchmark (requires hey):</p> <pre><code>make bench\n# Runs 100,000 requests with 100 concurrent connections\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#manual-performance-test","title":"Manual Performance Test","text":"<pre><code># Create a test payload\necho '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"get_system_time\",\"params\":{\"timezone\":\"UTC\"}}' &gt; payload.json\n\n# Run load test\nhey -m POST -T 'application/json' -D payload.json -n 10000 -c 50 http://localhost:8080/http\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#mcp-gateway-integration","title":"\ud83c\udf10 MCP Gateway Integration","text":""},{"location":"using/servers/go-fast-time-server/#registering-with-mcp-gateway","title":"Registering with MCP Gateway","text":"<p>The fast-time-server can be registered with an MCP Gateway to expose its tools through the gateway's federated API.</p>"},{"location":"using/servers/go-fast-time-server/#method-1-using-supergateway-recommended","title":"Method 1: Using Supergateway (Recommended)","text":"<pre><code># 1\ufe0f\u20e3 Start the Gateway (if not already running)\npip install mcp-contextforge-gateway\nBASIC_AUTH_PASSWORD=pass JWT_SECRET_KEY=my-test-key \\\n  mcpgateway --host 0.0.0.0 --port 4444 &amp;\n\n# 2\ufe0f\u20e3 Expose fast-time-server via supergateway\npip install uv\nnpx -y supergateway --stdio \"./dist/fast-time-server -transport=stdio\" --port 8002 &amp;\n\n# 3\ufe0f\u20e3 Register with the gateway\nexport MCPGATEWAY_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token \\\n    --username admin --exp 10080 --secret my-test-key)\n\ncurl -X POST -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"name\":\"fast_time\",\"url\":\"http://localhost:8002/sse\"}' \\\n     http://localhost:4444/gateways\n\n# 4\ufe0f\u20e3 Create a virtual server with the time tools\ncurl -X POST -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"name\":\"time_server\",\"description\":\"Fast time tools\",\"associatedTools\":[\"1\",\"2\"]}' \\\n     http://localhost:4444/servers\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#method-2-direct-sse-registration","title":"Method 2: Direct SSE Registration","text":"<pre><code># 1\ufe0f\u20e3 Start fast-time-server in SSE mode\n./dist/fast-time-server -transport=sse -port=8003\n\n# 2\ufe0f\u20e3 Register directly with the gateway\ncurl -X POST -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"name\":\"fast_time_direct\",\"url\":\"http://localhost:8003/sse\"}' \\\n     http://localhost:4444/gateways\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#testing-with-mcpgatewaywrapper","title":"Testing with mcpgateway.wrapper","text":"<p>The <code>mcpgateway.wrapper</code> bridges gateway tools to stdio, perfect for testing and MCP client integration:</p> <pre><code># 1\ufe0f\u20e3 Set up environment variables\nexport MCP_AUTH_TOKEN=$MCPGATEWAY_BEARER_TOKEN\nexport MCP_SERVER_CATALOG_URLS='http://localhost:4444/servers/UUID_OF_SERVER_1'\nexport MCP_TOOL_CALL_TIMEOUT=120\nexport MCP_WRAPPER_LOG_LEVEL=DEBUG\n\n# 2\ufe0f\u20e3 Start the wrapper (manual testing)\npython3 -m mcpgateway.wrapper\n\n# 3\ufe0f\u20e3 Test MCP protocol manually\n# Initialize\necho '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"initialize\",\"params\":{\"protocolVersion\":\"2025-03-26\",\"capabilities\":{},\"clientInfo\":{\"name\":\"test\",\"version\":\"1.0\"}}}' | python3 -m mcpgateway.wrapper\n\n# List tools\necho '{\"jsonrpc\":\"2.0\",\"id\":2,\"method\":\"tools/list\"}' | python3 -m mcpgateway.wrapper\n\n# Call get_system_time\necho '{\"jsonrpc\":\"2.0\",\"id\":3,\"method\":\"tools/call\",\"params\":{\"name\":\"get_system_time\",\"arguments\":{\"timezone\":\"Europe/Dublin\"}}}' | python3 -m mcpgateway.wrapper\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#testing-with-mcpgatewaytranslate","title":"Testing with mcpgateway.translate","text":"<p>Use <code>mcpgateway.translate</code> to bridge stdio servers to SSE endpoints:</p> <pre><code># 1\ufe0f\u20e3 Bridge fast-time-server (stdio) to SSE on port 9000\npython3 -m mcpgateway.translate \\\n  --stdio \"./dist/fast-time-server -transport=stdio\" \\\n  --port 9000\n\n# 2\ufe0f\u20e3 In another terminal, connect to the SSE stream\ncurl -N http://localhost:9000/sse\n\n# 3\ufe0f\u20e3 Send test requests (in a third terminal)\n# Initialize\ncurl -X POST http://localhost:9000/message \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"initialize\",\"params\":{\"protocolVersion\":\"2025-03-26\",\"capabilities\":{},\"clientInfo\":{\"name\":\"test\",\"version\":\"1.0\"}}}'\n\n# List tools\ncurl -X POST http://localhost:9000/message \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"jsonrpc\":\"2.0\",\"id\":2,\"method\":\"tools/list\"}'\n\n# Call get_system_time\ncurl -X POST http://localhost:9000/message \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"jsonrpc\":\"2.0\",\"id\":3,\"method\":\"tools/call\",\"params\":{\"name\":\"get_system_time\",\"arguments\":{\"timezone\":\"Asia/Tokyo\"}}}'\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#mcp-inspector-integration","title":"MCP Inspector Integration","text":"<p>Test your gateway setup with MCP Inspector:</p> <pre><code># 1\ufe0f\u20e3 Direct fast-time-server inspection\nnpx @modelcontextprotocol/inspector ./dist/fast-time-server\n\n# 2\ufe0f\u20e3 Inspect via gateway wrapper\nnpx @modelcontextprotocol/inspector python3 -m mcpgateway.wrapper\n# Environment: MCP_AUTH_TOKEN, MCP_SERVER_CATALOG_URLS\n\n# 3\ufe0f\u20e3 Inspect SSE endpoint directly\nnpx @modelcontextprotocol/inspector\n# Transport: SSE\n# URL: http://localhost:4444/servers/UUID_OF_SERVER_1/sse\n# Header: Authorization\n# Value: Bearer &lt;your-token&gt;\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#mcp-client-integration","title":"\ud83d\udd0c MCP Client Integration","text":""},{"location":"using/servers/go-fast-time-server/#claude-desktop","title":"Claude Desktop","text":"<p>Add to your <code>claude_desktop_config.json</code>:</p> Direct IntegrationVia Gateway WrapperDocker with MCP Client <pre><code>{\n  \"mcpServers\": {\n    \"fast-time-server\": {\n      \"command\": \"/path/to/fast-time-server\",\n      \"args\": [\"-transport=stdio\"],\n      \"env\": {}\n    }\n  }\n}\n</code></pre> <pre><code>{\n  \"mcpServers\": {\n    \"gateway-time\": {\n      \"command\": \"python3\",\n      \"args\": [\"-m\", \"mcpgateway.wrapper\"],\n      \"env\": {\n        \"MCP_AUTH_TOKEN\": \"&lt;your-bearer-token&gt;\",\n        \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444/servers/UUID_OF_SERVER_1\"\n      }\n    }\n  }\n}\n</code></pre> <pre><code>{\n  \"mcpServers\": {\n    \"fast-time-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\", \"--rm\", \"-i\",\n        \"ghcr.io/ibm/fast-time-server:latest\",\n        \"-transport=stdio\"\n      ]\n    }\n  }\n}\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#continuecline-integration","title":"Continue/Cline Integration","text":"<p>For VS Code extensions:</p> <pre><code>{\n  \"mcpServers\": {\n    \"fast-time-server\": {\n      \"command\": \"/path/to/fast-time-server\",\n      \"args\": [\"-transport=stdio\", \"-log-level=info\"],\n      \"env\": {}\n    }\n  }\n}\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#gateway-workflow-examples","title":"Gateway Workflow Examples","text":""},{"location":"using/servers/go-fast-time-server/#complete-end-to-end-test","title":"Complete End-to-End Test","text":"<pre><code># 1\ufe0f\u20e3 Start Gateway\nBASIC_AUTH_PASSWORD=pass JWT_SECRET_KEY=my-test-key mcpgateway --host 0.0.0.0 --port 4444 &amp;\n\n# 2\ufe0f\u20e3 Start fast-time-server via supergateway\nnpx -y supergateway --stdio \"./dist/fast-time-server -transport=stdio\" --port 8002 &amp;\n\n# 3\ufe0f\u20e3 Generate token and register\nexport MCPGATEWAY_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token --username admin --exp 10080 --secret my-test-key)\n\ncurl -X POST -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"name\":\"fast_time\",\"url\":\"http://localhost:8002/sse\"}' \\\n     http://localhost:4444/gateways\n\n# 4\ufe0f\u20e3 Verify tools are available\ncurl -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     http://localhost:4444/tools | jq\n\n# 5\ufe0f\u20e3 Create virtual server\ncurl -X POST -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"name\":\"time_server\",\"description\":\"Fast time tools\",\"associatedTools\":[\"1\"]}' \\\n     http://localhost:4444/servers\n\n# 6\ufe0f\u20e3 Test via wrapper\nexport MCP_AUTH_TOKEN=$MCPGATEWAY_BEARER_TOKEN\nexport MCP_SERVER_CATALOG_URLS='http://localhost:4444/servers/UUID_OF_SERVER_1'\necho '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/call\",\"params\":{\"name\":\"get_system_time\",\"arguments\":{\"timezone\":\"UTC\"}}}' | python3 -m mcpgateway.wrapper\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#expected-gateway-responses","title":"Expected Gateway Responses","text":"<p>When testing with the wrapper, you should see responses like:</p> <pre><code>// Tool listing response\n{\n  \"jsonrpc\":\"2.0\",\"id\":2,\n  \"result\":{\n    \"tools\":[\n      {\n        \"name\":\"get_system_time\",\n        \"description\":\"Get current time in a specific timezone\",\n        \"inputSchema\":{\n          \"type\":\"object\",\n          \"properties\":{\n            \"timezone\":{\n              \"type\":\"string\",\n              \"description\":\"IANA timezone name (e.g., 'America/New_York', 'Europe/London')\"\n            }\n          },\n          \"required\":[\"timezone\"]\n        }\n      }\n    ]\n  }\n}\n\n// Tool execution response\n{\n  \"jsonrpc\":\"2.0\",\"id\":3,\n  \"result\":{\n    \"content\":[\n      {\n        \"type\":\"text\",\n        \"text\":\"{\\\"timezone\\\":\\\"UTC\\\",\\\"datetime\\\":\\\"2025-07-08T21:30:15Z\\\",\\\"is_dst\\\":false}\"\n      }\n    ],\n    \"isError\":false\n  }\n}\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#usage-examples","title":"\ud83d\udca1 Usage Examples","text":""},{"location":"using/servers/go-fast-time-server/#get-current-time","title":"Get Current Time","text":"<pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"get_system_time\",\n  \"params\": {\n    \"timezone\": \"Europe/Dublin\"\n  }\n}\n</code></pre> <p>Response: <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": {\n    \"content\": [\n      {\n        \"type\": \"text\",\n        \"text\": \"{\\\"timezone\\\":\\\"Europe/Dublin\\\",\\\"datetime\\\":\\\"2025-07-08T22:30:15+01:00\\\",\\\"is_dst\\\":true}\"\n      }\n    ],\n    \"isError\": false\n  }\n}\n</code></pre></p>"},{"location":"using/servers/go-fast-time-server/#common-timezones","title":"Common Timezones","text":"Region Timezone Example \ud83c\uddfa\ud83c\uddf8 US East <code>America/New_York</code> <code>2025-07-08T17:30:15-04:00</code> \ud83c\uddfa\ud83c\uddf8 US West <code>America/Los_Angeles</code> <code>2025-07-08T14:30:15-07:00</code> \ud83c\uddec\ud83c\udde7 UK <code>Europe/London</code> <code>2025-07-08T22:30:15+01:00</code> \ud83c\uddee\ud83c\uddea Ireland <code>Europe/Dublin</code> <code>2025-07-08T22:30:15+01:00</code> \ud83c\uddef\ud83c\uddf5 Japan <code>Asia/Tokyo</code> <code>2025-07-09T06:30:15+09:00</code> \ud83c\udf0d UTC <code>UTC</code> <code>2025-07-08T21:30:15Z</code>"},{"location":"using/servers/go-fast-time-server/#maintenance","title":"\ud83e\uddf9 Maintenance","text":""},{"location":"using/servers/go-fast-time-server/#cleanup","title":"Cleanup","text":"<pre><code>make clean          # Remove build artifacts\ndocker system prune # Clean up Docker images/containers\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#updates","title":"Updates","text":"<pre><code>git pull            # Update source code\nmake tools          # Update Go tools (golangci-lint, staticcheck)\nmake tidy           # Update Go dependencies\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#troubleshooting","title":"\ud83d\udea8 Troubleshooting","text":""},{"location":"using/servers/go-fast-time-server/#common-issues","title":"Common Issues","text":"<p>Port Already in Use</p> <p><pre><code>Error: bind: address already in use\n</code></pre> Solution: Change the port with <code>-port=9000</code> or kill the existing process.</p> <p>Docker Permission Denied</p> <p><pre><code>docker: permission denied\n</code></pre> Solution: Add your user to the docker group or use <code>sudo</code>.</p> <p>SSE Authentication Failed</p> <p><pre><code>401 Unauthorized\n</code></pre> Solution: Ensure you're passing the correct <code>-auth-token</code> and including <code>Authorization: Bearer &lt;token&gt;</code> in requests.</p>"},{"location":"using/servers/go-fast-time-server/#debug-mode","title":"Debug Mode","text":"<p>Enable verbose logging:</p> <pre><code>./fast-time-server -transport=dual -log-level=debug\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#gateway-integration-issues","title":"Gateway Integration Issues","text":"<p>Gateway Registration Failed</p> <p><pre><code>Error: Connection refused to http://localhost:4444\n</code></pre> Solution: Ensure the MCP Gateway is running on the correct port and check firewall settings.</p> <p>Wrapper Authentication Failed</p> <p><pre><code>HTTP 401: Unauthorized\n</code></pre> Solution: Verify your <code>MCP_AUTH_TOKEN</code> is valid and not expired: <pre><code>curl -H \"Authorization: Bearer $MCP_AUTH_TOKEN\" http://localhost:4444/version\n</code></pre></p> <p>No Tools Available in Wrapper</p> <p><pre><code>{\"jsonrpc\":\"2.0\",\"id\":2,\"result\":{\"tools\":[]}}\n</code></pre> Solution: Check that: 1. fast-time-server is registered with the gateway 2. A virtual server exists with associated tools 3. <code>MCP_SERVER_CATALOG_URLS</code> points to the correct server ID</p> <p>Supergateway Not Found</p> <p><pre><code>npx: command not found\n</code></pre> Solution: Install Node.js and npm: <pre><code># Ubuntu/Debian\nsudo apt install nodejs npm\n\n# macOS\nbrew install node\n</code></pre></p> <p>mcpgateway.translate Connection Issues</p> <p><pre><code>Error: Process terminated unexpectedly\n</code></pre> Solution: Check that the stdio command is correct and the binary exists: <pre><code># Test the command directly first\n./dist/fast-time-server -transport=stdio\n</code></pre></p>"},{"location":"using/servers/go-fast-time-server/#testing-connectivity","title":"Testing Connectivity","text":"<p>Verify each component is working:</p> <pre><code># 1. Test fast-time-server directly\necho '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/list\"}' | ./dist/fast-time-server -transport=stdio | jq\n\n# 2. Test gateway API\ncurl -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" http://localhost:4444/health\n\n# 3. Test wrapper connectivity\nexport MCP_WRAPPER_LOG_LEVEL=DEBUG\npython3 -m mcpgateway.wrapper\n</code></pre>"},{"location":"using/servers/go-fast-time-server/#further-reading","title":"\ud83d\udcda Further Reading","text":"<ul> <li>MCP Protocol Specification</li> <li>IANA Time Zone Database</li> <li>Go Time Package Documentation</li> <li>JSON-RPC 2.0 Specification</li> </ul>"}]}